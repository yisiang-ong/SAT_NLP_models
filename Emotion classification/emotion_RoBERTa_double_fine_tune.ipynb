{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#package imports \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from transformers import DistilBertTokenizer, AutoTokenizer, AutoModelWithLMHead, DistilBertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "\n",
    "from typing import List\n",
    "import logging\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "from functools import lru_cache\n",
    "from argparse import Namespace\n",
    "from packaging import version\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This notebook is partly adapted from Saravia et al.'s Emotion dataset notebook which is\n",
    "#available at this link: https://colab.research.google.com/drive/1nwCE6b9PXIKhv2hvbqf1oZKIGkXMTi1X#scrollTo=t23zHggkEpc-\n",
    "\n",
    "#In fact, we use the Emotion dataset by Saravia et al. for the first finetuning step. Full citation below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_CITATION = \"\"\"\\\n",
    "@inproceedings{saravia-etal-2018-carer,\n",
    "    title = \"{CARER}: Contextualized Affect Representations for Emotion Recognition\",\n",
    "    author = \"Saravia, Elvis  and\n",
    "      Liu, Hsien-Chi Toby  and\n",
    "      Huang, Yen-Hao  and\n",
    "      Wu, Junlin  and\n",
    "      Chen, Yi-Shin\",\n",
    "    booktitle = \"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing\",\n",
    "    month = oct # \"-\" # nov,\n",
    "    year = \"2018\",\n",
    "    address = \"Brussels, Belgium\",\n",
    "    publisher = \"Association for Computational Linguistics\",\n",
    "    url = \"https://www.aclweb.org/anthology/D18-1404\",\n",
    "    doi = \"10.18653/v1/D18-1404\",\n",
    "    pages = \"3687--3697\"\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tune on CARER dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we define the paths for train, val, test, same split as already obtained in the T5 notebook\n",
    "train_path = \"emotion_data/train.txt\"\n",
    "test_path = \"emotion_data/test.txt\"\n",
    "val_path = \"emotion_data/val.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary associating each string label to an integer value\n",
    "\n",
    "labels = [ \"sadness\", \"joy\", \"anger\", \"fear\"]\n",
    "label2int = dict(zip(labels, list(range(len(labels)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yisiang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:998: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "#load actual model\n",
    "model = AutoModelWithLMHead.from_pretrained('roberta-base')\n",
    "base_model = model.base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Mish activation function \n",
    "#(from https://github.com/digantamisra98/Mish/blob/b5f006660ac0b4c46e2c6958ad0301d7f9c59651/Mish/Torch/mish.py)\n",
    "@torch.jit.script\n",
    "def mish(input):\n",
    "    return input * torch.tanh(F.softplus(input))\n",
    "  \n",
    "class Mish(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return mish(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note: the following code is partly adapted from Marcin Zablocki's tutorial 'custom classifier on top of bert-like language model'\n",
    "#define an EmoClassificationModel class to do the actual fine-tuning\n",
    "\n",
    "class EmoClassificationModel(nn.Module):\n",
    "    def __init__(self, base_model, n_classes, base_model_output_size=768, dropout=0.05):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(base_model_output_size, base_model_output_size),\n",
    "            Mish(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(base_model_output_size, n_classes)\n",
    "        )\n",
    "        \n",
    "        for layer in self.classifier:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                layer.weight.data.normal_(mean=0.0, std=0.02)\n",
    "                if layer.bias is not None:\n",
    "                    layer.bias.data.zero_()\n",
    "\n",
    "    def forward(self, input_, *args):\n",
    "        X, attention_mask = input_\n",
    "        hidden_states = self.base_model(X, attention_mask=attention_mask)\n",
    "        \n",
    "        return self.classifier(hidden_states[0][:, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tokenizer\\\\tokenizer_config.json',\n",
       " 'tokenizer\\\\special_tokens_map.json',\n",
       " 'tokenizer\\\\vocab.json',\n",
       " 'tokenizer\\\\merges.txt',\n",
       " 'tokenizer\\\\added_tokens.json',\n",
       " 'tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load pretrained tokenizer information\n",
    "tokenizer.save_pretrained(\"tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementation of CollateFN to do tokenization and batches of sequences\n",
    "\n",
    "class TokenizersCollateFn:\n",
    "    def __init__(self, max_tokens=512): \n",
    "\n",
    "        #RoBERTa uses the BPE tokenizer, similarly to GPT-2\n",
    "        t = ByteLevelBPETokenizer(\n",
    "            \"tokenizer/vocab.json\",\n",
    "            \"tokenizer/merges.txt\"\n",
    "        )\n",
    "        t._tokenizer.post_processor = BertProcessing(\n",
    "            (\"</s>\", t.token_to_id(\"</s>\")),\n",
    "            (\"<s>\", t.token_to_id(\"<s>\")),\n",
    "        )\n",
    "        t.enable_truncation(max_tokens)\n",
    "        t.enable_padding(pad_id=t.token_to_id(\"<pad>\"))\n",
    "        self.tokenizer = t\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        encoded = self.tokenizer.encode_batch([x[0] for x in batch])\n",
    "        sequences_padded = torch.tensor([enc.ids for enc in encoded])\n",
    "        attention_masks_padded = torch.tensor([enc.attention_mask for enc in encoded])\n",
    "        labels = torch.tensor([x[1] for x in batch])\n",
    "        \n",
    "        return (sequences_padded, attention_masks_padded), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class to create dataset objects from the data\n",
    "\n",
    "class EmoDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        super().__init__()\n",
    "        self.data_column = \"text\"\n",
    "        self.class_column = \"class\"\n",
    "        self.data = pd.read_csv(path, sep=\";\", header=None, names=[self.data_column, self.class_column],\n",
    "                               engine=\"python\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data.loc[idx, self.data_column], label2int[self.data.loc[idx, self.class_column]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use PyTorch Lighning for training. Lightning methods are defined here\n",
    "\n",
    "class TrainingModule(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.model = EmoClassificationModel(AutoModelWithLMHead.from_pretrained(\"roberta-base\").base_model, len(labels)) #was \"distilroberta-base\"\n",
    "        self.loss = nn.CrossEntropyLoss() #cross entropy loss since this is multi-class classification\n",
    "        # self.save_hyperparameters(hparams)\n",
    "        self.hparams = hparams\n",
    "\n",
    "    def step(self, batch, step_name=\"train\"):\n",
    "        X, y = batch\n",
    "        loss = self.loss(self.forward(X), y)\n",
    "        loss_key = f\"{step_name}_loss\"\n",
    "        tensorboard_logs = {loss_key: loss}\n",
    "\n",
    "        return { (\"loss\" if step_name == \"train\" else loss_key): loss, 'log': tensorboard_logs,\n",
    "               \"progress_bar\": {loss_key: loss}}\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        return self.model(X, *args)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"train\")\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"val\")\n",
    "\n",
    "    def validation_end(self, outputs: List[dict]):\n",
    "        loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        return {\"val_loss\": loss}\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"test\")\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.train_path, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.val_path)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.test_path)\n",
    "                \n",
    "    def create_data_loader(self, ds_path: str, shuffle=False):\n",
    "        return DataLoader(\n",
    "                    EmoDataset(ds_path),\n",
    "                    batch_size=self.hparams.batch_size,\n",
    "                    shuffle=shuffle,\n",
    "                    collate_fn=TokenizersCollateFn()\n",
    "        )\n",
    "        \n",
    "    @lru_cache()\n",
    "    def total_steps(self):\n",
    "        return len(self.train_dataloader()) // self.hparams.accumulate_grad_batches * self.hparams.epochs\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.model.parameters(), lr=self.hparams.lr) #we use AdamW as this usually performs well\n",
    "        lr_scheduler = get_linear_schedule_with_warmup(\n",
    "                    optimizer,\n",
    "                    num_warmup_steps=self.hparams.warmup_steps,\n",
    "                    num_training_steps=self.total_steps(),\n",
    "        )\n",
    "        return [optimizer], [{\"scheduler\": lr_scheduler, \"interval\": \"step\"}]\n",
    "   \n",
    "    def save_model(self):\n",
    "        torch.save(self.model.state_dict(), 'emotion_model/RoBERTa_emotion_2ft.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = Namespace(\n",
    "    train_path=train_path,\n",
    "    val_path=val_path,\n",
    "    test_path=test_path,\n",
    "    batch_size=15,\n",
    "    warmup_steps=100,\n",
    "    epochs=10,\n",
    "    lr=2E-05,\n",
    "    accumulate_grad_batches=1\n",
    ")\n",
    "module = TrainingModule(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rubbish collection\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",  # monitor validation loss\n",
    "    min_delta=0.001, #to very small change in the monitored quantity to qualify as an improvement\n",
    "    patience=20, # used to check number of time with no improvement after which training will be stopped\n",
    "    verbose=False, \n",
    "    mode=\"min\" #sed while training will stopped when the quantity monitor has stopped decreasing\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:GPU available: True, used: True\n",
      "INFO:lightning:CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\yisiang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:23: RuntimeWarning: You have defined a `val_dataloader()` and have defined a `validation_step()`, you may also want to define `validation_epoch_end()` for accumulating stats.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\yisiang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:23: RuntimeWarning: You have defined a `test_dataloader()` and have defined a `test_step()`, you may also want to define `test_epoch_end()` for accumulating stats.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\yisiang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "INFO:lightning:\n",
      "    | Name                                                              | Type                   | Params\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "0   | model                                                             | EmoClassificationModel | 124 M \n",
      "1   | model.base_model                                                  | RobertaModel           | 124 M \n",
      "2   | model.base_model.embeddings                                       | RobertaEmbeddings      | 39 M  \n",
      "3   | model.base_model.embeddings.word_embeddings                       | Embedding              | 38 M  \n",
      "4   | model.base_model.embeddings.position_embeddings                   | Embedding              | 394 K \n",
      "5   | model.base_model.embeddings.token_type_embeddings                 | Embedding              | 768   \n",
      "6   | model.base_model.embeddings.LayerNorm                             | LayerNorm              | 1 K   \n",
      "7   | model.base_model.embeddings.dropout                               | Dropout                | 0     \n",
      "8   | model.base_model.encoder                                          | RobertaEncoder         | 85 M  \n",
      "9   | model.base_model.encoder.layer                                    | ModuleList             | 85 M  \n",
      "10  | model.base_model.encoder.layer.0                                  | RobertaLayer           | 7 M   \n",
      "11  | model.base_model.encoder.layer.0.attention                        | RobertaAttention       | 2 M   \n",
      "12  | model.base_model.encoder.layer.0.attention.self                   | RobertaSelfAttention   | 1 M   \n",
      "13  | model.base_model.encoder.layer.0.attention.self.query             | Linear                 | 590 K \n",
      "14  | model.base_model.encoder.layer.0.attention.self.key               | Linear                 | 590 K \n",
      "15  | model.base_model.encoder.layer.0.attention.self.value             | Linear                 | 590 K \n",
      "16  | model.base_model.encoder.layer.0.attention.self.dropout           | Dropout                | 0     \n",
      "17  | model.base_model.encoder.layer.0.attention.output                 | RobertaSelfOutput      | 592 K \n",
      "18  | model.base_model.encoder.layer.0.attention.output.dense           | Linear                 | 590 K \n",
      "19  | model.base_model.encoder.layer.0.attention.output.LayerNorm       | LayerNorm              | 1 K   \n",
      "20  | model.base_model.encoder.layer.0.attention.output.dropout         | Dropout                | 0     \n",
      "21  | model.base_model.encoder.layer.0.intermediate                     | RobertaIntermediate    | 2 M   \n",
      "22  | model.base_model.encoder.layer.0.intermediate.dense               | Linear                 | 2 M   \n",
      "23  | model.base_model.encoder.layer.0.intermediate.intermediate_act_fn | GELUActivation         | 0     \n",
      "24  | model.base_model.encoder.layer.0.output                           | RobertaOutput          | 2 M   \n",
      "25  | model.base_model.encoder.layer.0.output.dense                     | Linear                 | 2 M   \n",
      "26  | model.base_model.encoder.layer.0.output.LayerNorm                 | LayerNorm              | 1 K   \n",
      "27  | model.base_model.encoder.layer.0.output.dropout                   | Dropout                | 0     \n",
      "28  | model.base_model.encoder.layer.1                                  | RobertaLayer           | 7 M   \n",
      "29  | model.base_model.encoder.layer.1.attention                        | RobertaAttention       | 2 M   \n",
      "30  | model.base_model.encoder.layer.1.attention.self                   | RobertaSelfAttention   | 1 M   \n",
      "31  | model.base_model.encoder.layer.1.attention.self.query             | Linear                 | 590 K \n",
      "32  | model.base_model.encoder.layer.1.attention.self.key               | Linear                 | 590 K \n",
      "33  | model.base_model.encoder.layer.1.attention.self.value             | Linear                 | 590 K \n",
      "34  | model.base_model.encoder.layer.1.attention.self.dropout           | Dropout                | 0     \n",
      "35  | model.base_model.encoder.layer.1.attention.output                 | RobertaSelfOutput      | 592 K \n",
      "36  | model.base_model.encoder.layer.1.attention.output.dense           | Linear                 | 590 K \n",
      "37  | model.base_model.encoder.layer.1.attention.output.LayerNorm       | LayerNorm              | 1 K   \n",
      "38  | model.base_model.encoder.layer.1.attention.output.dropout         | Dropout                | 0     \n",
      "39  | model.base_model.encoder.layer.1.intermediate                     | RobertaIntermediate    | 2 M   \n",
      "40  | model.base_model.encoder.layer.1.intermediate.dense               | Linear                 | 2 M   \n",
      "41  | model.base_model.encoder.layer.1.output                           | RobertaOutput          | 2 M   \n",
      "42  | model.base_model.encoder.layer.1.output.dense                     | Linear                 | 2 M   \n",
      "43  | model.base_model.encoder.layer.1.output.LayerNorm                 | LayerNorm              | 1 K   \n",
      "44  | model.base_model.encoder.layer.1.output.dropout                   | Dropout                | 0     \n",
      "45  | model.base_model.encoder.layer.2                                  | RobertaLayer           | 7 M   \n",
      "46  | model.base_model.encoder.layer.2.attention                        | RobertaAttention       | 2 M   \n",
      "47  | model.base_model.encoder.layer.2.attention.self                   | RobertaSelfAttention   | 1 M   \n",
      "48  | model.base_model.encoder.layer.2.attention.self.query             | Linear                 | 590 K \n",
      "49  | model.base_model.encoder.layer.2.attention.self.key               | Linear                 | 590 K \n",
      "50  | model.base_model.encoder.layer.2.attention.self.value             | Linear                 | 590 K \n",
      "51  | model.base_model.encoder.layer.2.attention.self.dropout           | Dropout                | 0     \n",
      "52  | model.base_model.encoder.layer.2.attention.output                 | RobertaSelfOutput      | 592 K \n",
      "53  | model.base_model.encoder.layer.2.attention.output.dense           | Linear                 | 590 K \n",
      "54  | model.base_model.encoder.layer.2.attention.output.LayerNorm       | LayerNorm              | 1 K   \n",
      "55  | model.base_model.encoder.layer.2.attention.output.dropout         | Dropout                | 0     \n",
      "56  | model.base_model.encoder.layer.2.intermediate                     | RobertaIntermediate    | 2 M   \n",
      "57  | model.base_model.encoder.layer.2.intermediate.dense               | Linear                 | 2 M   \n",
      "58  | model.base_model.encoder.layer.2.output                           | RobertaOutput          | 2 M   \n",
      "59  | model.base_model.encoder.layer.2.output.dense                     | Linear                 | 2 M   \n",
      "60  | model.base_model.encoder.layer.2.output.LayerNorm                 | LayerNorm              | 1 K   \n",
      "61  | model.base_model.encoder.layer.2.output.dropout                   | Dropout                | 0     \n",
      "62  | model.base_model.encoder.layer.3                                  | RobertaLayer           | 7 M   \n",
      "63  | model.base_model.encoder.layer.3.attention                        | RobertaAttention       | 2 M   \n",
      "64  | model.base_model.encoder.layer.3.attention.self                   | RobertaSelfAttention   | 1 M   \n",
      "65  | model.base_model.encoder.layer.3.attention.self.query             | Linear                 | 590 K \n",
      "66  | model.base_model.encoder.layer.3.attention.self.key               | Linear                 | 590 K \n",
      "67  | model.base_model.encoder.layer.3.attention.self.value             | Linear                 | 590 K \n",
      "68  | model.base_model.encoder.layer.3.attention.self.dropout           | Dropout                | 0     \n",
      "69  | model.base_model.encoder.layer.3.attention.output                 | RobertaSelfOutput      | 592 K \n",
      "70  | model.base_model.encoder.layer.3.attention.output.dense           | Linear                 | 590 K \n",
      "71  | model.base_model.encoder.layer.3.attention.output.LayerNorm       | LayerNorm              | 1 K   \n",
      "72  | model.base_model.encoder.layer.3.attention.output.dropout         | Dropout                | 0     \n",
      "73  | model.base_model.encoder.layer.3.intermediate                     | RobertaIntermediate    | 2 M   \n",
      "74  | model.base_model.encoder.layer.3.intermediate.dense               | Linear                 | 2 M   \n",
      "75  | model.base_model.encoder.layer.3.output                           | RobertaOutput          | 2 M   \n",
      "76  | model.base_model.encoder.layer.3.output.dense                     | Linear                 | 2 M   \n",
      "77  | model.base_model.encoder.layer.3.output.LayerNorm                 | LayerNorm              | 1 K   \n",
      "78  | model.base_model.encoder.layer.3.output.dropout                   | Dropout                | 0     \n",
      "79  | model.base_model.encoder.layer.4                                  | RobertaLayer           | 7 M   \n",
      "80  | model.base_model.encoder.layer.4.attention                        | RobertaAttention       | 2 M   \n",
      "81  | model.base_model.encoder.layer.4.attention.self                   | RobertaSelfAttention   | 1 M   \n",
      "82  | model.base_model.encoder.layer.4.attention.self.query             | Linear                 | 590 K \n",
      "83  | model.base_model.encoder.layer.4.attention.self.key               | Linear                 | 590 K \n",
      "84  | model.base_model.encoder.layer.4.attention.self.value             | Linear                 | 590 K \n",
      "85  | model.base_model.encoder.layer.4.attention.self.dropout           | Dropout                | 0     \n",
      "86  | model.base_model.encoder.layer.4.attention.output                 | RobertaSelfOutput      | 592 K \n",
      "87  | model.base_model.encoder.layer.4.attention.output.dense           | Linear                 | 590 K \n",
      "88  | model.base_model.encoder.layer.4.attention.output.LayerNorm       | LayerNorm              | 1 K   \n",
      "89  | model.base_model.encoder.layer.4.attention.output.dropout         | Dropout                | 0     \n",
      "90  | model.base_model.encoder.layer.4.intermediate                     | RobertaIntermediate    | 2 M   \n",
      "91  | model.base_model.encoder.layer.4.intermediate.dense               | Linear                 | 2 M   \n",
      "92  | model.base_model.encoder.layer.4.output                           | RobertaOutput          | 2 M   \n",
      "93  | model.base_model.encoder.layer.4.output.dense                     | Linear                 | 2 M   \n",
      "94  | model.base_model.encoder.layer.4.output.LayerNorm                 | LayerNorm              | 1 K   \n",
      "95  | model.base_model.encoder.layer.4.output.dropout                   | Dropout                | 0     \n",
      "96  | model.base_model.encoder.layer.5                                  | RobertaLayer           | 7 M   \n",
      "97  | model.base_model.encoder.layer.5.attention                        | RobertaAttention       | 2 M   \n",
      "98  | model.base_model.encoder.layer.5.attention.self                   | RobertaSelfAttention   | 1 M   \n",
      "99  | model.base_model.encoder.layer.5.attention.self.query             | Linear                 | 590 K \n",
      "100 | model.base_model.encoder.layer.5.attention.self.key               | Linear                 | 590 K \n",
      "101 | model.base_model.encoder.layer.5.attention.self.value             | Linear                 | 590 K \n",
      "102 | model.base_model.encoder.layer.5.attention.self.dropout           | Dropout                | 0     \n",
      "103 | model.base_model.encoder.layer.5.attention.output                 | RobertaSelfOutput      | 592 K \n",
      "104 | model.base_model.encoder.layer.5.attention.output.dense           | Linear                 | 590 K \n",
      "105 | model.base_model.encoder.layer.5.attention.output.LayerNorm       | LayerNorm              | 1 K   \n",
      "106 | model.base_model.encoder.layer.5.attention.output.dropout         | Dropout                | 0     \n",
      "107 | model.base_model.encoder.layer.5.intermediate                     | RobertaIntermediate    | 2 M   \n",
      "108 | model.base_model.encoder.layer.5.intermediate.dense               | Linear                 | 2 M   \n",
      "109 | model.base_model.encoder.layer.5.output                           | RobertaOutput          | 2 M   \n",
      "110 | model.base_model.encoder.layer.5.output.dense                     | Linear                 | 2 M   \n",
      "111 | model.base_model.encoder.layer.5.output.LayerNorm                 | LayerNorm              | 1 K   \n",
      "112 | model.base_model.encoder.layer.5.output.dropout                   | Dropout                | 0     \n",
      "113 | model.base_model.encoder.layer.6                                  | RobertaLayer           | 7 M   \n",
      "114 | model.base_model.encoder.layer.6.attention                        | RobertaAttention       | 2 M   \n",
      "115 | model.base_model.encoder.layer.6.attention.self                   | RobertaSelfAttention   | 1 M   \n",
      "116 | model.base_model.encoder.layer.6.attention.self.query             | Linear                 | 590 K \n",
      "117 | model.base_model.encoder.layer.6.attention.self.key               | Linear                 | 590 K \n",
      "118 | model.base_model.encoder.layer.6.attention.self.value             | Linear                 | 590 K \n",
      "119 | model.base_model.encoder.layer.6.attention.self.dropout           | Dropout                | 0     \n",
      "120 | model.base_model.encoder.layer.6.attention.output                 | RobertaSelfOutput      | 592 K \n",
      "121 | model.base_model.encoder.layer.6.attention.output.dense           | Linear                 | 590 K \n",
      "122 | model.base_model.encoder.layer.6.attention.output.LayerNorm       | LayerNorm              | 1 K   \n",
      "123 | model.base_model.encoder.layer.6.attention.output.dropout         | Dropout                | 0     \n",
      "124 | model.base_model.encoder.layer.6.intermediate                     | RobertaIntermediate    | 2 M   \n",
      "125 | model.base_model.encoder.layer.6.intermediate.dense               | Linear                 | 2 M   \n",
      "126 | model.base_model.encoder.layer.6.output                           | RobertaOutput          | 2 M   \n",
      "127 | model.base_model.encoder.layer.6.output.dense                     | Linear                 | 2 M   \n",
      "128 | model.base_model.encoder.layer.6.output.LayerNorm                 | LayerNorm              | 1 K   \n",
      "129 | model.base_model.encoder.layer.6.output.dropout                   | Dropout                | 0     \n",
      "130 | model.base_model.encoder.layer.7                                  | RobertaLayer           | 7 M   \n",
      "131 | model.base_model.encoder.layer.7.attention                        | RobertaAttention       | 2 M   \n",
      "132 | model.base_model.encoder.layer.7.attention.self                   | RobertaSelfAttention   | 1 M   \n",
      "133 | model.base_model.encoder.layer.7.attention.self.query             | Linear                 | 590 K \n",
      "134 | model.base_model.encoder.layer.7.attention.self.key               | Linear                 | 590 K \n",
      "135 | model.base_model.encoder.layer.7.attention.self.value             | Linear                 | 590 K \n",
      "136 | model.base_model.encoder.layer.7.attention.self.dropout           | Dropout                | 0     \n",
      "137 | model.base_model.encoder.layer.7.attention.output                 | RobertaSelfOutput      | 592 K \n",
      "138 | model.base_model.encoder.layer.7.attention.output.dense           | Linear                 | 590 K \n",
      "139 | model.base_model.encoder.layer.7.attention.output.LayerNorm       | LayerNorm              | 1 K   \n",
      "140 | model.base_model.encoder.layer.7.attention.output.dropout         | Dropout                | 0     \n",
      "141 | model.base_model.encoder.layer.7.intermediate                     | RobertaIntermediate    | 2 M   \n",
      "142 | model.base_model.encoder.layer.7.intermediate.dense               | Linear                 | 2 M   \n",
      "143 | model.base_model.encoder.layer.7.output                           | RobertaOutput          | 2 M   \n",
      "144 | model.base_model.encoder.layer.7.output.dense                     | Linear                 | 2 M   \n",
      "145 | model.base_model.encoder.layer.7.output.LayerNorm                 | LayerNorm              | 1 K   \n",
      "146 | model.base_model.encoder.layer.7.output.dropout                   | Dropout                | 0     \n",
      "147 | model.base_model.encoder.layer.8                                  | RobertaLayer           | 7 M   \n",
      "148 | model.base_model.encoder.layer.8.attention                        | RobertaAttention       | 2 M   \n",
      "149 | model.base_model.encoder.layer.8.attention.self                   | RobertaSelfAttention   | 1 M   \n",
      "150 | model.base_model.encoder.layer.8.attention.self.query             | Linear                 | 590 K \n",
      "151 | model.base_model.encoder.layer.8.attention.self.key               | Linear                 | 590 K \n",
      "152 | model.base_model.encoder.layer.8.attention.self.value             | Linear                 | 590 K \n",
      "153 | model.base_model.encoder.layer.8.attention.self.dropout           | Dropout                | 0     \n",
      "154 | model.base_model.encoder.layer.8.attention.output                 | RobertaSelfOutput      | 592 K \n",
      "155 | model.base_model.encoder.layer.8.attention.output.dense           | Linear                 | 590 K \n",
      "156 | model.base_model.encoder.layer.8.attention.output.LayerNorm       | LayerNorm              | 1 K   \n",
      "157 | model.base_model.encoder.layer.8.attention.output.dropout         | Dropout                | 0     \n",
      "158 | model.base_model.encoder.layer.8.intermediate                     | RobertaIntermediate    | 2 M   \n",
      "159 | model.base_model.encoder.layer.8.intermediate.dense               | Linear                 | 2 M   \n",
      "160 | model.base_model.encoder.layer.8.output                           | RobertaOutput          | 2 M   \n",
      "161 | model.base_model.encoder.layer.8.output.dense                     | Linear                 | 2 M   \n",
      "162 | model.base_model.encoder.layer.8.output.LayerNorm                 | LayerNorm              | 1 K   \n",
      "163 | model.base_model.encoder.layer.8.output.dropout                   | Dropout                | 0     \n",
      "164 | model.base_model.encoder.layer.9                                  | RobertaLayer           | 7 M   \n",
      "165 | model.base_model.encoder.layer.9.attention                        | RobertaAttention       | 2 M   \n",
      "166 | model.base_model.encoder.layer.9.attention.self                   | RobertaSelfAttention   | 1 M   \n",
      "167 | model.base_model.encoder.layer.9.attention.self.query             | Linear                 | 590 K \n",
      "168 | model.base_model.encoder.layer.9.attention.self.key               | Linear                 | 590 K \n",
      "169 | model.base_model.encoder.layer.9.attention.self.value             | Linear                 | 590 K \n",
      "170 | model.base_model.encoder.layer.9.attention.self.dropout           | Dropout                | 0     \n",
      "171 | model.base_model.encoder.layer.9.attention.output                 | RobertaSelfOutput      | 592 K \n",
      "172 | model.base_model.encoder.layer.9.attention.output.dense           | Linear                 | 590 K \n",
      "173 | model.base_model.encoder.layer.9.attention.output.LayerNorm       | LayerNorm              | 1 K   \n",
      "174 | model.base_model.encoder.layer.9.attention.output.dropout         | Dropout                | 0     \n",
      "175 | model.base_model.encoder.layer.9.intermediate                     | RobertaIntermediate    | 2 M   \n",
      "176 | model.base_model.encoder.layer.9.intermediate.dense               | Linear                 | 2 M   \n",
      "177 | model.base_model.encoder.layer.9.output                           | RobertaOutput          | 2 M   \n",
      "178 | model.base_model.encoder.layer.9.output.dense                     | Linear                 | 2 M   \n",
      "179 | model.base_model.encoder.layer.9.output.LayerNorm                 | LayerNorm              | 1 K   \n",
      "180 | model.base_model.encoder.layer.9.output.dropout                   | Dropout                | 0     \n",
      "181 | model.base_model.encoder.layer.10                                 | RobertaLayer           | 7 M   \n",
      "182 | model.base_model.encoder.layer.10.attention                       | RobertaAttention       | 2 M   \n",
      "183 | model.base_model.encoder.layer.10.attention.self                  | RobertaSelfAttention   | 1 M   \n",
      "184 | model.base_model.encoder.layer.10.attention.self.query            | Linear                 | 590 K \n",
      "185 | model.base_model.encoder.layer.10.attention.self.key              | Linear                 | 590 K \n",
      "186 | model.base_model.encoder.layer.10.attention.self.value            | Linear                 | 590 K \n",
      "187 | model.base_model.encoder.layer.10.attention.self.dropout          | Dropout                | 0     \n",
      "188 | model.base_model.encoder.layer.10.attention.output                | RobertaSelfOutput      | 592 K \n",
      "189 | model.base_model.encoder.layer.10.attention.output.dense          | Linear                 | 590 K \n",
      "190 | model.base_model.encoder.layer.10.attention.output.LayerNorm      | LayerNorm              | 1 K   \n",
      "191 | model.base_model.encoder.layer.10.attention.output.dropout        | Dropout                | 0     \n",
      "192 | model.base_model.encoder.layer.10.intermediate                    | RobertaIntermediate    | 2 M   \n",
      "193 | model.base_model.encoder.layer.10.intermediate.dense              | Linear                 | 2 M   \n",
      "194 | model.base_model.encoder.layer.10.output                          | RobertaOutput          | 2 M   \n",
      "195 | model.base_model.encoder.layer.10.output.dense                    | Linear                 | 2 M   \n",
      "196 | model.base_model.encoder.layer.10.output.LayerNorm                | LayerNorm              | 1 K   \n",
      "197 | model.base_model.encoder.layer.10.output.dropout                  | Dropout                | 0     \n",
      "198 | model.base_model.encoder.layer.11                                 | RobertaLayer           | 7 M   \n",
      "199 | model.base_model.encoder.layer.11.attention                       | RobertaAttention       | 2 M   \n",
      "200 | model.base_model.encoder.layer.11.attention.self                  | RobertaSelfAttention   | 1 M   \n",
      "201 | model.base_model.encoder.layer.11.attention.self.query            | Linear                 | 590 K \n",
      "202 | model.base_model.encoder.layer.11.attention.self.key              | Linear                 | 590 K \n",
      "203 | model.base_model.encoder.layer.11.attention.self.value            | Linear                 | 590 K \n",
      "204 | model.base_model.encoder.layer.11.attention.self.dropout          | Dropout                | 0     \n",
      "205 | model.base_model.encoder.layer.11.attention.output                | RobertaSelfOutput      | 592 K \n",
      "206 | model.base_model.encoder.layer.11.attention.output.dense          | Linear                 | 590 K \n",
      "207 | model.base_model.encoder.layer.11.attention.output.LayerNorm      | LayerNorm              | 1 K   \n",
      "208 | model.base_model.encoder.layer.11.attention.output.dropout        | Dropout                | 0     \n",
      "209 | model.base_model.encoder.layer.11.intermediate                    | RobertaIntermediate    | 2 M   \n",
      "210 | model.base_model.encoder.layer.11.intermediate.dense              | Linear                 | 2 M   \n",
      "211 | model.base_model.encoder.layer.11.output                          | RobertaOutput          | 2 M   \n",
      "212 | model.base_model.encoder.layer.11.output.dense                    | Linear                 | 2 M   \n",
      "213 | model.base_model.encoder.layer.11.output.LayerNorm                | LayerNorm              | 1 K   \n",
      "214 | model.base_model.encoder.layer.11.output.dropout                  | Dropout                | 0     \n",
      "215 | model.classifier                                                  | Sequential             | 593 K \n",
      "216 | model.classifier.0                                                | Dropout                | 0     \n",
      "217 | model.classifier.1                                                | Linear                 | 590 K \n",
      "218 | model.classifier.2                                                | Mish                   | 0     \n",
      "219 | model.classifier.3                                                | Dropout                | 0     \n",
      "220 | model.classifier.4                                                | Linear                 | 3 K   \n",
      "221 | loss                                                              | CrossEntropyLoss       | 0     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:  96%|█████████▌| 1150/1201 [01:47<00:04, 10.68it/s, loss=0.018, train_loss=0.018, v_num=157]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train (using cuda)\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=hparams.epochs, progress_bar_refresh_rate=50,\n",
    "                     accumulate_grad_batches=hparams.accumulate_grad_batches,\n",
    "                     early_stop_callback=early_stop_callback)\n",
    "\n",
    "trainer.fit(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model (uncomment to save)\n",
    "\n",
    "# module.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "________________________________________________________________________________\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     sadness     0.9916    0.9344    0.9621       503\n",
      "         joy     0.9941    0.9864    0.9903       515\n",
      "       anger     0.9384    0.9767    0.9572       515\n",
      "        fear     0.9478    0.9722    0.9598       467\n",
      "\n",
      "    accuracy                         0.9675      2000\n",
      "   macro avg     0.9680    0.9674    0.9673      2000\n",
      "weighted avg     0.9683    0.9675    0.9676      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    progress = [\"/\", \"-\", \"\\\\\", \"|\", \"/\", \"-\", \"\\\\\", \"|\"]\n",
    "    module.eval().cuda()\n",
    "    true_y, pred_y = [], []\n",
    "    for i, batch_ in enumerate(module.test_dataloader()):\n",
    "        (X, attn), y = batch_\n",
    "        batch = (X.cuda(), attn.cuda())\n",
    "        print(progress[i % len(progress)], end=\"\\r\")\n",
    "        y_pred = torch.argmax(module(batch), dim=1)\n",
    "        true_y.extend(y.cpu())\n",
    "        pred_y.extend(y_pred.cpu())\n",
    "print(\"\\n\" + \"_\" * 80)\n",
    "print(classification_report(true_y, pred_y, target_names=label2int.keys(), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot confusion matrix\n",
    "\n",
    "cm = confusion_matrix(true_y, pred_y, labels=range(len(labels)))\n",
    "df_cm = pd.DataFrame(cm, index = labels, columns = labels)\n",
    "\n",
    "plt.rcParams.update({'font.size': 12}) \n",
    "plt.figure(figsize = (10,8));\n",
    "sn.heatmap(df_cm, annot=True, cmap='Greens', fmt='g');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tune on EmpatheticPersonas data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we define the paths for train, val, test\n",
    "train_path = \"emotion_data/my_train.txt\"\n",
    "test_path = \"emotion_data/my_test.txt\"\n",
    "val_path = \"emotion_data/my_val.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use PyTorch Lighning for training. Lightning methods are defined here\n",
    "\n",
    "class TrainingModule(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.model = EmoClassificationModel(AutoModelWithLMHead.from_pretrained(\"roberta-base\").base_model, len(labels)) #was \"distilroberta-base\"\n",
    "        self.loss = nn.CrossEntropyLoss() #cross entropy loss since this is multi-class classification\n",
    "        self.hparams = hparams\n",
    "\n",
    "    def step(self, batch, step_name=\"train\"):\n",
    "        X, y = batch\n",
    "        loss = self.loss(self.forward(X), y)\n",
    "        loss_key = f\"{step_name}_loss\"\n",
    "        tensorboard_logs = {loss_key: loss}\n",
    "\n",
    "        return { (\"loss\" if step_name == \"train\" else loss_key): loss, 'log': tensorboard_logs,\n",
    "               \"progress_bar\": {loss_key: loss}}\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        return self.model(X, *args)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"train\")\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"val\")\n",
    "\n",
    "    def validation_end(self, outputs: List[dict]):\n",
    "        loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        return {\"val_loss\": loss}\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"test\")\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.train_path, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.val_path)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.test_path)\n",
    "                \n",
    "    def create_data_loader(self, ds_path: str, shuffle=False):\n",
    "        return DataLoader(\n",
    "                    EmoDataset(ds_path),\n",
    "                    batch_size=self.hparams.batch_size,\n",
    "                    shuffle=shuffle,\n",
    "                    collate_fn=TokenizersCollateFn()\n",
    "        )\n",
    "        \n",
    "    @lru_cache()\n",
    "    def total_steps(self):\n",
    "        return len(self.train_dataloader()) // self.hparams.accumulate_grad_batches * self.hparams.epochs\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.model.parameters(), lr=self.hparams.lr) #we use AdamW \n",
    "        lr_scheduler = get_linear_schedule_with_warmup(\n",
    "                    optimizer,\n",
    "                    num_warmup_steps=self.hparams.warmup_steps,\n",
    "                    num_training_steps=self.total_steps(),\n",
    "        )\n",
    "        return [optimizer], [{\"scheduler\": lr_scheduler, \"interval\": \"step\"}]\n",
    "\n",
    "    def save_model(self):\n",
    "        torch.save(self.model.state_dict(), 'emotion_model/RoBERTa_emotion_2ft_2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = Namespace(\n",
    "    train_path=train_path,\n",
    "    val_path=val_path,\n",
    "    test_path=test_path,\n",
    "    batch_size=15,\n",
    "    warmup_steps=100,\n",
    "    epochs=20,\n",
    "    lr=2E-05,\n",
    "    accumulate_grad_batches=1\n",
    ")\n",
    "module = TrainingModule(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingModule(\n",
       "  (model): EmoClassificationModel(\n",
       "    (base_model): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): Sequential(\n",
       "      (0): Dropout(p=0.05, inplace=False)\n",
       "      (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (2): Mish()\n",
       "      (3): Dropout(p=0.05, inplace=False)\n",
       "      (4): Linear(in_features=768, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (loss): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "module.model.load_state_dict(torch.load('emotion_model/RoBERTa_emotion_2ft.pt'))\n",
    "module.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rubbish collection\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",  # monitor validation loss\n",
    "    min_delta=0.001, #to very small change in the monitored quantity to qualify as an improvement\n",
    "    patience=20, # used to check number of time with no improvement after which training will be stopped\n",
    "    verbose=False, \n",
    "    mode=\"min\" #sed while training will stopped when the quantity monitor has stopped decreasing\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:GPU available: True, used: True\n",
      "INFO:lightning:CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\yisiang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:23: RuntimeWarning: You have defined a `val_dataloader()` and have defined a `validation_step()`, you may also want to define `validation_epoch_end()` for accumulating stats.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\yisiang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:23: RuntimeWarning: You have defined a `test_dataloader()` and have defined a `test_step()`, you may also want to define `test_epoch_end()` for accumulating stats.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\yisiang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "INFO:lightning:\n",
      "    | Name                                                              | Type                   | Params\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "0   | model                                                             | EmoClassificationModel | 124 M \n",
      "1   | model.base_model                                                  | RobertaModel           | 124 M \n",
      "2   | model.base_model.embeddings                                       | RobertaEmbeddings      | 39 M  \n",
      "3   | model.base_model.embeddings.word_embeddings                       | Embedding              | 38 M  \n",
      "4   | model.base_model.embeddings.position_embeddings                   | Embedding              | 394 K \n",
      "5   | model.base_model.embeddings.token_type_embeddings                 | Embedding              | 768   \n",
      "6   | model.base_model.embeddings.LayerNorm                             | LayerNorm              | 1 K   \n",
      "7   | model.base_model.embeddings.dropout                               | Dropout                | 0     \n",
      "8   | model.base_model.encoder                                          | RobertaEncoder         | 85 M  \n",
      "9   | model.base_model.encoder.layer                                    | ModuleList             | 85 M  \n",
      "10  | model.base_model.encoder.layer.0                                  | RobertaLayer           | 7 M   \n",
      "11  | model.base_model.encoder.layer.0.attention                        | RobertaAttention       | 2 M   \n",
      "12  | model.base_model.encoder.layer.0.attention.self                   | RobertaSelfAttention   | 1 M   \n",
      "13  | model.base_model.encoder.layer.0.attention.self.query             | Linear                 | 590 K \n",
      "14  | model.base_model.encoder.layer.0.attention.self.key               | Linear                 | 590 K \n",
      "15  | model.base_model.encoder.layer.0.attention.self.value             | Linear                 | 590 K \n",
      "16  | model.base_model.encoder.layer.0.attention.self.dropout           | Dropout                | 0     \n",
      "17  | model.base_model.encoder.layer.0.attention.output                 | RobertaSelfOutput      | 592 K \n",
      "18  | model.base_model.encoder.layer.0.attention.output.dense           | Linear                 | 590 K \n",
      "19  | model.base_model.encoder.layer.0.attention.output.LayerNorm       | LayerNorm              | 1 K   \n",
      "20  | model.base_model.encoder.layer.0.attention.output.dropout         | Dropout                | 0     \n",
      "21  | model.base_model.encoder.layer.0.intermediate                     | RobertaIntermediate    | 2 M   \n",
      "22  | model.base_model.encoder.layer.0.intermediate.dense               | Linear                 | 2 M   \n",
      "23  | model.base_model.encoder.layer.0.intermediate.intermediate_act_fn | GELUActivation         | 0     \n",
      "24  | model.base_model.encoder.layer.0.output                           | RobertaOutput          | 2 M   \n",
      "25  | model.base_model.encoder.layer.0.output.dense                     | Linear                 | 2 M   \n",
      "26  | model.base_model.encoder.layer.0.output.LayerNorm                 | LayerNorm              | 1 K   \n",
      "27  | model.base_model.encoder.layer.0.output.dropout                   | Dropout                | 0     \n",
      "28  | model.base_model.encoder.layer.1                                  | RobertaLayer           | 7 M   \n",
      "29  | model.base_model.encoder.layer.1.attention                        | RobertaAttention       | 2 M   \n",
      "30  | model.base_model.encoder.layer.1.attention.self                   | RobertaSelfAttention   | 1 M   \n",
      "31  | model.base_model.encoder.layer.1.attention.self.query             | Linear                 | 590 K \n",
      "32  | model.base_model.encoder.layer.1.attention.self.key               | Linear                 | 590 K \n",
      "33  | model.base_model.encoder.layer.1.attention.self.value             | Linear                 | 590 K \n",
      "34  | model.base_model.encoder.layer.1.attention.self.dropout           | Dropout                | 0     \n",
      "35  | model.base_model.encoder.layer.1.attention.output                 | RobertaSelfOutput      | 592 K \n",
      "36  | model.base_model.encoder.layer.1.attention.output.dense           | Linear                 | 590 K \n",
      "37  | model.base_model.encoder.layer.1.attention.output.LayerNorm       | LayerNorm              | 1 K   \n",
      "38  | model.base_model.encoder.layer.1.attention.output.dropout         | Dropout                | 0     \n",
      "39  | model.base_model.encoder.layer.1.intermediate                     | RobertaIntermediate    | 2 M   \n",
      "40  | model.base_model.encoder.layer.1.intermediate.dense               | Linear                 | 2 M   \n",
      "41  | model.base_model.encoder.layer.1.output                           | RobertaOutput          | 2 M   \n",
      "42  | model.base_model.encoder.layer.1.output.dense                     | Linear                 | 2 M   \n",
      "43  | model.base_model.encoder.layer.1.output.LayerNorm                 | LayerNorm              | 1 K   \n",
      "44  | model.base_model.encoder.layer.1.output.dropout                   | Dropout                | 0     \n",
      "45  | model.base_model.encoder.layer.2                                  | RobertaLayer           | 7 M   \n",
      "46  | model.base_model.encoder.layer.2.attention                        | RobertaAttention       | 2 M   \n",
      "47  | model.base_model.encoder.layer.2.attention.self                   | RobertaSelfAttention   | 1 M   \n",
      "48  | model.base_model.encoder.layer.2.attention.self.query             | Linear                 | 590 K \n",
      "49  | model.base_model.encoder.layer.2.attention.self.key               | Linear                 | 590 K \n",
      "50  | model.base_model.encoder.layer.2.attention.self.value             | Linear                 | 590 K \n",
      "51  | model.base_model.encoder.layer.2.attention.self.dropout           | Dropout                | 0     \n",
      "52  | model.base_model.encoder.layer.2.attention.output                 | RobertaSelfOutput      | 592 K \n",
      "53  | model.base_model.encoder.layer.2.attention.output.dense           | Linear                 | 590 K \n",
      "54  | model.base_model.encoder.layer.2.attention.output.LayerNorm       | LayerNorm              | 1 K   \n",
      "55  | model.base_model.encoder.layer.2.attention.output.dropout         | Dropout                | 0     \n",
      "56  | model.base_model.encoder.layer.2.intermediate                     | RobertaIntermediate    | 2 M   \n",
      "57  | model.base_model.encoder.layer.2.intermediate.dense               | Linear                 | 2 M   \n",
      "58  | model.base_model.encoder.layer.2.output                           | RobertaOutput          | 2 M   \n",
      "59  | model.base_model.encoder.layer.2.output.dense                     | Linear                 | 2 M   \n",
      "60  | model.base_model.encoder.layer.2.output.LayerNorm                 | LayerNorm              | 1 K   \n",
      "61  | model.base_model.encoder.layer.2.output.dropout                   | Dropout                | 0     \n",
      "62  | model.base_model.encoder.layer.3                                  | RobertaLayer           | 7 M   \n",
      "63  | model.base_model.encoder.layer.3.attention                        | RobertaAttention       | 2 M   \n",
      "64  | model.base_model.encoder.layer.3.attention.self                   | RobertaSelfAttention   | 1 M   \n",
      "65  | model.base_model.encoder.layer.3.attention.self.query             | Linear                 | 590 K \n",
      "66  | model.base_model.encoder.layer.3.attention.self.key               | Linear                 | 590 K \n",
      "67  | model.base_model.encoder.layer.3.attention.self.value             | Linear                 | 590 K \n",
      "68  | model.base_model.encoder.layer.3.attention.self.dropout           | Dropout                | 0     \n",
      "69  | model.base_model.encoder.layer.3.attention.output                 | RobertaSelfOutput      | 592 K \n",
      "70  | model.base_model.encoder.layer.3.attention.output.dense           | Linear                 | 590 K \n",
      "71  | model.base_model.encoder.layer.3.attention.output.LayerNorm       | LayerNorm              | 1 K   \n",
      "72  | model.base_model.encoder.layer.3.attention.output.dropout         | Dropout                | 0     \n",
      "73  | model.base_model.encoder.layer.3.intermediate                     | RobertaIntermediate    | 2 M   \n",
      "74  | model.base_model.encoder.layer.3.intermediate.dense               | Linear                 | 2 M   \n",
      "75  | model.base_model.encoder.layer.3.output                           | RobertaOutput          | 2 M   \n",
      "76  | model.base_model.encoder.layer.3.output.dense                     | Linear                 | 2 M   \n",
      "77  | model.base_model.encoder.layer.3.output.LayerNorm                 | LayerNorm              | 1 K   \n",
      "78  | model.base_model.encoder.layer.3.output.dropout                   | Dropout                | 0     \n",
      "79  | model.base_model.encoder.layer.4                                  | RobertaLayer           | 7 M   \n",
      "80  | model.base_model.encoder.layer.4.attention                        | RobertaAttention       | 2 M   \n",
      "81  | model.base_model.encoder.layer.4.attention.self                   | RobertaSelfAttention   | 1 M   \n",
      "82  | model.base_model.encoder.layer.4.attention.self.query             | Linear                 | 590 K \n",
      "83  | model.base_model.encoder.layer.4.attention.self.key               | Linear                 | 590 K \n",
      "84  | model.base_model.encoder.layer.4.attention.self.value             | Linear                 | 590 K \n",
      "85  | model.base_model.encoder.layer.4.attention.self.dropout           | Dropout                | 0     \n",
      "86  | model.base_model.encoder.layer.4.attention.output                 | RobertaSelfOutput      | 592 K \n",
      "87  | model.base_model.encoder.layer.4.attention.output.dense           | Linear                 | 590 K \n",
      "88  | model.base_model.encoder.layer.4.attention.output.LayerNorm       | LayerNorm              | 1 K   \n",
      "89  | model.base_model.encoder.layer.4.attention.output.dropout         | Dropout                | 0     \n",
      "90  | model.base_model.encoder.layer.4.intermediate                     | RobertaIntermediate    | 2 M   \n",
      "91  | model.base_model.encoder.layer.4.intermediate.dense               | Linear                 | 2 M   \n",
      "92  | model.base_model.encoder.layer.4.output                           | RobertaOutput          | 2 M   \n",
      "93  | model.base_model.encoder.layer.4.output.dense                     | Linear                 | 2 M   \n",
      "94  | model.base_model.encoder.layer.4.output.LayerNorm                 | LayerNorm              | 1 K   \n",
      "95  | model.base_model.encoder.layer.4.output.dropout                   | Dropout                | 0     \n",
      "96  | model.base_model.encoder.layer.5                                  | RobertaLayer           | 7 M   \n",
      "97  | model.base_model.encoder.layer.5.attention                        | RobertaAttention       | 2 M   \n",
      "98  | model.base_model.encoder.layer.5.attention.self                   | RobertaSelfAttention   | 1 M   \n",
      "99  | model.base_model.encoder.layer.5.attention.self.query             | Linear                 | 590 K \n",
      "100 | model.base_model.encoder.layer.5.attention.self.key               | Linear                 | 590 K \n",
      "101 | model.base_model.encoder.layer.5.attention.self.value             | Linear                 | 590 K \n",
      "102 | model.base_model.encoder.layer.5.attention.self.dropout           | Dropout                | 0     \n",
      "103 | model.base_model.encoder.layer.5.attention.output                 | RobertaSelfOutput      | 592 K \n",
      "104 | model.base_model.encoder.layer.5.attention.output.dense           | Linear                 | 590 K \n",
      "105 | model.base_model.encoder.layer.5.attention.output.LayerNorm       | LayerNorm              | 1 K   \n",
      "106 | model.base_model.encoder.layer.5.attention.output.dropout         | Dropout                | 0     \n",
      "107 | model.base_model.encoder.layer.5.intermediate                     | RobertaIntermediate    | 2 M   \n",
      "108 | model.base_model.encoder.layer.5.intermediate.dense               | Linear                 | 2 M   \n",
      "109 | model.base_model.encoder.layer.5.output                           | RobertaOutput          | 2 M   \n",
      "110 | model.base_model.encoder.layer.5.output.dense                     | Linear                 | 2 M   \n",
      "111 | model.base_model.encoder.layer.5.output.LayerNorm                 | LayerNorm              | 1 K   \n",
      "112 | model.base_model.encoder.layer.5.output.dropout                   | Dropout                | 0     \n",
      "113 | model.base_model.encoder.layer.6                                  | RobertaLayer           | 7 M   \n",
      "114 | model.base_model.encoder.layer.6.attention                        | RobertaAttention       | 2 M   \n",
      "115 | model.base_model.encoder.layer.6.attention.self                   | RobertaSelfAttention   | 1 M   \n",
      "116 | model.base_model.encoder.layer.6.attention.self.query             | Linear                 | 590 K \n",
      "117 | model.base_model.encoder.layer.6.attention.self.key               | Linear                 | 590 K \n",
      "118 | model.base_model.encoder.layer.6.attention.self.value             | Linear                 | 590 K \n",
      "119 | model.base_model.encoder.layer.6.attention.self.dropout           | Dropout                | 0     \n",
      "120 | model.base_model.encoder.layer.6.attention.output                 | RobertaSelfOutput      | 592 K \n",
      "121 | model.base_model.encoder.layer.6.attention.output.dense           | Linear                 | 590 K \n",
      "122 | model.base_model.encoder.layer.6.attention.output.LayerNorm       | LayerNorm              | 1 K   \n",
      "123 | model.base_model.encoder.layer.6.attention.output.dropout         | Dropout                | 0     \n",
      "124 | model.base_model.encoder.layer.6.intermediate                     | RobertaIntermediate    | 2 M   \n",
      "125 | model.base_model.encoder.layer.6.intermediate.dense               | Linear                 | 2 M   \n",
      "126 | model.base_model.encoder.layer.6.output                           | RobertaOutput          | 2 M   \n",
      "127 | model.base_model.encoder.layer.6.output.dense                     | Linear                 | 2 M   \n",
      "128 | model.base_model.encoder.layer.6.output.LayerNorm                 | LayerNorm              | 1 K   \n",
      "129 | model.base_model.encoder.layer.6.output.dropout                   | Dropout                | 0     \n",
      "130 | model.base_model.encoder.layer.7                                  | RobertaLayer           | 7 M   \n",
      "131 | model.base_model.encoder.layer.7.attention                        | RobertaAttention       | 2 M   \n",
      "132 | model.base_model.encoder.layer.7.attention.self                   | RobertaSelfAttention   | 1 M   \n",
      "133 | model.base_model.encoder.layer.7.attention.self.query             | Linear                 | 590 K \n",
      "134 | model.base_model.encoder.layer.7.attention.self.key               | Linear                 | 590 K \n",
      "135 | model.base_model.encoder.layer.7.attention.self.value             | Linear                 | 590 K \n",
      "136 | model.base_model.encoder.layer.7.attention.self.dropout           | Dropout                | 0     \n",
      "137 | model.base_model.encoder.layer.7.attention.output                 | RobertaSelfOutput      | 592 K \n",
      "138 | model.base_model.encoder.layer.7.attention.output.dense           | Linear                 | 590 K \n",
      "139 | model.base_model.encoder.layer.7.attention.output.LayerNorm       | LayerNorm              | 1 K   \n",
      "140 | model.base_model.encoder.layer.7.attention.output.dropout         | Dropout                | 0     \n",
      "141 | model.base_model.encoder.layer.7.intermediate                     | RobertaIntermediate    | 2 M   \n",
      "142 | model.base_model.encoder.layer.7.intermediate.dense               | Linear                 | 2 M   \n",
      "143 | model.base_model.encoder.layer.7.output                           | RobertaOutput          | 2 M   \n",
      "144 | model.base_model.encoder.layer.7.output.dense                     | Linear                 | 2 M   \n",
      "145 | model.base_model.encoder.layer.7.output.LayerNorm                 | LayerNorm              | 1 K   \n",
      "146 | model.base_model.encoder.layer.7.output.dropout                   | Dropout                | 0     \n",
      "147 | model.base_model.encoder.layer.8                                  | RobertaLayer           | 7 M   \n",
      "148 | model.base_model.encoder.layer.8.attention                        | RobertaAttention       | 2 M   \n",
      "149 | model.base_model.encoder.layer.8.attention.self                   | RobertaSelfAttention   | 1 M   \n",
      "150 | model.base_model.encoder.layer.8.attention.self.query             | Linear                 | 590 K \n",
      "151 | model.base_model.encoder.layer.8.attention.self.key               | Linear                 | 590 K \n",
      "152 | model.base_model.encoder.layer.8.attention.self.value             | Linear                 | 590 K \n",
      "153 | model.base_model.encoder.layer.8.attention.self.dropout           | Dropout                | 0     \n",
      "154 | model.base_model.encoder.layer.8.attention.output                 | RobertaSelfOutput      | 592 K \n",
      "155 | model.base_model.encoder.layer.8.attention.output.dense           | Linear                 | 590 K \n",
      "156 | model.base_model.encoder.layer.8.attention.output.LayerNorm       | LayerNorm              | 1 K   \n",
      "157 | model.base_model.encoder.layer.8.attention.output.dropout         | Dropout                | 0     \n",
      "158 | model.base_model.encoder.layer.8.intermediate                     | RobertaIntermediate    | 2 M   \n",
      "159 | model.base_model.encoder.layer.8.intermediate.dense               | Linear                 | 2 M   \n",
      "160 | model.base_model.encoder.layer.8.output                           | RobertaOutput          | 2 M   \n",
      "161 | model.base_model.encoder.layer.8.output.dense                     | Linear                 | 2 M   \n",
      "162 | model.base_model.encoder.layer.8.output.LayerNorm                 | LayerNorm              | 1 K   \n",
      "163 | model.base_model.encoder.layer.8.output.dropout                   | Dropout                | 0     \n",
      "164 | model.base_model.encoder.layer.9                                  | RobertaLayer           | 7 M   \n",
      "165 | model.base_model.encoder.layer.9.attention                        | RobertaAttention       | 2 M   \n",
      "166 | model.base_model.encoder.layer.9.attention.self                   | RobertaSelfAttention   | 1 M   \n",
      "167 | model.base_model.encoder.layer.9.attention.self.query             | Linear                 | 590 K \n",
      "168 | model.base_model.encoder.layer.9.attention.self.key               | Linear                 | 590 K \n",
      "169 | model.base_model.encoder.layer.9.attention.self.value             | Linear                 | 590 K \n",
      "170 | model.base_model.encoder.layer.9.attention.self.dropout           | Dropout                | 0     \n",
      "171 | model.base_model.encoder.layer.9.attention.output                 | RobertaSelfOutput      | 592 K \n",
      "172 | model.base_model.encoder.layer.9.attention.output.dense           | Linear                 | 590 K \n",
      "173 | model.base_model.encoder.layer.9.attention.output.LayerNorm       | LayerNorm              | 1 K   \n",
      "174 | model.base_model.encoder.layer.9.attention.output.dropout         | Dropout                | 0     \n",
      "175 | model.base_model.encoder.layer.9.intermediate                     | RobertaIntermediate    | 2 M   \n",
      "176 | model.base_model.encoder.layer.9.intermediate.dense               | Linear                 | 2 M   \n",
      "177 | model.base_model.encoder.layer.9.output                           | RobertaOutput          | 2 M   \n",
      "178 | model.base_model.encoder.layer.9.output.dense                     | Linear                 | 2 M   \n",
      "179 | model.base_model.encoder.layer.9.output.LayerNorm                 | LayerNorm              | 1 K   \n",
      "180 | model.base_model.encoder.layer.9.output.dropout                   | Dropout                | 0     \n",
      "181 | model.base_model.encoder.layer.10                                 | RobertaLayer           | 7 M   \n",
      "182 | model.base_model.encoder.layer.10.attention                       | RobertaAttention       | 2 M   \n",
      "183 | model.base_model.encoder.layer.10.attention.self                  | RobertaSelfAttention   | 1 M   \n",
      "184 | model.base_model.encoder.layer.10.attention.self.query            | Linear                 | 590 K \n",
      "185 | model.base_model.encoder.layer.10.attention.self.key              | Linear                 | 590 K \n",
      "186 | model.base_model.encoder.layer.10.attention.self.value            | Linear                 | 590 K \n",
      "187 | model.base_model.encoder.layer.10.attention.self.dropout          | Dropout                | 0     \n",
      "188 | model.base_model.encoder.layer.10.attention.output                | RobertaSelfOutput      | 592 K \n",
      "189 | model.base_model.encoder.layer.10.attention.output.dense          | Linear                 | 590 K \n",
      "190 | model.base_model.encoder.layer.10.attention.output.LayerNorm      | LayerNorm              | 1 K   \n",
      "191 | model.base_model.encoder.layer.10.attention.output.dropout        | Dropout                | 0     \n",
      "192 | model.base_model.encoder.layer.10.intermediate                    | RobertaIntermediate    | 2 M   \n",
      "193 | model.base_model.encoder.layer.10.intermediate.dense              | Linear                 | 2 M   \n",
      "194 | model.base_model.encoder.layer.10.output                          | RobertaOutput          | 2 M   \n",
      "195 | model.base_model.encoder.layer.10.output.dense                    | Linear                 | 2 M   \n",
      "196 | model.base_model.encoder.layer.10.output.LayerNorm                | LayerNorm              | 1 K   \n",
      "197 | model.base_model.encoder.layer.10.output.dropout                  | Dropout                | 0     \n",
      "198 | model.base_model.encoder.layer.11                                 | RobertaLayer           | 7 M   \n",
      "199 | model.base_model.encoder.layer.11.attention                       | RobertaAttention       | 2 M   \n",
      "200 | model.base_model.encoder.layer.11.attention.self                  | RobertaSelfAttention   | 1 M   \n",
      "201 | model.base_model.encoder.layer.11.attention.self.query            | Linear                 | 590 K \n",
      "202 | model.base_model.encoder.layer.11.attention.self.key              | Linear                 | 590 K \n",
      "203 | model.base_model.encoder.layer.11.attention.self.value            | Linear                 | 590 K \n",
      "204 | model.base_model.encoder.layer.11.attention.self.dropout          | Dropout                | 0     \n",
      "205 | model.base_model.encoder.layer.11.attention.output                | RobertaSelfOutput      | 592 K \n",
      "206 | model.base_model.encoder.layer.11.attention.output.dense          | Linear                 | 590 K \n",
      "207 | model.base_model.encoder.layer.11.attention.output.LayerNorm      | LayerNorm              | 1 K   \n",
      "208 | model.base_model.encoder.layer.11.attention.output.dropout        | Dropout                | 0     \n",
      "209 | model.base_model.encoder.layer.11.intermediate                    | RobertaIntermediate    | 2 M   \n",
      "210 | model.base_model.encoder.layer.11.intermediate.dense              | Linear                 | 2 M   \n",
      "211 | model.base_model.encoder.layer.11.output                          | RobertaOutput          | 2 M   \n",
      "212 | model.base_model.encoder.layer.11.output.dense                    | Linear                 | 2 M   \n",
      "213 | model.base_model.encoder.layer.11.output.LayerNorm                | LayerNorm              | 1 K   \n",
      "214 | model.base_model.encoder.layer.11.output.dropout                  | Dropout                | 0     \n",
      "215 | model.classifier                                                  | Sequential             | 593 K \n",
      "216 | model.classifier.0                                                | Dropout                | 0     \n",
      "217 | model.classifier.1                                                | Linear                 | 590 K \n",
      "218 | model.classifier.2                                                | Mish                   | 0     \n",
      "219 | model.classifier.3                                                | Dropout                | 0     \n",
      "220 | model.classifier.4                                                | Linear                 | 3 K   \n",
      "221 | loss                                                              | CrossEntropyLoss       | 0     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:  85%|████████▍ | 60/71 [00:04<00:00, 12.07it/s, loss=0.036, train_loss=0.00421, v_num=161]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=hparams.epochs, progress_bar_refresh_rate=10,\n",
    "                     accumulate_grad_batches=hparams.accumulate_grad_batches,\n",
    "                     early_stop_callback=early_stop_callback)\n",
    "\n",
    "trainer.fit(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model (uncomment to save)\n",
    "\n",
    "# module.save_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on the EmpatheticPersonas test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\n",
      "________________________________________________________________________________\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     sadness     0.8846    0.8846    0.8846        26\n",
      "         joy     0.9697    0.9697    0.9697        33\n",
      "       anger     0.9714    0.9714    0.9714        35\n",
      "        fear     0.9200    0.9200    0.9200        25\n",
      "\n",
      "    accuracy                         0.9412       119\n",
      "   macro avg     0.9364    0.9364    0.9364       119\n",
      "weighted avg     0.9412    0.9412    0.9412       119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    progress = [\"/\", \"-\", \"\\\\\", \"|\", \"/\", \"-\", \"\\\\\", \"|\"]\n",
    "    module.eval().cuda()\n",
    "    true_y, pred_y = [], []\n",
    "    for i, batch_ in enumerate(module.test_dataloader()):\n",
    "        (X, attn), y = batch_\n",
    "        batch = (X.cuda(), attn.cuda())\n",
    "        print(progress[i % len(progress)], end=\"\\r\")\n",
    "        y_pred = torch.argmax(module(batch), dim=1)\n",
    "        true_y.extend(y.cpu())\n",
    "        pred_y.extend(y_pred.cpu())\n",
    "print(\"\\n\" + \"_\" * 80)\n",
    "print(classification_report(true_y, pred_y, target_names=label2int.keys(), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot confusion matrix\n",
    "\n",
    "cm = confusion_matrix(true_y, pred_y, labels=range(len(labels)))\n",
    "df_cm = pd.DataFrame(cm, index = labels, columns = labels)\n",
    "\n",
    "plt.rcParams.update({'font.size': 12}) \n",
    "plt.figure(figsize = (10,8));\n",
    "sn.heatmap(df_cm, annot=True, cmap='Greens', fmt='g');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54bb103c3e8827112ac287ff09b16e5ca2d85540a3af0b288083619c88e41aa7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
