{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#package imports \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "from transformers import DistilBertTokenizer, AutoTokenizer, AutoModelWithLMHead, DistilBertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "\n",
    "from typing import List\n",
    "import logging\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "from functools import lru_cache\n",
    "from argparse import Namespace\n",
    "from packaging import version\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This notebook is partly adapted from Saravia et al.'s Emotion dataset notebook which is\n",
    "#available at this link: https://colab.research.google.com/drive/1nwCE6b9PXIKhv2hvbqf1oZKIGkXMTi1X#scrollTo=t23zHggkEpc-\n",
    "\n",
    "#In fact, we use the Emotion dataset by Saravia et al. for the first finetuning step. Full citation below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_CITATION = \"\"\"\\\n",
    "@inproceedings{saravia-etal-2018-carer,\n",
    "    title = \"{CARER}: Contextualized Affect Representations for Emotion Recognition\",\n",
    "    author = \"Saravia, Elvis  and\n",
    "      Liu, Hsien-Chi Toby  and\n",
    "      Huang, Yen-Hao  and\n",
    "      Wu, Junlin  and\n",
    "      Chen, Yi-Shin\",\n",
    "    booktitle = \"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing\",\n",
    "    month = oct # \"-\" # nov,\n",
    "    year = \"2018\",\n",
    "    address = \"Brussels, Belgium\",\n",
    "    publisher = \"Association for Computational Linguistics\",\n",
    "    url = \"https://www.aclweb.org/anthology/D18-1404\",\n",
    "    doi = \"10.18653/v1/D18-1404\",\n",
    "    pages = \"3687--3697\"\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"emotion_data/my_train.txt\"\n",
    "test_path = \"emotion_data/my_test.txt\"\n",
    "val_path = \"emotion_data/my_val.txt\"\n",
    "\n",
    "#create a dictionary associating each string label to an integer value\n",
    "\n",
    "labels = [ \"sadness\", \"joy\", \"anger\", \"fear\"]\n",
    "label2int = dict(zip(labels, list(range(len(labels)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yisiang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:998: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#we use RoBERTa base\n",
    "\n",
    "#load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "#load actual model\n",
    "model = AutoModelWithLMHead.from_pretrained('roberta-base')\n",
    "base_model = model.base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Mish activation function \n",
    "#(from https://github.com/digantamisra98/Mish/blob/b5f006660ac0b4c46e2c6958ad0301d7f9c59651/Mish/Torch/mish.py)\n",
    "@torch.jit.script\n",
    "def mish(input):\n",
    "    return input * torch.tanh(F.softplus(input))\n",
    "  \n",
    "class Mish(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return mish(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note: the following code is partly adapted from Marcin Zablocki's tutorial 'custom classifier on top of bert-like language model'\n",
    "#define an EmoClassificationModel class to do the actual fine-tuning\n",
    "\n",
    "class EmoClassificationModel(nn.Module):\n",
    "    def __init__(self, base_model, n_classes, base_model_output_size=768, dropout=0.05):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(base_model_output_size, base_model_output_size),\n",
    "            Mish(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(base_model_output_size, n_classes)\n",
    "        )\n",
    "        \n",
    "        for layer in self.classifier:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                layer.weight.data.normal_(mean=0.0, std=0.02)\n",
    "                if layer.bias is not None:\n",
    "                    layer.bias.data.zero_()\n",
    "\n",
    "    def forward(self, input_, *args):\n",
    "        X, attention_mask = input_\n",
    "        hidden_states = self.base_model(X, attention_mask=attention_mask)\n",
    "        \n",
    "        return self.classifier(hidden_states[0][:, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tokenizer\\\\tokenizer_config.json',\n",
       " 'tokenizer\\\\special_tokens_map.json',\n",
       " 'tokenizer\\\\vocab.json',\n",
       " 'tokenizer\\\\merges.txt',\n",
       " 'tokenizer\\\\added_tokens.json',\n",
       " 'tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load pretrained tokenizer information\n",
    "tokenizer.save_pretrained(\"tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementation of CollateFN to do tokenization and batches of sequences\n",
    "\n",
    "class TokenizersCollateFn:\n",
    "    def __init__(self, max_tokens=512): \n",
    "\n",
    "        #RoBERTa uses the BPE tokenizer, similarly to GPT-2\n",
    "        t = ByteLevelBPETokenizer(\n",
    "            \"tokenizer/vocab.json\",\n",
    "            \"tokenizer/merges.txt\"\n",
    "        )\n",
    "        t._tokenizer.post_processor = BertProcessing(\n",
    "            (\"</s>\", t.token_to_id(\"</s>\")),\n",
    "            (\"<s>\", t.token_to_id(\"<s>\")),\n",
    "        )\n",
    "        t.enable_truncation(max_tokens)\n",
    "        t.enable_padding(pad_id=t.token_to_id(\"<pad>\"))\n",
    "        self.tokenizer = t\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        encoded = self.tokenizer.encode_batch([x[0] for x in batch])\n",
    "        sequences_padded = torch.tensor([enc.ids for enc in encoded])\n",
    "        attention_masks_padded = torch.tensor([enc.attention_mask for enc in encoded])\n",
    "        labels = torch.tensor([x[1] for x in batch])\n",
    "        \n",
    "        return (sequences_padded, attention_masks_padded), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class to create dataset objects from the data\n",
    "\n",
    "class EmoDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        super().__init__()\n",
    "        self.data_column = \"text\"\n",
    "        self.class_column = \"class\"\n",
    "        self.data = pd.read_csv(path, sep=\";\", header=None, names=[self.data_column, self.class_column],\n",
    "                               engine=\"python\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data.loc[idx, self.data_column], label2int[self.data.loc[idx, self.class_column]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('i am feeling somewhat afraid as all the rioting in the city makes me anxious that something will happen to me or i wont be able to get food and essential items',\n",
       " 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check, visualise one sample and label (converted to numerical)\n",
    "ds = EmoDataset(train_path)\n",
    "ds[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use PyTorch Lighning for training. Lightning methods are defined here\n",
    "\n",
    "class TrainingModule(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.model = EmoClassificationModel(AutoModelWithLMHead.from_pretrained(\"roberta-base\").base_model, len(labels)) #was \"distilroberta-base\"\n",
    "        self.loss = nn.CrossEntropyLoss() #cross entropy loss since this is multi-class classification\n",
    "        # self.save_hyperparameters(hparams)\n",
    "        self.hparams = hparams\n",
    "\n",
    "    def step(self, batch, step_name=\"train\"):\n",
    "        X, y = batch\n",
    "        loss = self.loss(self.forward(X), y)\n",
    "        loss_key = f\"{step_name}_loss\"\n",
    "        tensorboard_logs = {loss_key: loss}\n",
    "\n",
    "        return { (\"loss\" if step_name == \"train\" else loss_key): loss, 'log': tensorboard_logs,\n",
    "               \"progress_bar\": {loss_key: loss}}\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        return self.model(X, *args)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"train\")\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"val\")\n",
    "\n",
    "    def validation_end(self, outputs: List[dict]):\n",
    "        loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        return {\"val_loss\": loss}\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"test\")\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.train_path, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.val_path)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.test_path)\n",
    "                \n",
    "    def create_data_loader(self, ds_path: str, shuffle=False):\n",
    "        return DataLoader(\n",
    "                    EmoDataset(ds_path),\n",
    "                    batch_size=self.hparams.batch_size,\n",
    "                    shuffle=shuffle,\n",
    "                    collate_fn=TokenizersCollateFn()\n",
    "        )\n",
    "        \n",
    "    @lru_cache()\n",
    "    def total_steps(self):\n",
    "        return len(self.train_dataloader()) // self.hparams.accumulate_grad_batches * self.hparams.epochs\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.model.parameters(), lr=self.hparams.lr) #we use AdamW as this usually performs well\n",
    "        lr_scheduler = get_linear_schedule_with_warmup(\n",
    "                    optimizer,\n",
    "                    num_warmup_steps=self.hparams.warmup_steps,\n",
    "                    num_training_steps=self.total_steps(),\n",
    "        )\n",
    "        return [optimizer], [{\"scheduler\": lr_scheduler, \"interval\": \"step\"}]\n",
    "   \n",
    "    def save_model(self):\n",
    "        torch.save(self.model.state_dict(), 'emotion_model/RoBERTa_emotion_1ft.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = Namespace(\n",
    "    train_path=train_path,\n",
    "    val_path=val_path,\n",
    "    test_path=test_path,\n",
    "    batch_size=20,\n",
    "    warmup_steps=100,\n",
    "    epochs=20,\n",
    "    lr=2E-06,\n",
    "    accumulate_grad_batches=1\n",
    ")\n",
    "module = TrainingModule(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rubbish collection\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",  # monitor validation loss\n",
    "    min_delta=0.001, #to very small change in the monitored quantity to qualify as an improvement\n",
    "    patience=10, # used to check number of time with no improvement after which training will be stopped\n",
    "    verbose=False, \n",
    "    mode=\"min\" #sed while training will stopped when the quantity monitor has stopped decreasing\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:GPU available: True, used: True\n",
      "INFO:lightning:CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\yisiang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:23: RuntimeWarning: You have defined a `val_dataloader()` and have defined a `validation_step()`, you may also want to define `validation_epoch_end()` for accumulating stats.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\yisiang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:23: RuntimeWarning: You have defined a `test_dataloader()` and have defined a `test_step()`, you may also want to define `test_epoch_end()` for accumulating stats.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\yisiang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "INFO:lightning:\n",
      "    | Name                                                              | Type                   | Params\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "0   | model                                                             | EmoClassificationModel | 124 M \n",
      "1   | model.base_model                                                  | RobertaModel           | 124 M \n",
      "2   | model.base_model.embeddings                                       | RobertaEmbeddings      | 39 M  \n",
      "3   | model.base_model.embeddings.word_embeddings                       | Embedding              | 38 M  \n",
      "4   | model.base_model.embeddings.position_embeddings                   | Embedding              | 394 K \n",
      "5   | model.base_model.embeddings.token_type_embeddings                 | Embedding              | 768   \n",
      "6   | model.base_model.embeddings.LayerNorm                             | LayerNorm              | 1 K   \n",
      "7   | model.base_model.embeddings.dropout                               | Dropout                | 0     \n",
      "8   | model.base_model.encoder                                          | RobertaEncoder         | 85 M  \n",
      "9   | model.base_model.encoder.layer                                    | ModuleList             | 85 M  \n",
      "10  | model.base_model.encoder.layer.0                                  | RobertaLayer           | 7 M   \n",
      "11  | model.base_model.encoder.layer.0.attention                        | RobertaAttention       | 2 M   \n",
      "12  | model.base_model.encoder.layer.0.attention.self                   | RobertaSelfAttention   | 1 M   \n",
      "13  | model.base_model.encoder.layer.0.attention.self.query             | Linear                 | 590 K \n",
      "14  | model.base_model.encoder.layer.0.attention.self.key               | Linear                 | 590 K \n",
      "15  | model.base_model.encoder.layer.0.attention.self.value             | Linear                 | 590 K \n",
      "16  | model.base_model.encoder.layer.0.attention.self.dropout           | Dropout                | 0     \n",
      "17  | model.base_model.encoder.layer.0.attention.output                 | RobertaSelfOutput      | 592 K \n",
      "18  | model.base_model.encoder.layer.0.attention.output.dense           | Linear                 | 590 K \n",
      "19  | model.base_model.encoder.layer.0.attention.output.LayerNorm       | LayerNorm              | 1 K   \n",
      "20  | model.base_model.encoder.layer.0.attention.output.dropout         | Dropout                | 0     \n",
      "21  | model.base_model.encoder.layer.0.intermediate                     | RobertaIntermediate    | 2 M   \n",
      "22  | model.base_model.encoder.layer.0.intermediate.dense               | Linear                 | 2 M   \n",
      "23  | model.base_model.encoder.layer.0.intermediate.intermediate_act_fn | GELUActivation         | 0     \n",
      "24  | model.base_model.encoder.layer.0.output                           | RobertaOutput          | 2 M   \n",
      "25  | model.base_model.encoder.layer.0.output.dense                     | Linear                 | 2 M   \n",
      "26  | model.base_model.encoder.layer.0.output.LayerNorm                 | LayerNorm              | 1 K   \n",
      "27  | model.base_model.encoder.layer.0.output.dropout                   | Dropout                | 0     \n",
      "28  | model.base_model.encoder.layer.1                                  | RobertaLayer           | 7 M   \n",
      "29  | model.base_model.encoder.layer.1.attention                        | RobertaAttention       | 2 M   \n",
      "30  | model.base_model.encoder.layer.1.attention.self                   | RobertaSelfAttention   | 1 M   \n",
      "31  | model.base_model.encoder.layer.1.attention.self.query             | Linear                 | 590 K \n",
      "32  | model.base_model.encoder.layer.1.attention.self.key               | Linear                 | 590 K \n",
      "33  | model.base_model.encoder.layer.1.attention.self.value             | Linear                 | 590 K \n",
      "34  | model.base_model.encoder.layer.1.attention.self.dropout           | Dropout                | 0     \n",
      "35  | model.base_model.encoder.layer.1.attention.output                 | RobertaSelfOutput      | 592 K \n",
      "36  | model.base_model.encoder.layer.1.attention.output.dense           | Linear                 | 590 K \n",
      "37  | model.base_model.encoder.layer.1.attention.output.LayerNorm       | LayerNorm              | 1 K   \n",
      "38  | model.base_model.encoder.layer.1.attention.output.dropout         | Dropout                | 0     \n",
      "39  | model.base_model.encoder.layer.1.intermediate                     | RobertaIntermediate    | 2 M   \n",
      "40  | model.base_model.encoder.layer.1.intermediate.dense               | Linear                 | 2 M   \n",
      "41  | model.base_model.encoder.layer.1.output                           | RobertaOutput          | 2 M   \n",
      "42  | model.base_model.encoder.layer.1.output.dense                     | Linear                 | 2 M   \n",
      "43  | model.base_model.encoder.layer.1.output.LayerNorm                 | LayerNorm              | 1 K   \n",
      "44  | model.base_model.encoder.layer.1.output.dropout                   | Dropout                | 0     \n",
      "45  | model.base_model.encoder.layer.2                                  | RobertaLayer           | 7 M   \n",
      "46  | model.base_model.encoder.layer.2.attention                        | RobertaAttention       | 2 M   \n",
      "47  | model.base_model.encoder.layer.2.attention.self                   | RobertaSelfAttention   | 1 M   \n",
      "48  | model.base_model.encoder.layer.2.attention.self.query             | Linear                 | 590 K \n",
      "49  | model.base_model.encoder.layer.2.attention.self.key               | Linear                 | 590 K \n",
      "50  | model.base_model.encoder.layer.2.attention.self.value             | Linear                 | 590 K \n",
      "51  | model.base_model.encoder.layer.2.attention.self.dropout           | Dropout                | 0     \n",
      "52  | model.base_model.encoder.layer.2.attention.output                 | RobertaSelfOutput      | 592 K \n",
      "53  | model.base_model.encoder.layer.2.attention.output.dense           | Linear                 | 590 K \n",
      "54  | model.base_model.encoder.layer.2.attention.output.LayerNorm       | LayerNorm              | 1 K   \n",
      "55  | model.base_model.encoder.layer.2.attention.output.dropout         | Dropout                | 0     \n",
      "56  | model.base_model.encoder.layer.2.intermediate                     | RobertaIntermediate    | 2 M   \n",
      "57  | model.base_model.encoder.layer.2.intermediate.dense               | Linear                 | 2 M   \n",
      "58  | model.base_model.encoder.layer.2.output                           | RobertaOutput          | 2 M   \n",
      "59  | model.base_model.encoder.layer.2.output.dense                     | Linear                 | 2 M   \n",
      "60  | model.base_model.encoder.layer.2.output.LayerNorm                 | LayerNorm              | 1 K   \n",
      "61  | model.base_model.encoder.layer.2.output.dropout                   | Dropout                | 0     \n",
      "62  | model.base_model.encoder.layer.3                                  | RobertaLayer           | 7 M   \n",
      "63  | model.base_model.encoder.layer.3.attention                        | RobertaAttention       | 2 M   \n",
      "64  | model.base_model.encoder.layer.3.attention.self                   | RobertaSelfAttention   | 1 M   \n",
      "65  | model.base_model.encoder.layer.3.attention.self.query             | Linear                 | 590 K \n",
      "66  | model.base_model.encoder.layer.3.attention.self.key               | Linear                 | 590 K \n",
      "67  | model.base_model.encoder.layer.3.attention.self.value             | Linear                 | 590 K \n",
      "68  | model.base_model.encoder.layer.3.attention.self.dropout           | Dropout                | 0     \n",
      "69  | model.base_model.encoder.layer.3.attention.output                 | RobertaSelfOutput      | 592 K \n",
      "70  | model.base_model.encoder.layer.3.attention.output.dense           | Linear                 | 590 K \n",
      "71  | model.base_model.encoder.layer.3.attention.output.LayerNorm       | LayerNorm              | 1 K   \n",
      "72  | model.base_model.encoder.layer.3.attention.output.dropout         | Dropout                | 0     \n",
      "73  | model.base_model.encoder.layer.3.intermediate                     | RobertaIntermediate    | 2 M   \n",
      "74  | model.base_model.encoder.layer.3.intermediate.dense               | Linear                 | 2 M   \n",
      "75  | model.base_model.encoder.layer.3.output                           | RobertaOutput          | 2 M   \n",
      "76  | model.base_model.encoder.layer.3.output.dense                     | Linear                 | 2 M   \n",
      "77  | model.base_model.encoder.layer.3.output.LayerNorm                 | LayerNorm              | 1 K   \n",
      "78  | model.base_model.encoder.layer.3.output.dropout                   | Dropout                | 0     \n",
      "79  | model.base_model.encoder.layer.4                                  | RobertaLayer           | 7 M   \n",
      "80  | model.base_model.encoder.layer.4.attention                        | RobertaAttention       | 2 M   \n",
      "81  | model.base_model.encoder.layer.4.attention.self                   | RobertaSelfAttention   | 1 M   \n",
      "82  | model.base_model.encoder.layer.4.attention.self.query             | Linear                 | 590 K \n",
      "83  | model.base_model.encoder.layer.4.attention.self.key               | Linear                 | 590 K \n",
      "84  | model.base_model.encoder.layer.4.attention.self.value             | Linear                 | 590 K \n",
      "85  | model.base_model.encoder.layer.4.attention.self.dropout           | Dropout                | 0     \n",
      "86  | model.base_model.encoder.layer.4.attention.output                 | RobertaSelfOutput      | 592 K \n",
      "87  | model.base_model.encoder.layer.4.attention.output.dense           | Linear                 | 590 K \n",
      "88  | model.base_model.encoder.layer.4.attention.output.LayerNorm       | LayerNorm              | 1 K   \n",
      "89  | model.base_model.encoder.layer.4.attention.output.dropout         | Dropout                | 0     \n",
      "90  | model.base_model.encoder.layer.4.intermediate                     | RobertaIntermediate    | 2 M   \n",
      "91  | model.base_model.encoder.layer.4.intermediate.dense               | Linear                 | 2 M   \n",
      "92  | model.base_model.encoder.layer.4.output                           | RobertaOutput          | 2 M   \n",
      "93  | model.base_model.encoder.layer.4.output.dense                     | Linear                 | 2 M   \n",
      "94  | model.base_model.encoder.layer.4.output.LayerNorm                 | LayerNorm              | 1 K   \n",
      "95  | model.base_model.encoder.layer.4.output.dropout                   | Dropout                | 0     \n",
      "96  | model.base_model.encoder.layer.5                                  | RobertaLayer           | 7 M   \n",
      "97  | model.base_model.encoder.layer.5.attention                        | RobertaAttention       | 2 M   \n",
      "98  | model.base_model.encoder.layer.5.attention.self                   | RobertaSelfAttention   | 1 M   \n",
      "99  | model.base_model.encoder.layer.5.attention.self.query             | Linear                 | 590 K \n",
      "100 | model.base_model.encoder.layer.5.attention.self.key               | Linear                 | 590 K \n",
      "101 | model.base_model.encoder.layer.5.attention.self.value             | Linear                 | 590 K \n",
      "102 | model.base_model.encoder.layer.5.attention.self.dropout           | Dropout                | 0     \n",
      "103 | model.base_model.encoder.layer.5.attention.output                 | RobertaSelfOutput      | 592 K \n",
      "104 | model.base_model.encoder.layer.5.attention.output.dense           | Linear                 | 590 K \n",
      "105 | model.base_model.encoder.layer.5.attention.output.LayerNorm       | LayerNorm              | 1 K   \n",
      "106 | model.base_model.encoder.layer.5.attention.output.dropout         | Dropout                | 0     \n",
      "107 | model.base_model.encoder.layer.5.intermediate                     | RobertaIntermediate    | 2 M   \n",
      "108 | model.base_model.encoder.layer.5.intermediate.dense               | Linear                 | 2 M   \n",
      "109 | model.base_model.encoder.layer.5.output                           | RobertaOutput          | 2 M   \n",
      "110 | model.base_model.encoder.layer.5.output.dense                     | Linear                 | 2 M   \n",
      "111 | model.base_model.encoder.layer.5.output.LayerNorm                 | LayerNorm              | 1 K   \n",
      "112 | model.base_model.encoder.layer.5.output.dropout                   | Dropout                | 0     \n",
      "113 | model.base_model.encoder.layer.6                                  | RobertaLayer           | 7 M   \n",
      "114 | model.base_model.encoder.layer.6.attention                        | RobertaAttention       | 2 M   \n",
      "115 | model.base_model.encoder.layer.6.attention.self                   | RobertaSelfAttention   | 1 M   \n",
      "116 | model.base_model.encoder.layer.6.attention.self.query             | Linear                 | 590 K \n",
      "117 | model.base_model.encoder.layer.6.attention.self.key               | Linear                 | 590 K \n",
      "118 | model.base_model.encoder.layer.6.attention.self.value             | Linear                 | 590 K \n",
      "119 | model.base_model.encoder.layer.6.attention.self.dropout           | Dropout                | 0     \n",
      "120 | model.base_model.encoder.layer.6.attention.output                 | RobertaSelfOutput      | 592 K \n",
      "121 | model.base_model.encoder.layer.6.attention.output.dense           | Linear                 | 590 K \n",
      "122 | model.base_model.encoder.layer.6.attention.output.LayerNorm       | LayerNorm              | 1 K   \n",
      "123 | model.base_model.encoder.layer.6.attention.output.dropout         | Dropout                | 0     \n",
      "124 | model.base_model.encoder.layer.6.intermediate                     | RobertaIntermediate    | 2 M   \n",
      "125 | model.base_model.encoder.layer.6.intermediate.dense               | Linear                 | 2 M   \n",
      "126 | model.base_model.encoder.layer.6.output                           | RobertaOutput          | 2 M   \n",
      "127 | model.base_model.encoder.layer.6.output.dense                     | Linear                 | 2 M   \n",
      "128 | model.base_model.encoder.layer.6.output.LayerNorm                 | LayerNorm              | 1 K   \n",
      "129 | model.base_model.encoder.layer.6.output.dropout                   | Dropout                | 0     \n",
      "130 | model.base_model.encoder.layer.7                                  | RobertaLayer           | 7 M   \n",
      "131 | model.base_model.encoder.layer.7.attention                        | RobertaAttention       | 2 M   \n",
      "132 | model.base_model.encoder.layer.7.attention.self                   | RobertaSelfAttention   | 1 M   \n",
      "133 | model.base_model.encoder.layer.7.attention.self.query             | Linear                 | 590 K \n",
      "134 | model.base_model.encoder.layer.7.attention.self.key               | Linear                 | 590 K \n",
      "135 | model.base_model.encoder.layer.7.attention.self.value             | Linear                 | 590 K \n",
      "136 | model.base_model.encoder.layer.7.attention.self.dropout           | Dropout                | 0     \n",
      "137 | model.base_model.encoder.layer.7.attention.output                 | RobertaSelfOutput      | 592 K \n",
      "138 | model.base_model.encoder.layer.7.attention.output.dense           | Linear                 | 590 K \n",
      "139 | model.base_model.encoder.layer.7.attention.output.LayerNorm       | LayerNorm              | 1 K   \n",
      "140 | model.base_model.encoder.layer.7.attention.output.dropout         | Dropout                | 0     \n",
      "141 | model.base_model.encoder.layer.7.intermediate                     | RobertaIntermediate    | 2 M   \n",
      "142 | model.base_model.encoder.layer.7.intermediate.dense               | Linear                 | 2 M   \n",
      "143 | model.base_model.encoder.layer.7.output                           | RobertaOutput          | 2 M   \n",
      "144 | model.base_model.encoder.layer.7.output.dense                     | Linear                 | 2 M   \n",
      "145 | model.base_model.encoder.layer.7.output.LayerNorm                 | LayerNorm              | 1 K   \n",
      "146 | model.base_model.encoder.layer.7.output.dropout                   | Dropout                | 0     \n",
      "147 | model.base_model.encoder.layer.8                                  | RobertaLayer           | 7 M   \n",
      "148 | model.base_model.encoder.layer.8.attention                        | RobertaAttention       | 2 M   \n",
      "149 | model.base_model.encoder.layer.8.attention.self                   | RobertaSelfAttention   | 1 M   \n",
      "150 | model.base_model.encoder.layer.8.attention.self.query             | Linear                 | 590 K \n",
      "151 | model.base_model.encoder.layer.8.attention.self.key               | Linear                 | 590 K \n",
      "152 | model.base_model.encoder.layer.8.attention.self.value             | Linear                 | 590 K \n",
      "153 | model.base_model.encoder.layer.8.attention.self.dropout           | Dropout                | 0     \n",
      "154 | model.base_model.encoder.layer.8.attention.output                 | RobertaSelfOutput      | 592 K \n",
      "155 | model.base_model.encoder.layer.8.attention.output.dense           | Linear                 | 590 K \n",
      "156 | model.base_model.encoder.layer.8.attention.output.LayerNorm       | LayerNorm              | 1 K   \n",
      "157 | model.base_model.encoder.layer.8.attention.output.dropout         | Dropout                | 0     \n",
      "158 | model.base_model.encoder.layer.8.intermediate                     | RobertaIntermediate    | 2 M   \n",
      "159 | model.base_model.encoder.layer.8.intermediate.dense               | Linear                 | 2 M   \n",
      "160 | model.base_model.encoder.layer.8.output                           | RobertaOutput          | 2 M   \n",
      "161 | model.base_model.encoder.layer.8.output.dense                     | Linear                 | 2 M   \n",
      "162 | model.base_model.encoder.layer.8.output.LayerNorm                 | LayerNorm              | 1 K   \n",
      "163 | model.base_model.encoder.layer.8.output.dropout                   | Dropout                | 0     \n",
      "164 | model.base_model.encoder.layer.9                                  | RobertaLayer           | 7 M   \n",
      "165 | model.base_model.encoder.layer.9.attention                        | RobertaAttention       | 2 M   \n",
      "166 | model.base_model.encoder.layer.9.attention.self                   | RobertaSelfAttention   | 1 M   \n",
      "167 | model.base_model.encoder.layer.9.attention.self.query             | Linear                 | 590 K \n",
      "168 | model.base_model.encoder.layer.9.attention.self.key               | Linear                 | 590 K \n",
      "169 | model.base_model.encoder.layer.9.attention.self.value             | Linear                 | 590 K \n",
      "170 | model.base_model.encoder.layer.9.attention.self.dropout           | Dropout                | 0     \n",
      "171 | model.base_model.encoder.layer.9.attention.output                 | RobertaSelfOutput      | 592 K \n",
      "172 | model.base_model.encoder.layer.9.attention.output.dense           | Linear                 | 590 K \n",
      "173 | model.base_model.encoder.layer.9.attention.output.LayerNorm       | LayerNorm              | 1 K   \n",
      "174 | model.base_model.encoder.layer.9.attention.output.dropout         | Dropout                | 0     \n",
      "175 | model.base_model.encoder.layer.9.intermediate                     | RobertaIntermediate    | 2 M   \n",
      "176 | model.base_model.encoder.layer.9.intermediate.dense               | Linear                 | 2 M   \n",
      "177 | model.base_model.encoder.layer.9.output                           | RobertaOutput          | 2 M   \n",
      "178 | model.base_model.encoder.layer.9.output.dense                     | Linear                 | 2 M   \n",
      "179 | model.base_model.encoder.layer.9.output.LayerNorm                 | LayerNorm              | 1 K   \n",
      "180 | model.base_model.encoder.layer.9.output.dropout                   | Dropout                | 0     \n",
      "181 | model.base_model.encoder.layer.10                                 | RobertaLayer           | 7 M   \n",
      "182 | model.base_model.encoder.layer.10.attention                       | RobertaAttention       | 2 M   \n",
      "183 | model.base_model.encoder.layer.10.attention.self                  | RobertaSelfAttention   | 1 M   \n",
      "184 | model.base_model.encoder.layer.10.attention.self.query            | Linear                 | 590 K \n",
      "185 | model.base_model.encoder.layer.10.attention.self.key              | Linear                 | 590 K \n",
      "186 | model.base_model.encoder.layer.10.attention.self.value            | Linear                 | 590 K \n",
      "187 | model.base_model.encoder.layer.10.attention.self.dropout          | Dropout                | 0     \n",
      "188 | model.base_model.encoder.layer.10.attention.output                | RobertaSelfOutput      | 592 K \n",
      "189 | model.base_model.encoder.layer.10.attention.output.dense          | Linear                 | 590 K \n",
      "190 | model.base_model.encoder.layer.10.attention.output.LayerNorm      | LayerNorm              | 1 K   \n",
      "191 | model.base_model.encoder.layer.10.attention.output.dropout        | Dropout                | 0     \n",
      "192 | model.base_model.encoder.layer.10.intermediate                    | RobertaIntermediate    | 2 M   \n",
      "193 | model.base_model.encoder.layer.10.intermediate.dense              | Linear                 | 2 M   \n",
      "194 | model.base_model.encoder.layer.10.output                          | RobertaOutput          | 2 M   \n",
      "195 | model.base_model.encoder.layer.10.output.dense                    | Linear                 | 2 M   \n",
      "196 | model.base_model.encoder.layer.10.output.LayerNorm                | LayerNorm              | 1 K   \n",
      "197 | model.base_model.encoder.layer.10.output.dropout                  | Dropout                | 0     \n",
      "198 | model.base_model.encoder.layer.11                                 | RobertaLayer           | 7 M   \n",
      "199 | model.base_model.encoder.layer.11.attention                       | RobertaAttention       | 2 M   \n",
      "200 | model.base_model.encoder.layer.11.attention.self                  | RobertaSelfAttention   | 1 M   \n",
      "201 | model.base_model.encoder.layer.11.attention.self.query            | Linear                 | 590 K \n",
      "202 | model.base_model.encoder.layer.11.attention.self.key              | Linear                 | 590 K \n",
      "203 | model.base_model.encoder.layer.11.attention.self.value            | Linear                 | 590 K \n",
      "204 | model.base_model.encoder.layer.11.attention.self.dropout          | Dropout                | 0     \n",
      "205 | model.base_model.encoder.layer.11.attention.output                | RobertaSelfOutput      | 592 K \n",
      "206 | model.base_model.encoder.layer.11.attention.output.dense          | Linear                 | 590 K \n",
      "207 | model.base_model.encoder.layer.11.attention.output.LayerNorm      | LayerNorm              | 1 K   \n",
      "208 | model.base_model.encoder.layer.11.attention.output.dropout        | Dropout                | 0     \n",
      "209 | model.base_model.encoder.layer.11.intermediate                    | RobertaIntermediate    | 2 M   \n",
      "210 | model.base_model.encoder.layer.11.intermediate.dense              | Linear                 | 2 M   \n",
      "211 | model.base_model.encoder.layer.11.output                          | RobertaOutput          | 2 M   \n",
      "212 | model.base_model.encoder.layer.11.output.dense                    | Linear                 | 2 M   \n",
      "213 | model.base_model.encoder.layer.11.output.LayerNorm                | LayerNorm              | 1 K   \n",
      "214 | model.base_model.encoder.layer.11.output.dropout                  | Dropout                | 0     \n",
      "215 | model.classifier                                                  | Sequential             | 593 K \n",
      "216 | model.classifier.0                                                | Dropout                | 0     \n",
      "217 | model.classifier.1                                                | Linear                 | 590 K \n",
      "218 | model.classifier.2                                                | Mish                   | 0     \n",
      "219 | model.classifier.3                                                | Dropout                | 0     \n",
      "220 | model.classifier.4                                                | Linear                 | 3 K   \n",
      "221 | loss                                                              | CrossEntropyLoss       | 0     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  74%|███████▍  | 40/54 [00:04<00:01,  9.97it/s, loss=0.165, train_loss=0.0835, v_num=148]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train (using cuda)\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=hparams.epochs, progress_bar_refresh_rate=20,\n",
    "                     accumulate_grad_batches=hparams.accumulate_grad_batches, \n",
    "                     early_stop_callback=early_stop_callback)\n",
    "\n",
    "trainer.fit(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model (uncomment to save)\n",
    "\n",
    "# module.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "________________________________________________________________________________\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     sadness     0.8077    0.8077    0.8077        26\n",
      "         joy     0.9688    0.9394    0.9538        33\n",
      "       anger     0.9167    0.9429    0.9296        35\n",
      "        fear     0.8800    0.8800    0.8800        25\n",
      "\n",
      "    accuracy                         0.8992       119\n",
      "   macro avg     0.8933    0.8925    0.8928       119\n",
      "weighted avg     0.8996    0.8992    0.8993       119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    progress = [\"/\", \"-\", \"\\\\\", \"|\", \"/\", \"-\", \"\\\\\", \"|\"]\n",
    "    module.eval().cuda()\n",
    "    true_y, pred_y = [], []\n",
    "    for i, batch_ in enumerate(module.test_dataloader()):\n",
    "        (X, attn), y = batch_\n",
    "        batch = (X.cuda(), attn.cuda())\n",
    "        print(progress[i % len(progress)], end=\"\\r\")\n",
    "        y_pred = torch.argmax(module(batch), dim=1)\n",
    "        true_y.extend(y.cpu())\n",
    "        pred_y.extend(y_pred.cpu())\n",
    "print(\"\\n\" + \"_\" * 80)\n",
    "print(classification_report(true_y, pred_y, target_names=label2int.keys(), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot confusion matrix\n",
    "\n",
    "cm = confusion_matrix(true_y, pred_y, labels=range(len(labels)))\n",
    "df_cm = pd.DataFrame(cm, index = labels, columns = labels)\n",
    "\n",
    "plt.rcParams.update({'font.size': 12}) \n",
    "plt.figure(figsize = (10,8));\n",
    "sn.heatmap(df_cm, annot=True, cmap='Greens', fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hparams = Namespace(\n",
    "#     train_path=train_path,\n",
    "#     val_path=val_path,\n",
    "#     test_path=test_path,\n",
    "#     batch_size=16,\n",
    "#     warmup_steps=100,\n",
    "#     epochs=10,\n",
    "#     lr=1.5E-04,\n",
    "#     accumulate_grad_batches=1\n",
    "# )\n",
    "# module = TrainingModule(hparams)\n",
    "# device = torch.device('cuda:0')\n",
    "# module.model.load_state_dict(torch.load('emotion_model/RoBERTa_emotion_2ft.pt'))\n",
    "# module.model.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54bb103c3e8827112ac287ff09b16e5ca2d85540a3af0b288083619c88e41aa7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
