{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GPO7an53D4c",
        "outputId": "4f827ba2-a6d3-426f-c564-7dd30adc325a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuSM2A6O3OTf"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers==2.9.0 \n",
        "!pip install pytorch_lightning==0.7.5\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_F6gM6zX3Pw3",
        "outputId": "05a0bb4c-6436-4e83-ca33-8e4882860bff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Aug 14 15:42:46 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P0    30W /  70W |   5792MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZk9iRbR3RUm",
        "outputId": "f2fa0e10-6662-44be-d90b-747013717702"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import glob\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import logging\n",
        "import random\n",
        "import re\n",
        "from itertools import chain\n",
        "from string import punctuation\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "import gc\n",
        "\n",
        "from transformers import (\n",
        "    AdamW,\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    get_linear_schedule_with_warmup\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5JyCK0g3SaQ"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXgDNzGz3Vvs"
      },
      "source": [
        "## For logging losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tf12vWfj3WQC"
      },
      "outputs": [],
      "source": [
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class LoggingCallback(pl.Callback):\n",
        "  def on_validation_end(self, trainer, pl_module):\n",
        "    logger.info(\"***** Validation results *****\")\n",
        "    if pl_module.is_logger():\n",
        "      metrics = trainer.callback_metrics\n",
        "      # Log results\n",
        "      for key in sorted(metrics):\n",
        "        if key not in [\"log\", \"progress_bar\"]:\n",
        "          logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
        "\n",
        "  def on_test_end(self, trainer, pl_module):\n",
        "    logger.info(\"***** Test results *****\")\n",
        "\n",
        "    if pl_module.is_logger():\n",
        "      metrics = trainer.callback_metrics\n",
        "\n",
        "      # Log and save results to file\n",
        "      output_test_results_file = os.path.join(pl_module.hparams.output_dir, \"test_results.txt\")\n",
        "      with open(output_test_results_file, \"w\") as writer:\n",
        "        for key in sorted(metrics):\n",
        "          if key not in [\"log\", \"progress_bar\"]:\n",
        "            logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
        "            writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AH8ZqbnE3XgF"
      },
      "outputs": [],
      "source": [
        "#Load the tokenizer for the T5-base model\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwKE56Ke3Ypb"
      },
      "outputs": [],
      "source": [
        "label2int = {\n",
        "  \"sadness\": 1,\n",
        "  \"joy\": 2,\n",
        "  \"anger\": 3,\n",
        "  \"fear\": 4,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMGfRCnk9Acv",
        "outputId": "43ca38e8-8952-41e6-89d8-bb46a4112f2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[24784]\n",
            "[3922]\n",
            "[11213]\n",
            "[2971]\n"
          ]
        }
      ],
      "source": [
        "#check how it encodes the labels (they're all single ids)\n",
        "emotions = [ \"sadness\", \"joy\", \"anger\", \"fear\"]\n",
        "for em in emotions:\n",
        "  print(tokenizer.encode(em))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XveKvoqG3aOq"
      },
      "outputs": [],
      "source": [
        "class EmotionDataset(Dataset):\n",
        "  def __init__(self, tokenizer, data_dir, type_path,  max_len=512):\n",
        "    self.path = os.path.join(data_dir, type_path + '.txt')\n",
        "\n",
        "    self.data_column = \"text\"\n",
        "    self.class_column = \"emotion\"\n",
        "    self.data = pd.read_csv(self.path, sep=\";\", header=None, names=[self.data_column, self.class_column],\n",
        "                            engine=\"python\")\n",
        "    \n",
        "    self.max_len = max_len\n",
        "    self.tokenizer = tokenizer\n",
        "    self.inputs = []\n",
        "    self.targets = []\n",
        "\n",
        "    self._build()\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.inputs)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    source_ids = self.inputs[index][\"input_ids\"].squeeze()\n",
        "    target_ids = self.targets[index][\"input_ids\"].squeeze()\n",
        "\n",
        "    src_mask    = self.inputs[index][\"attention_mask\"].squeeze()  #might need to squeeze\n",
        "    target_mask = self.targets[index][\"attention_mask\"].squeeze()  #might need to squeeze\n",
        "\n",
        "    return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask}\n",
        "  \n",
        "  def _build(self):\n",
        "    for idx in range(len(self.data)):\n",
        "      input_, target = self.data.loc[idx, self.data_column], self.data.loc[idx, self.class_column]      \n",
        "      \n",
        "      input_ = input_ + ' </s>'\n",
        "      target = target + \" </s>\"\n",
        "\n",
        "       #tokenize inputs\n",
        "      tokenized_inputs = self.tokenizer.batch_encode_plus(\n",
        "          [input_], max_length=self.max_len, pad_to_max_length=True, return_tensors=\"pt\"\n",
        "      )\n",
        "       #tokenize targets\n",
        "      tokenized_targets = self.tokenizer.batch_encode_plus(\n",
        "          [target], max_length=2, pad_to_max_length=True, return_tensors=\"pt\"\n",
        "      )\n",
        "\n",
        "      self.inputs.append(tokenized_inputs)\n",
        "      self.targets.append(tokenized_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jQpvUUH4xVy"
      },
      "outputs": [],
      "source": [
        "def get_dataset(tokenizer, type_path, args):\n",
        "  return EmotionDataset(tokenizer=tokenizer, data_dir=args.data_dir, type_path=type_path,  max_len=args.max_seq_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvTb-7-n3d_q"
      },
      "source": [
        "## Model preparation with pytorch lightning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30RCIe6F3fes"
      },
      "outputs": [],
      "source": [
        "class T5FineTuner(pl.LightningModule):\n",
        "  def __init__(self, hparams):\n",
        "    super(T5FineTuner, self).__init__()\n",
        "    self.hparams = hparams\n",
        "    \n",
        "    self.model = T5ForConditionalGeneration.from_pretrained(hparams.model_name_or_path)\n",
        "    self.tokenizer = T5Tokenizer.from_pretrained(hparams.tokenizer_name_or_path)\n",
        "  \n",
        "  def is_logger(self):\n",
        "    return self.trainer.proc_rank <= 0\n",
        "  \n",
        "  def forward(\n",
        "      self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, lm_labels=None\n",
        "  ):\n",
        "    return self.model(\n",
        "        input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        decoder_input_ids=decoder_input_ids,\n",
        "        decoder_attention_mask=decoder_attention_mask,\n",
        "        lm_labels=lm_labels,\n",
        "    )\n",
        "\n",
        "  def _step(self, batch):\n",
        "    lm_labels = batch[\"target_ids\"]\n",
        "    lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
        "\n",
        "    outputs = self(\n",
        "        input_ids=batch[\"source_ids\"],\n",
        "        attention_mask=batch[\"source_mask\"],\n",
        "        lm_labels=lm_labels,\n",
        "        decoder_attention_mask=batch['target_mask']\n",
        "    )\n",
        "\n",
        "    loss = outputs[0]\n",
        "\n",
        "    return loss\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    loss = self._step(batch)\n",
        "\n",
        "    tensorboard_logs = {\"train_loss\": loss}\n",
        "    return {\"loss\": loss, \"log\": tensorboard_logs}\n",
        "  \n",
        "  def training_epoch_end(self, outputs):\n",
        "    avg_train_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
        "    tensorboard_logs = {\"avg_train_loss\": avg_train_loss}\n",
        "    return {\"avg_train_loss\": avg_train_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    loss = self._step(batch)\n",
        "    return {\"val_loss\": loss}\n",
        "  \n",
        "  def validation_epoch_end(self, outputs):\n",
        "    avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
        "    tensorboard_logs = {\"val_loss\": avg_loss}\n",
        "    return {\"avg_val_loss\": avg_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    \"Prepare optimizer and schedule (linear warmup and decay)\"\n",
        "\n",
        "    model = self.model\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": self.hparams.weight_decay,\n",
        "        },\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": 0.0,\n",
        "        },\n",
        "    ]\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.adam_epsilon)\n",
        "    self.opt = optimizer\n",
        "    return [optimizer]\n",
        "  \n",
        "  def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_idx, second_order_closure=None):\n",
        "    if self.trainer.use_tpu:\n",
        "      xm.optimizer_step(optimizer)\n",
        "    else:\n",
        "      optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    self.lr_scheduler.step()\n",
        "  \n",
        "  def get_tqdm_dict(self):\n",
        "    tqdm_dict = {\"loss\": \"{:.3f}\".format(self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n",
        "\n",
        "    return tqdm_dict\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    train_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"train\", args=self.hparams)\n",
        "    dataloader = DataLoader(train_dataset, batch_size=self.hparams.train_batch_size, drop_last=True, shuffle=True, num_workers=4)\n",
        "    t_total = (\n",
        "        (len(dataloader.dataset) // (self.hparams.train_batch_size * max(1, self.hparams.n_gpu)))\n",
        "        // self.hparams.gradient_accumulation_steps\n",
        "        * float(self.hparams.num_train_epochs)\n",
        "    )\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        self.opt, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=t_total\n",
        "    )\n",
        "    self.lr_scheduler = scheduler\n",
        "    return dataloader\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    val_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"val\", args=self.hparams)\n",
        "    return DataLoader(val_dataset, batch_size=self.hparams.eval_batch_size, num_workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4m5Cqx54FAC"
      },
      "source": [
        "## Start training with Empathetic_labelled dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRLElcXn4Iuv"
      },
      "outputs": [],
      "source": [
        "#recover the same dataset splits as made in the baseline notebook\n",
        "train_path = \"drive/MyDrive/emotion_data/train.txt\"\n",
        "test_path = \"drive/MyDrive/emotion_data/test.txt\"\n",
        "val_path = \"drive/MyDrive/emotion_data/val.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wcvxKA-4MtG"
      },
      "outputs": [],
      "source": [
        "#load the tokenizer for this model\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3EKfl5F4OFO"
      },
      "outputs": [],
      "source": [
        "dataset = EmotionDataset(tokenizer, 'drive/MyDrive/emotion_data/', 'val', 512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFpn1mzu4PMU",
        "outputId": "eb3e97a9-bf40-4e7f-ec62-d80d4cd66a8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i couldn t help feeling very nervous like a kid on their first day at school wondering if anyone would want to sit next to me for lunch\n",
            "fear\n"
          ]
        }
      ],
      "source": [
        "#show a sample\n",
        "data = dataset[42]\n",
        "print(tokenizer.decode(data['source_ids']))\n",
        "print(tokenizer.decode(data['target_ids']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I96Dcvlm4Qub"
      },
      "outputs": [],
      "source": [
        "#rubbish collection\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Mq_B3S54TY1"
      },
      "outputs": [],
      "source": [
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "early_stop_callback = EarlyStopping(\n",
        "    monitor=\"val_loss\",  # monitor validation loss\n",
        "    min_delta=0.001, #to very small change in the monitored quantity to qualify as an improvement\n",
        "    patience=20, # used to check number of time with no improvement after which training will be stopped\n",
        "    verbose=False, \n",
        "    mode=\"min\" #sed while training will stopped when the quantity monitor has stopped decreasing\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmSJPJVN4VUd"
      },
      "outputs": [],
      "source": [
        "args_dict = dict(\n",
        "    data_dir=\"\", # path for data files\n",
        "    output_dir=\"\", # path to save the checkpoints\n",
        "    model_name_or_path='t5-base',\n",
        "    tokenizer_name_or_path='t5-base',\n",
        "    max_seq_length=512,\n",
        "    learning_rate=2e-4,\n",
        "    weight_decay=0.0,\n",
        "    adam_epsilon=1e-8,\n",
        "    warmup_steps=0,\n",
        "    train_batch_size=8,\n",
        "    eval_batch_size=8,\n",
        "    num_train_epochs=10,\n",
        "    gradient_accumulation_steps=2,\n",
        "    n_gpu=1,\n",
        "    fp_16=False, \n",
        "    opt_level='O1',\n",
        "    max_grad_norm=1.0,\n",
        "    seed=42,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBjEceWj4YHN",
        "outputId": "5dc4f0e7-7099-4d1d-d21c-18ac5e7fe3e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'data_dir': 'drive/MyDrive/emotion_data/', 'output_dir': 'drive/MyDrive/t5_emotion', 'model_name_or_path': 't5-base', 'tokenizer_name_or_path': 't5-base', 'max_seq_length': 512, 'learning_rate': 0.0002, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'warmup_steps': 0, 'train_batch_size': 8, 'eval_batch_size': 8, 'num_train_epochs': 10, 'gradient_accumulation_steps': 2, 'n_gpu': 1, 'fp_16': False, 'opt_level': 'O1', 'max_grad_norm': 1.0, 'seed': 42}\n"
          ]
        }
      ],
      "source": [
        "args_dict.update({'data_dir': 'drive/MyDrive/emotion_data/', 'output_dir': 'drive/MyDrive/t5_emotion'})\n",
        "args = argparse.Namespace(**args_dict)\n",
        "print(args_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "If9uoHJJ4n5l",
        "outputId": "917a424b-ef5a-490a-e599-dd9981b1787d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: Checkpoint directory drive/MyDrive/t5_emotion exists and is not empty with save_top_k != 0.All files in this directory will be deleted when a checkpoint is saved!\n",
            "  warnings.warn(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "    filepath=args.output_dir, prefix=\"checkpoint\", monitor=\"val_loss\", mode=\"min\", save_top_k=1\n",
        ")\n",
        "\n",
        "train_params = dict(\n",
        "    accumulate_grad_batches=args.gradient_accumulation_steps,\n",
        "    gpus=args.n_gpu,\n",
        "    max_epochs=args.num_train_epochs,\n",
        "    early_stop_callback=early_stop_callback,\n",
        "    precision= 16 if args.fp_16 else 32,\n",
        "    amp_level=args.opt_level,\n",
        "    gradient_clip_val=args.max_grad_norm,\n",
        "    checkpoint_callback=checkpoint_callback,\n",
        "    callbacks=[LoggingCallback()],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amCUPQcj5h73"
      },
      "outputs": [],
      "source": [
        "#clear cache before starting\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxln-ELU41hx"
      },
      "outputs": [],
      "source": [
        "#create instance of model\n",
        "model = T5FineTuner(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wt1sTyv_42m9"
      },
      "outputs": [],
      "source": [
        "trainer = pl.Trainer(**train_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "fe4b78c9f8ff471794adeb7aad1ff766",
            "ee08f535218f4609bfb280b35f7cac3d",
            "eee3af1eb0e14a4eb33b59e658141cf1",
            "36bf5ec90b784570b7299e85c8af5f89",
            "0b7e14d255a6494cbf4606db06a88dbb",
            "d1f816f4842944a1ac7253bc2959b84a",
            "f836036496f34b9a869944101758fc27",
            "720dc3af92f44cea9c0856cac4f4fd19",
            "474c26b047094c509c62ea77aa38c61f",
            "22dd9927ef064521a3c30878458fd866",
            "40d6b6e9825f438d91cfb6bfda0308c5",
            "746faffb6c4d44a5a0428693ea11a44b",
            "5737e50346b0429da0128da3880d411c",
            "a24606a416664258aaa6aac57c0c1b2b",
            "efbd88be2a4c4ee8a5652c3ffcaca1be",
            "2ff58a1294b74fa78de15bf38545e4dd",
            "9b49a515d9fc4653b4b42565d7eba28b",
            "37a161f51393471a87f40cefbb4d4d32",
            "7c1004bf6ba245f4af76399fbb943a17",
            "0a06deef42d74937a3c612e80a8ad674",
            "cf8082a823b342a992d68c925f56a126",
            "0813dc5ab5d14c43995c3229f85bdd57"
          ]
        },
        "id": "_pGEIV_A43sk",
        "outputId": "6e491c6c-ca79-41c6-e960-e6f0a0193d67"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe4b78c9f8ff471794adeb7aad1ff766",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation sanity check: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "746faffb6c4d44a5a0428693ea11a44b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#train loop\n",
        "trainer.fit(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJxqkSfp480y"
      },
      "outputs": [],
      "source": [
        "#save model (uncomment to save)\n",
        "\n",
        "torch.save(model.state_dict(), 'drive/MyDrive/t5_emotion/T5emotion_2ft.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJd0yf2049u2"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOC66VVw4_OO"
      },
      "outputs": [],
      "source": [
        "#load model (uncomment to load)\n",
        "'''\n",
        "model = T5FineTuner(args)\n",
        "model.load_state_dict(torch.load('drive/MyDrive/t5_emotion/T5emotion_2ft.pt'))\n",
        "model.to(device)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsTXAkyC5GIe"
      },
      "source": [
        "## Evaluation on Empathetic labelled test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tmynzRi5Lfc"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6IW9zXJ5Mvh"
      },
      "outputs": [],
      "source": [
        "dataset = EmotionDataset(tokenizer, 'drive/MyDrive/emotion_data', 'test', 512)\n",
        "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "model.model.eval()\n",
        "outputs = []\n",
        "targets = []\n",
        "for batch in tqdm(loader):\n",
        "  outs = model.model.generate(input_ids=batch['source_ids'].cuda(), \n",
        "                              attention_mask=batch['source_mask'].cuda(), \n",
        "                              max_length=2)\n",
        "\n",
        "  dec = [tokenizer.decode(ids) for ids in outs]\n",
        "  target = [tokenizer.decode(ids) for ids in batch[\"target_ids\"]]\n",
        "  \n",
        "  outputs.extend(dec)\n",
        "  targets.extend(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Id86Laz5y6B"
      },
      "outputs": [],
      "source": [
        "for i, out in enumerate(outputs):\n",
        "  if out not in emotions:\n",
        "    print(i, 'detected invalid prediction')\n",
        "    del outputs[i]\n",
        "    del targets[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gofoxqq050wL"
      },
      "outputs": [],
      "source": [
        "#other metrics\n",
        "print(metrics.classification_report(targets, outputs, digits=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDee73eX58_Y"
      },
      "source": [
        "## Further finetune the model on our own dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hDiI1n36Bx8"
      },
      "outputs": [],
      "source": [
        "#retrieve paths of splits as defined in the baseline notebook\n",
        "\n",
        "train_path = \"drive/MyDrive/emotion_data/my_train.txt\"\n",
        "test_path = \"drive/MyDrive/emotion_data/my_test.txt\"\n",
        "val_path = \"drive/MyDrive/emotion_data/my_val.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfYfdC6Y6FJH"
      },
      "outputs": [],
      "source": [
        "class T5FineTuner(pl.LightningModule):\n",
        "  def __init__(self, hparams):\n",
        "    super(T5FineTuner, self).__init__()\n",
        "    self.hparams = hparams\n",
        "    \n",
        "    self.model = T5ForConditionalGeneration.from_pretrained(hparams.model_name_or_path)\n",
        "    self.tokenizer = T5Tokenizer.from_pretrained(hparams.tokenizer_name_or_path)\n",
        "  \n",
        "  def is_logger(self):\n",
        "    return self.trainer.proc_rank <= 0\n",
        "  \n",
        "  def forward(\n",
        "      self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, lm_labels=None\n",
        "  ):\n",
        "    return self.model(\n",
        "        input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        decoder_input_ids=decoder_input_ids,\n",
        "        decoder_attention_mask=decoder_attention_mask,\n",
        "        lm_labels=lm_labels,\n",
        "    )\n",
        "\n",
        "  def _step(self, batch):\n",
        "    lm_labels = batch[\"target_ids\"]\n",
        "    lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
        "\n",
        "    outputs = self(\n",
        "        input_ids=batch[\"source_ids\"],\n",
        "        attention_mask=batch[\"source_mask\"],\n",
        "        lm_labels=lm_labels,\n",
        "        decoder_attention_mask=batch['target_mask']\n",
        "    )\n",
        "\n",
        "    loss = outputs[0]\n",
        "\n",
        "    return loss\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    loss = self._step(batch)\n",
        "\n",
        "    tensorboard_logs = {\"train_loss\": loss}\n",
        "    return {\"loss\": loss, \"log\": tensorboard_logs}\n",
        "  \n",
        "  def training_epoch_end(self, outputs):\n",
        "    avg_train_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
        "    tensorboard_logs = {\"avg_train_loss\": avg_train_loss}\n",
        "    return {\"avg_train_loss\": avg_train_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    loss = self._step(batch)\n",
        "    return {\"val_loss\": loss}\n",
        "  \n",
        "  def validation_epoch_end(self, outputs):\n",
        "    avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
        "    tensorboard_logs = {\"val_loss\": avg_loss}\n",
        "    return {\"avg_val_loss\": avg_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    \"Prepare optimizer and schedule (linear warmup and decay)\"\n",
        "\n",
        "    model = self.model\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": self.hparams.weight_decay,\n",
        "        },\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": 0.0,\n",
        "        },\n",
        "    ]\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.adam_epsilon)\n",
        "    self.opt = optimizer\n",
        "    return [optimizer]\n",
        "  \n",
        "  def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_idx, second_order_closure=None):\n",
        "    if self.trainer.use_tpu:\n",
        "      xm.optimizer_step(optimizer)\n",
        "    else:\n",
        "      optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    self.lr_scheduler.step()\n",
        "  \n",
        "  def get_tqdm_dict(self):\n",
        "    tqdm_dict = {\"loss\": \"{:.3f}\".format(self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n",
        "\n",
        "    return tqdm_dict\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    train_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"my_train\", args=self.hparams)\n",
        "    dataloader = DataLoader(train_dataset, batch_size=self.hparams.train_batch_size, drop_last=True, shuffle=True, num_workers=4)\n",
        "    t_total = (\n",
        "        (len(dataloader.dataset) // (self.hparams.train_batch_size * max(1, self.hparams.n_gpu)))\n",
        "        // self.hparams.gradient_accumulation_steps\n",
        "        * float(self.hparams.num_train_epochs)\n",
        "    )\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        self.opt, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=t_total\n",
        "    )\n",
        "    self.lr_scheduler = scheduler\n",
        "    return dataloader\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    val_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"my_val\", args=self.hparams)\n",
        "    return DataLoader(val_dataset, batch_size=self.hparams.eval_batch_size, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giwwvTxz6KiN"
      },
      "outputs": [],
      "source": [
        "#load the tokenizer for this model\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbG0AID-6Lq2"
      },
      "outputs": [],
      "source": [
        "#clear cache before starting\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJQZuBZE6SXS"
      },
      "outputs": [],
      "source": [
        "#rubbish collection\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRd_5TiK6RS9"
      },
      "outputs": [],
      "source": [
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "early_stop_callback = EarlyStopping(\n",
        "    monitor=\"val_loss\",  # monitor validation loss\n",
        "    min_delta=0.001, #to very small change in the monitored quantity to qualify as an improvement\n",
        "    patience=20, # used to check number of time with no improvement after which training will be stopped\n",
        "    verbose=False, \n",
        "    mode=\"min\" #sed while training will stopped when the quantity monitor has stopped decreasing\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZPxhRJ_6MwJ"
      },
      "outputs": [],
      "source": [
        "args_dict = dict(\n",
        "    data_dir=\"\", # path for data files\n",
        "    output_dir=\"\", # path to save the checkpoints\n",
        "    model_name_or_path='t5-base',\n",
        "    tokenizer_name_or_path='t5-base',\n",
        "    max_seq_length=512,\n",
        "    learning_rate=1e-4,\n",
        "    weight_decay=0.0,\n",
        "    adam_epsilon=1e-8,\n",
        "    warmup_steps=0,\n",
        "    train_batch_size=1,\n",
        "    eval_batch_size=1,\n",
        "    num_train_epochs=12,\n",
        "    gradient_accumulation_steps=16,\n",
        "    n_gpu=1,\n",
        "    fp_16=False, \n",
        "    opt_level='O1', \n",
        "    max_grad_norm=1.0,\n",
        "    seed=42,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJ0TST916Tk5"
      },
      "outputs": [],
      "source": [
        "args_dict.update({'data_dir': 'drive/MyDrive/emotion_data/', 'output_dir': 'drive/MyDrive/t5_emotion'})\n",
        "args = argparse.Namespace(**args_dict)\n",
        "print(args_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rv4LiVzE6WEX"
      },
      "outputs": [],
      "source": [
        "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "    filepath=args.output_dir, prefix=\"checkpoint\", monitor=\"val_loss\", mode=\"min\", save_top_k=1\n",
        ")\n",
        "\n",
        "train_params = dict(\n",
        "    accumulate_grad_batches=args.gradient_accumulation_steps,\n",
        "    gpus=args.n_gpu,\n",
        "    max_epochs=args.num_train_epochs,\n",
        "    early_stop_callback=early_stop_callback,\n",
        "    precision= 16 if args.fp_16 else 32,\n",
        "    amp_level=args.opt_level,\n",
        "    gradient_clip_val=args.max_grad_norm,\n",
        "    checkpoint_callback=checkpoint_callback,\n",
        "    callbacks=[LoggingCallback()],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_DfXBAH6c93"
      },
      "outputs": [],
      "source": [
        "#load the weights of the model previously finetuned on the emotional reactions dataset\n",
        "device = torch.device('cuda:0')\n",
        "model = T5FineTuner(args)\n",
        "model.load_state_dict(torch.load('drive/MyDrive/t5_emotion/T5emotion_1ft.pt'))\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECfpEpI06xg7"
      },
      "outputs": [],
      "source": [
        "trainer = pl.Trainer(**train_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMXJWd0U6zp3"
      },
      "outputs": [],
      "source": [
        "#rubbish collection\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jN15oBHG6zMG"
      },
      "outputs": [],
      "source": [
        "#train loop\n",
        "trainer.fit(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EY_As_uV66Mw"
      },
      "outputs": [],
      "source": [
        "#save model (uncomment to save)\n",
        "'''\n",
        "torch.save(model.state_dict(), 'drive/MyDrive/t5_emotion/T5_emotion_twicefinetuned.pt')\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JimBBHJ6264"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0')\n",
        "#load model (uncomment to load)\n",
        "'''\n",
        "model = T5FineTuner(args)\n",
        "model.model.load_state_dict(torch.load('drive/MyDrive/t5_emotion/T5_emotion_twicefinetuned.pt'))\n",
        "model.to(device)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnrb3p8q6714"
      },
      "source": [
        "## Evaluation on our test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9Om1Tn767NT"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjYKmjZ47ApZ"
      },
      "outputs": [],
      "source": [
        "dataset = EmotionDataset(tokenizer, 'drive/MyDrive/emotion_data', 'my_test', 512)\n",
        "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "model.model.eval()\n",
        "outputs = []\n",
        "targets = []\n",
        "for batch in tqdm(loader):\n",
        "  outs = model.model.generate(input_ids=batch['source_ids'].cuda(), \n",
        "                              attention_mask=batch['source_mask'].cuda(), \n",
        "                              max_length=2)\n",
        "\n",
        "  dec = [tokenizer.decode(ids) for ids in outs]\n",
        "  target = [tokenizer.decode(ids) for ids in batch[\"target_ids\"]]\n",
        "  \n",
        "  outputs.extend(dec)\n",
        "  targets.extend(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECeb9_B37N9q"
      },
      "outputs": [],
      "source": [
        "for i, out in enumerate(outputs):\n",
        "  if out not in emotions:\n",
        "    print(i, 'detected invalid prediction')\n",
        "    del outputs[i]\n",
        "    del targets[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6w_G_cSL7O3h"
      },
      "outputs": [],
      "source": [
        "#other metrics\n",
        "print(metrics.classification_report(targets, outputs, digits=4))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Emotion_T5_double_fine_tune.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0813dc5ab5d14c43995c3229f85bdd57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a06deef42d74937a3c612e80a8ad674": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b7e14d255a6494cbf4606db06a88dbb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "22dd9927ef064521a3c30878458fd866": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ff58a1294b74fa78de15bf38545e4dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "36bf5ec90b784570b7299e85c8af5f89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22dd9927ef064521a3c30878458fd866",
            "placeholder": "",
            "style": "IPY_MODEL_40d6b6e9825f438d91cfb6bfda0308c5",
            "value": " 5/5 [00:01&lt;00:00,  2.98it/s]"
          }
        },
        "37a161f51393471a87f40cefbb4d4d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40d6b6e9825f438d91cfb6bfda0308c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "474c26b047094c509c62ea77aa38c61f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5737e50346b0429da0128da3880d411c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b49a515d9fc4653b4b42565d7eba28b",
            "placeholder": "",
            "style": "IPY_MODEL_37a161f51393471a87f40cefbb4d4d32",
            "value": "Epoch 1:   6%"
          }
        },
        "720dc3af92f44cea9c0856cac4f4fd19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "746faffb6c4d44a5a0428693ea11a44b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5737e50346b0429da0128da3880d411c",
              "IPY_MODEL_a24606a416664258aaa6aac57c0c1b2b",
              "IPY_MODEL_efbd88be2a4c4ee8a5652c3ffcaca1be"
            ],
            "layout": "IPY_MODEL_2ff58a1294b74fa78de15bf38545e4dd"
          }
        },
        "7c1004bf6ba245f4af76399fbb943a17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b49a515d9fc4653b4b42565d7eba28b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a24606a416664258aaa6aac57c0c1b2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c1004bf6ba245f4af76399fbb943a17",
            "max": 2250,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a06deef42d74937a3c612e80a8ad674",
            "value": 127
          }
        },
        "cf8082a823b342a992d68c925f56a126": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1f816f4842944a1ac7253bc2959b84a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee08f535218f4609bfb280b35f7cac3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1f816f4842944a1ac7253bc2959b84a",
            "placeholder": "",
            "style": "IPY_MODEL_f836036496f34b9a869944101758fc27",
            "value": "Validation sanity check: 100%"
          }
        },
        "eee3af1eb0e14a4eb33b59e658141cf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_720dc3af92f44cea9c0856cac4f4fd19",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_474c26b047094c509c62ea77aa38c61f",
            "value": 1
          }
        },
        "efbd88be2a4c4ee8a5652c3ffcaca1be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf8082a823b342a992d68c925f56a126",
            "placeholder": "",
            "style": "IPY_MODEL_0813dc5ab5d14c43995c3229f85bdd57",
            "value": " 127/2250 [02:06&lt;35:14,  1.00it/s, loss=0.172, v_num=2]"
          }
        },
        "f836036496f34b9a869944101758fc27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe4b78c9f8ff471794adeb7aad1ff766": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee08f535218f4609bfb280b35f7cac3d",
              "IPY_MODEL_eee3af1eb0e14a4eb33b59e658141cf1",
              "IPY_MODEL_36bf5ec90b784570b7299e85c8af5f89"
            ],
            "layout": "IPY_MODEL_0b7e14d255a6494cbf4606db06a88dbb"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}