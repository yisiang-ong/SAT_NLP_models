{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#package imports \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from transformers import DistilBertTokenizer, AutoTokenizer, AutoModelWithLMHead, DistilBertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "\n",
    "from typing import List\n",
    "import logging\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "from functools import lru_cache\n",
    "from argparse import Namespace\n",
    "from packaging import version\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This notebook is partly adapted from Saravia et al.'s Emotion dataset notebook which is\n",
    "#available at this link: https://colab.research.google.com/drive/1nwCE6b9PXIKhv2hvbqf1oZKIGkXMTi1X#scrollTo=t23zHggkEpc-\n",
    "\n",
    "#In fact, we use the Emotion dataset by Saravia et al. for the first finetuning step. Full citation below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_CITATION = \"\"\"\\\n",
    "@inproceedings{saravia-etal-2018-carer,\n",
    "    title = \"{CARER}: Contextualized Affect Representations for Emotion Recognition\",\n",
    "    author = \"Saravia, Elvis  and\n",
    "      Liu, Hsien-Chi Toby  and\n",
    "      Huang, Yen-Hao  and\n",
    "      Wu, Junlin  and\n",
    "      Chen, Yi-Shin\",\n",
    "    booktitle = \"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing\",\n",
    "    month = oct # \"-\" # nov,\n",
    "    year = \"2018\",\n",
    "    address = \"Brussels, Belgium\",\n",
    "    publisher = \"Association for Computational Linguistics\",\n",
    "    url = \"https://www.aclweb.org/anthology/D18-1404\",\n",
    "    doi = \"10.18653/v1/D18-1404\",\n",
    "    pages = \"3687--3697\"\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tune on CARER dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we define the paths for train, val, test, same split as already obtained in the T5 notebook\n",
    "train_path = \"empathy_dataset/train.txt\"\n",
    "test_path = \"empathy_dataset/test.txt\"\n",
    "val_path = \"empathy_dataset/val.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weak': 0, 'strong': 1}\n"
     ]
    }
   ],
   "source": [
    "#create a dictionary which associates each string label to an integer value\n",
    "labels = [\"weak\", \"strong\"]\n",
    "label2int = dict(zip(labels, list(range(len(labels)))))\n",
    "print(label2int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yisiang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:998: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "#load actual model\n",
    "model = AutoModelWithLMHead.from_pretrained('roberta-base')\n",
    "base_model = model.base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Mish activation function \n",
    "#(from https://github.com/digantamisra98/Mish/blob/b5f006660ac0b4c46e2c6958ad0301d7f9c59651/Mish/Torch/mish.py)\n",
    "@torch.jit.script\n",
    "def mish(input):\n",
    "    return input * torch.tanh(F.softplus(input))\n",
    "  \n",
    "class Mish(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return mish(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define an EmpathyClassificationModel class to do the actual fine-tuning\n",
    "\n",
    "class EmpathyClassificationModel(nn.Module):\n",
    "    def __init__(self, base_model, n_classes, base_model_output_size=768, dropout=0.05):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(base_model_output_size, base_model_output_size),\n",
    "            Mish(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(base_model_output_size, n_classes)\n",
    "        )\n",
    "        \n",
    "        for layer in self.classifier:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                layer.weight.data.normal_(mean=0.0, std=0.02)\n",
    "                if layer.bias is not None:\n",
    "                    layer.bias.data.zero_()\n",
    "\n",
    "    def forward(self, input_, *args):\n",
    "        X, attention_mask = input_\n",
    "        hidden_states = self.base_model(X, attention_mask=attention_mask)\n",
    "        \n",
    "        return self.classifier(hidden_states[0][:, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tokenizer\\\\tokenizer_config.json',\n",
       " 'tokenizer\\\\special_tokens_map.json',\n",
       " 'tokenizer\\\\vocab.json',\n",
       " 'tokenizer\\\\merges.txt',\n",
       " 'tokenizer\\\\added_tokens.json',\n",
       " 'tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load pretrained tokenizer information\n",
    "tokenizer.save_pretrained(\"tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementation of CollateFN to do tokenization and batches of sequences\n",
    "\n",
    "class TokenizersCollateFn:\n",
    "    def __init__(self, max_tokens=512): \n",
    "\n",
    "        #RoBERTa uses the BPE tokenizer, similarly to GPT-2\n",
    "        t = ByteLevelBPETokenizer(\n",
    "            \"tokenizer/vocab.json\",\n",
    "            \"tokenizer/merges.txt\"\n",
    "        )\n",
    "        t._tokenizer.post_processor = BertProcessing(\n",
    "            (\"</s>\", t.token_to_id(\"</s>\")),\n",
    "            (\"<s>\", t.token_to_id(\"<s>\")),\n",
    "        )\n",
    "        t.enable_truncation(max_tokens)\n",
    "        t.enable_padding(pad_id=t.token_to_id(\"<pad>\"))\n",
    "        self.tokenizer = t\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        encoded = self.tokenizer.encode_batch([x[0] for x in batch])\n",
    "        sequences_padded = torch.tensor([enc.ids for enc in encoded])\n",
    "        attention_masks_padded = torch.tensor([enc.attention_mask for enc in encoded])\n",
    "        labels = torch.tensor([x[1] for x in batch])\n",
    "        \n",
    "        return (sequences_padded, attention_masks_padded), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class to create dataset objects from the data\n",
    "\n",
    "class EmpathyDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        super().__init__()\n",
    "        self.data_column = \"text\"\n",
    "        self.class_column = \"class\"\n",
    "        self.data = pd.read_csv(path, sep=\";\", header=None, names=[self.data_column, self.class_column],\n",
    "                               engine=\"python\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data.loc[idx, self.data_column], label2int[self.data.loc[idx, self.class_column]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use PyTorch Lighning for training. Lightning methods are defined here\n",
    "\n",
    "class TrainingModule(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.model = EmpathyClassificationModel(AutoModelWithLMHead.from_pretrained(\"roberta-base\").base_model, len(labels))\n",
    "        self.loss = nn.CrossEntropyLoss() \n",
    "        self.hparams = hparams\n",
    "        #  self.save_hyperparameters(hparams)\n",
    "\n",
    "    def step(self, batch, step_name=\"train\"):\n",
    "        X, y = batch\n",
    "        loss = self.loss(self.forward(X), y)\n",
    "        loss_key = f\"{step_name}_loss\"\n",
    "        tensorboard_logs = {loss_key: loss}\n",
    "\n",
    "        return { (\"loss\" if step_name == \"train\" else loss_key): loss, 'log': tensorboard_logs,\n",
    "               \"progress_bar\": {loss_key: loss}}\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        return self.model(X, *args)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"train\")\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"val\")\n",
    "\n",
    "    def validation_end(self, outputs: List[dict]):\n",
    "        loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        return {\"val_loss\": loss}\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"test\")\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.train_path, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.val_path)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.test_path)\n",
    "                \n",
    "    def create_data_loader(self, ds_path: str, shuffle=False):\n",
    "        return DataLoader(\n",
    "                    EmpathyDataset(ds_path),\n",
    "                    batch_size=self.hparams.batch_size,\n",
    "                    shuffle=shuffle,\n",
    "                    collate_fn=TokenizersCollateFn()\n",
    "        )\n",
    "        \n",
    "    @lru_cache()\n",
    "    def total_steps(self):\n",
    "        return len(self.train_dataloader()) // self.hparams.accumulate_grad_batches * self.hparams.epochs\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.model.parameters(), lr=self.hparams.lr) #we use AdamW as this usually performs well\n",
    "        lr_scheduler = get_linear_schedule_with_warmup(\n",
    "                    optimizer,\n",
    "                    num_warmup_steps=self.hparams.warmup_steps,\n",
    "                    num_training_steps=self.total_steps(),\n",
    "        )\n",
    "        return [optimizer], [{\"scheduler\": lr_scheduler, \"interval\": \"step\"}]\n",
    "    \n",
    "    def save_model(self):\n",
    "        torch.save(self.model.state_dict(), f'empathy_model/RoBERTa_empathy_2ft.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = Namespace(\n",
    "    train_path=train_path,\n",
    "    val_path=val_path,\n",
    "    test_path=test_path,\n",
    "    batch_size=20,\n",
    "    warmup_steps=100,\n",
    "    epochs=20,\n",
    "    lr=2E-06,\n",
    "    accumulate_grad_batches=1\n",
    ")\n",
    "module = TrainingModule(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rubbish collection\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",  # monitor validation loss\n",
    "    min_delta=0.001, #to very small change in the monitored quantity to qualify as an improvement\n",
    "    patience=20, # used to check number of time with no improvement after which training will be stopped\n",
    "    verbose=False, \n",
    "    mode=\"min\" #sed while training will stopped when the quantity monitor has stopped decreasing\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:GPU available: True, used: True\n",
      "INFO:lightning:CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\yisiang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:23: RuntimeWarning: You have defined a `val_dataloader()` and have defined a `validation_step()`, you may also want to define `validation_epoch_end()` for accumulating stats.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\yisiang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:23: RuntimeWarning: You have defined a `test_dataloader()` and have defined a `test_step()`, you may also want to define `test_epoch_end()` for accumulating stats.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\yisiang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "INFO:lightning:\n",
      "    | Name                                                              | Type                       | Params\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "0   | model                                                             | EmpathyClassificationModel | 124 M \n",
      "1   | model.base_model                                                  | RobertaModel               | 124 M \n",
      "2   | model.base_model.embeddings                                       | RobertaEmbeddings          | 39 M  \n",
      "3   | model.base_model.embeddings.word_embeddings                       | Embedding                  | 38 M  \n",
      "4   | model.base_model.embeddings.position_embeddings                   | Embedding                  | 394 K \n",
      "5   | model.base_model.embeddings.token_type_embeddings                 | Embedding                  | 768   \n",
      "6   | model.base_model.embeddings.LayerNorm                             | LayerNorm                  | 1 K   \n",
      "7   | model.base_model.embeddings.dropout                               | Dropout                    | 0     \n",
      "8   | model.base_model.encoder                                          | RobertaEncoder             | 85 M  \n",
      "9   | model.base_model.encoder.layer                                    | ModuleList                 | 85 M  \n",
      "10  | model.base_model.encoder.layer.0                                  | RobertaLayer               | 7 M   \n",
      "11  | model.base_model.encoder.layer.0.attention                        | RobertaAttention           | 2 M   \n",
      "12  | model.base_model.encoder.layer.0.attention.self                   | RobertaSelfAttention       | 1 M   \n",
      "13  | model.base_model.encoder.layer.0.attention.self.query             | Linear                     | 590 K \n",
      "14  | model.base_model.encoder.layer.0.attention.self.key               | Linear                     | 590 K \n",
      "15  | model.base_model.encoder.layer.0.attention.self.value             | Linear                     | 590 K \n",
      "16  | model.base_model.encoder.layer.0.attention.self.dropout           | Dropout                    | 0     \n",
      "17  | model.base_model.encoder.layer.0.attention.output                 | RobertaSelfOutput          | 592 K \n",
      "18  | model.base_model.encoder.layer.0.attention.output.dense           | Linear                     | 590 K \n",
      "19  | model.base_model.encoder.layer.0.attention.output.LayerNorm       | LayerNorm                  | 1 K   \n",
      "20  | model.base_model.encoder.layer.0.attention.output.dropout         | Dropout                    | 0     \n",
      "21  | model.base_model.encoder.layer.0.intermediate                     | RobertaIntermediate        | 2 M   \n",
      "22  | model.base_model.encoder.layer.0.intermediate.dense               | Linear                     | 2 M   \n",
      "23  | model.base_model.encoder.layer.0.intermediate.intermediate_act_fn | GELUActivation             | 0     \n",
      "24  | model.base_model.encoder.layer.0.output                           | RobertaOutput              | 2 M   \n",
      "25  | model.base_model.encoder.layer.0.output.dense                     | Linear                     | 2 M   \n",
      "26  | model.base_model.encoder.layer.0.output.LayerNorm                 | LayerNorm                  | 1 K   \n",
      "27  | model.base_model.encoder.layer.0.output.dropout                   | Dropout                    | 0     \n",
      "28  | model.base_model.encoder.layer.1                                  | RobertaLayer               | 7 M   \n",
      "29  | model.base_model.encoder.layer.1.attention                        | RobertaAttention           | 2 M   \n",
      "30  | model.base_model.encoder.layer.1.attention.self                   | RobertaSelfAttention       | 1 M   \n",
      "31  | model.base_model.encoder.layer.1.attention.self.query             | Linear                     | 590 K \n",
      "32  | model.base_model.encoder.layer.1.attention.self.key               | Linear                     | 590 K \n",
      "33  | model.base_model.encoder.layer.1.attention.self.value             | Linear                     | 590 K \n",
      "34  | model.base_model.encoder.layer.1.attention.self.dropout           | Dropout                    | 0     \n",
      "35  | model.base_model.encoder.layer.1.attention.output                 | RobertaSelfOutput          | 592 K \n",
      "36  | model.base_model.encoder.layer.1.attention.output.dense           | Linear                     | 590 K \n",
      "37  | model.base_model.encoder.layer.1.attention.output.LayerNorm       | LayerNorm                  | 1 K   \n",
      "38  | model.base_model.encoder.layer.1.attention.output.dropout         | Dropout                    | 0     \n",
      "39  | model.base_model.encoder.layer.1.intermediate                     | RobertaIntermediate        | 2 M   \n",
      "40  | model.base_model.encoder.layer.1.intermediate.dense               | Linear                     | 2 M   \n",
      "41  | model.base_model.encoder.layer.1.output                           | RobertaOutput              | 2 M   \n",
      "42  | model.base_model.encoder.layer.1.output.dense                     | Linear                     | 2 M   \n",
      "43  | model.base_model.encoder.layer.1.output.LayerNorm                 | LayerNorm                  | 1 K   \n",
      "44  | model.base_model.encoder.layer.1.output.dropout                   | Dropout                    | 0     \n",
      "45  | model.base_model.encoder.layer.2                                  | RobertaLayer               | 7 M   \n",
      "46  | model.base_model.encoder.layer.2.attention                        | RobertaAttention           | 2 M   \n",
      "47  | model.base_model.encoder.layer.2.attention.self                   | RobertaSelfAttention       | 1 M   \n",
      "48  | model.base_model.encoder.layer.2.attention.self.query             | Linear                     | 590 K \n",
      "49  | model.base_model.encoder.layer.2.attention.self.key               | Linear                     | 590 K \n",
      "50  | model.base_model.encoder.layer.2.attention.self.value             | Linear                     | 590 K \n",
      "51  | model.base_model.encoder.layer.2.attention.self.dropout           | Dropout                    | 0     \n",
      "52  | model.base_model.encoder.layer.2.attention.output                 | RobertaSelfOutput          | 592 K \n",
      "53  | model.base_model.encoder.layer.2.attention.output.dense           | Linear                     | 590 K \n",
      "54  | model.base_model.encoder.layer.2.attention.output.LayerNorm       | LayerNorm                  | 1 K   \n",
      "55  | model.base_model.encoder.layer.2.attention.output.dropout         | Dropout                    | 0     \n",
      "56  | model.base_model.encoder.layer.2.intermediate                     | RobertaIntermediate        | 2 M   \n",
      "57  | model.base_model.encoder.layer.2.intermediate.dense               | Linear                     | 2 M   \n",
      "58  | model.base_model.encoder.layer.2.output                           | RobertaOutput              | 2 M   \n",
      "59  | model.base_model.encoder.layer.2.output.dense                     | Linear                     | 2 M   \n",
      "60  | model.base_model.encoder.layer.2.output.LayerNorm                 | LayerNorm                  | 1 K   \n",
      "61  | model.base_model.encoder.layer.2.output.dropout                   | Dropout                    | 0     \n",
      "62  | model.base_model.encoder.layer.3                                  | RobertaLayer               | 7 M   \n",
      "63  | model.base_model.encoder.layer.3.attention                        | RobertaAttention           | 2 M   \n",
      "64  | model.base_model.encoder.layer.3.attention.self                   | RobertaSelfAttention       | 1 M   \n",
      "65  | model.base_model.encoder.layer.3.attention.self.query             | Linear                     | 590 K \n",
      "66  | model.base_model.encoder.layer.3.attention.self.key               | Linear                     | 590 K \n",
      "67  | model.base_model.encoder.layer.3.attention.self.value             | Linear                     | 590 K \n",
      "68  | model.base_model.encoder.layer.3.attention.self.dropout           | Dropout                    | 0     \n",
      "69  | model.base_model.encoder.layer.3.attention.output                 | RobertaSelfOutput          | 592 K \n",
      "70  | model.base_model.encoder.layer.3.attention.output.dense           | Linear                     | 590 K \n",
      "71  | model.base_model.encoder.layer.3.attention.output.LayerNorm       | LayerNorm                  | 1 K   \n",
      "72  | model.base_model.encoder.layer.3.attention.output.dropout         | Dropout                    | 0     \n",
      "73  | model.base_model.encoder.layer.3.intermediate                     | RobertaIntermediate        | 2 M   \n",
      "74  | model.base_model.encoder.layer.3.intermediate.dense               | Linear                     | 2 M   \n",
      "75  | model.base_model.encoder.layer.3.output                           | RobertaOutput              | 2 M   \n",
      "76  | model.base_model.encoder.layer.3.output.dense                     | Linear                     | 2 M   \n",
      "77  | model.base_model.encoder.layer.3.output.LayerNorm                 | LayerNorm                  | 1 K   \n",
      "78  | model.base_model.encoder.layer.3.output.dropout                   | Dropout                    | 0     \n",
      "79  | model.base_model.encoder.layer.4                                  | RobertaLayer               | 7 M   \n",
      "80  | model.base_model.encoder.layer.4.attention                        | RobertaAttention           | 2 M   \n",
      "81  | model.base_model.encoder.layer.4.attention.self                   | RobertaSelfAttention       | 1 M   \n",
      "82  | model.base_model.encoder.layer.4.attention.self.query             | Linear                     | 590 K \n",
      "83  | model.base_model.encoder.layer.4.attention.self.key               | Linear                     | 590 K \n",
      "84  | model.base_model.encoder.layer.4.attention.self.value             | Linear                     | 590 K \n",
      "85  | model.base_model.encoder.layer.4.attention.self.dropout           | Dropout                    | 0     \n",
      "86  | model.base_model.encoder.layer.4.attention.output                 | RobertaSelfOutput          | 592 K \n",
      "87  | model.base_model.encoder.layer.4.attention.output.dense           | Linear                     | 590 K \n",
      "88  | model.base_model.encoder.layer.4.attention.output.LayerNorm       | LayerNorm                  | 1 K   \n",
      "89  | model.base_model.encoder.layer.4.attention.output.dropout         | Dropout                    | 0     \n",
      "90  | model.base_model.encoder.layer.4.intermediate                     | RobertaIntermediate        | 2 M   \n",
      "91  | model.base_model.encoder.layer.4.intermediate.dense               | Linear                     | 2 M   \n",
      "92  | model.base_model.encoder.layer.4.output                           | RobertaOutput              | 2 M   \n",
      "93  | model.base_model.encoder.layer.4.output.dense                     | Linear                     | 2 M   \n",
      "94  | model.base_model.encoder.layer.4.output.LayerNorm                 | LayerNorm                  | 1 K   \n",
      "95  | model.base_model.encoder.layer.4.output.dropout                   | Dropout                    | 0     \n",
      "96  | model.base_model.encoder.layer.5                                  | RobertaLayer               | 7 M   \n",
      "97  | model.base_model.encoder.layer.5.attention                        | RobertaAttention           | 2 M   \n",
      "98  | model.base_model.encoder.layer.5.attention.self                   | RobertaSelfAttention       | 1 M   \n",
      "99  | model.base_model.encoder.layer.5.attention.self.query             | Linear                     | 590 K \n",
      "100 | model.base_model.encoder.layer.5.attention.self.key               | Linear                     | 590 K \n",
      "101 | model.base_model.encoder.layer.5.attention.self.value             | Linear                     | 590 K \n",
      "102 | model.base_model.encoder.layer.5.attention.self.dropout           | Dropout                    | 0     \n",
      "103 | model.base_model.encoder.layer.5.attention.output                 | RobertaSelfOutput          | 592 K \n",
      "104 | model.base_model.encoder.layer.5.attention.output.dense           | Linear                     | 590 K \n",
      "105 | model.base_model.encoder.layer.5.attention.output.LayerNorm       | LayerNorm                  | 1 K   \n",
      "106 | model.base_model.encoder.layer.5.attention.output.dropout         | Dropout                    | 0     \n",
      "107 | model.base_model.encoder.layer.5.intermediate                     | RobertaIntermediate        | 2 M   \n",
      "108 | model.base_model.encoder.layer.5.intermediate.dense               | Linear                     | 2 M   \n",
      "109 | model.base_model.encoder.layer.5.output                           | RobertaOutput              | 2 M   \n",
      "110 | model.base_model.encoder.layer.5.output.dense                     | Linear                     | 2 M   \n",
      "111 | model.base_model.encoder.layer.5.output.LayerNorm                 | LayerNorm                  | 1 K   \n",
      "112 | model.base_model.encoder.layer.5.output.dropout                   | Dropout                    | 0     \n",
      "113 | model.base_model.encoder.layer.6                                  | RobertaLayer               | 7 M   \n",
      "114 | model.base_model.encoder.layer.6.attention                        | RobertaAttention           | 2 M   \n",
      "115 | model.base_model.encoder.layer.6.attention.self                   | RobertaSelfAttention       | 1 M   \n",
      "116 | model.base_model.encoder.layer.6.attention.self.query             | Linear                     | 590 K \n",
      "117 | model.base_model.encoder.layer.6.attention.self.key               | Linear                     | 590 K \n",
      "118 | model.base_model.encoder.layer.6.attention.self.value             | Linear                     | 590 K \n",
      "119 | model.base_model.encoder.layer.6.attention.self.dropout           | Dropout                    | 0     \n",
      "120 | model.base_model.encoder.layer.6.attention.output                 | RobertaSelfOutput          | 592 K \n",
      "121 | model.base_model.encoder.layer.6.attention.output.dense           | Linear                     | 590 K \n",
      "122 | model.base_model.encoder.layer.6.attention.output.LayerNorm       | LayerNorm                  | 1 K   \n",
      "123 | model.base_model.encoder.layer.6.attention.output.dropout         | Dropout                    | 0     \n",
      "124 | model.base_model.encoder.layer.6.intermediate                     | RobertaIntermediate        | 2 M   \n",
      "125 | model.base_model.encoder.layer.6.intermediate.dense               | Linear                     | 2 M   \n",
      "126 | model.base_model.encoder.layer.6.output                           | RobertaOutput              | 2 M   \n",
      "127 | model.base_model.encoder.layer.6.output.dense                     | Linear                     | 2 M   \n",
      "128 | model.base_model.encoder.layer.6.output.LayerNorm                 | LayerNorm                  | 1 K   \n",
      "129 | model.base_model.encoder.layer.6.output.dropout                   | Dropout                    | 0     \n",
      "130 | model.base_model.encoder.layer.7                                  | RobertaLayer               | 7 M   \n",
      "131 | model.base_model.encoder.layer.7.attention                        | RobertaAttention           | 2 M   \n",
      "132 | model.base_model.encoder.layer.7.attention.self                   | RobertaSelfAttention       | 1 M   \n",
      "133 | model.base_model.encoder.layer.7.attention.self.query             | Linear                     | 590 K \n",
      "134 | model.base_model.encoder.layer.7.attention.self.key               | Linear                     | 590 K \n",
      "135 | model.base_model.encoder.layer.7.attention.self.value             | Linear                     | 590 K \n",
      "136 | model.base_model.encoder.layer.7.attention.self.dropout           | Dropout                    | 0     \n",
      "137 | model.base_model.encoder.layer.7.attention.output                 | RobertaSelfOutput          | 592 K \n",
      "138 | model.base_model.encoder.layer.7.attention.output.dense           | Linear                     | 590 K \n",
      "139 | model.base_model.encoder.layer.7.attention.output.LayerNorm       | LayerNorm                  | 1 K   \n",
      "140 | model.base_model.encoder.layer.7.attention.output.dropout         | Dropout                    | 0     \n",
      "141 | model.base_model.encoder.layer.7.intermediate                     | RobertaIntermediate        | 2 M   \n",
      "142 | model.base_model.encoder.layer.7.intermediate.dense               | Linear                     | 2 M   \n",
      "143 | model.base_model.encoder.layer.7.output                           | RobertaOutput              | 2 M   \n",
      "144 | model.base_model.encoder.layer.7.output.dense                     | Linear                     | 2 M   \n",
      "145 | model.base_model.encoder.layer.7.output.LayerNorm                 | LayerNorm                  | 1 K   \n",
      "146 | model.base_model.encoder.layer.7.output.dropout                   | Dropout                    | 0     \n",
      "147 | model.base_model.encoder.layer.8                                  | RobertaLayer               | 7 M   \n",
      "148 | model.base_model.encoder.layer.8.attention                        | RobertaAttention           | 2 M   \n",
      "149 | model.base_model.encoder.layer.8.attention.self                   | RobertaSelfAttention       | 1 M   \n",
      "150 | model.base_model.encoder.layer.8.attention.self.query             | Linear                     | 590 K \n",
      "151 | model.base_model.encoder.layer.8.attention.self.key               | Linear                     | 590 K \n",
      "152 | model.base_model.encoder.layer.8.attention.self.value             | Linear                     | 590 K \n",
      "153 | model.base_model.encoder.layer.8.attention.self.dropout           | Dropout                    | 0     \n",
      "154 | model.base_model.encoder.layer.8.attention.output                 | RobertaSelfOutput          | 592 K \n",
      "155 | model.base_model.encoder.layer.8.attention.output.dense           | Linear                     | 590 K \n",
      "156 | model.base_model.encoder.layer.8.attention.output.LayerNorm       | LayerNorm                  | 1 K   \n",
      "157 | model.base_model.encoder.layer.8.attention.output.dropout         | Dropout                    | 0     \n",
      "158 | model.base_model.encoder.layer.8.intermediate                     | RobertaIntermediate        | 2 M   \n",
      "159 | model.base_model.encoder.layer.8.intermediate.dense               | Linear                     | 2 M   \n",
      "160 | model.base_model.encoder.layer.8.output                           | RobertaOutput              | 2 M   \n",
      "161 | model.base_model.encoder.layer.8.output.dense                     | Linear                     | 2 M   \n",
      "162 | model.base_model.encoder.layer.8.output.LayerNorm                 | LayerNorm                  | 1 K   \n",
      "163 | model.base_model.encoder.layer.8.output.dropout                   | Dropout                    | 0     \n",
      "164 | model.base_model.encoder.layer.9                                  | RobertaLayer               | 7 M   \n",
      "165 | model.base_model.encoder.layer.9.attention                        | RobertaAttention           | 2 M   \n",
      "166 | model.base_model.encoder.layer.9.attention.self                   | RobertaSelfAttention       | 1 M   \n",
      "167 | model.base_model.encoder.layer.9.attention.self.query             | Linear                     | 590 K \n",
      "168 | model.base_model.encoder.layer.9.attention.self.key               | Linear                     | 590 K \n",
      "169 | model.base_model.encoder.layer.9.attention.self.value             | Linear                     | 590 K \n",
      "170 | model.base_model.encoder.layer.9.attention.self.dropout           | Dropout                    | 0     \n",
      "171 | model.base_model.encoder.layer.9.attention.output                 | RobertaSelfOutput          | 592 K \n",
      "172 | model.base_model.encoder.layer.9.attention.output.dense           | Linear                     | 590 K \n",
      "173 | model.base_model.encoder.layer.9.attention.output.LayerNorm       | LayerNorm                  | 1 K   \n",
      "174 | model.base_model.encoder.layer.9.attention.output.dropout         | Dropout                    | 0     \n",
      "175 | model.base_model.encoder.layer.9.intermediate                     | RobertaIntermediate        | 2 M   \n",
      "176 | model.base_model.encoder.layer.9.intermediate.dense               | Linear                     | 2 M   \n",
      "177 | model.base_model.encoder.layer.9.output                           | RobertaOutput              | 2 M   \n",
      "178 | model.base_model.encoder.layer.9.output.dense                     | Linear                     | 2 M   \n",
      "179 | model.base_model.encoder.layer.9.output.LayerNorm                 | LayerNorm                  | 1 K   \n",
      "180 | model.base_model.encoder.layer.9.output.dropout                   | Dropout                    | 0     \n",
      "181 | model.base_model.encoder.layer.10                                 | RobertaLayer               | 7 M   \n",
      "182 | model.base_model.encoder.layer.10.attention                       | RobertaAttention           | 2 M   \n",
      "183 | model.base_model.encoder.layer.10.attention.self                  | RobertaSelfAttention       | 1 M   \n",
      "184 | model.base_model.encoder.layer.10.attention.self.query            | Linear                     | 590 K \n",
      "185 | model.base_model.encoder.layer.10.attention.self.key              | Linear                     | 590 K \n",
      "186 | model.base_model.encoder.layer.10.attention.self.value            | Linear                     | 590 K \n",
      "187 | model.base_model.encoder.layer.10.attention.self.dropout          | Dropout                    | 0     \n",
      "188 | model.base_model.encoder.layer.10.attention.output                | RobertaSelfOutput          | 592 K \n",
      "189 | model.base_model.encoder.layer.10.attention.output.dense          | Linear                     | 590 K \n",
      "190 | model.base_model.encoder.layer.10.attention.output.LayerNorm      | LayerNorm                  | 1 K   \n",
      "191 | model.base_model.encoder.layer.10.attention.output.dropout        | Dropout                    | 0     \n",
      "192 | model.base_model.encoder.layer.10.intermediate                    | RobertaIntermediate        | 2 M   \n",
      "193 | model.base_model.encoder.layer.10.intermediate.dense              | Linear                     | 2 M   \n",
      "194 | model.base_model.encoder.layer.10.output                          | RobertaOutput              | 2 M   \n",
      "195 | model.base_model.encoder.layer.10.output.dense                    | Linear                     | 2 M   \n",
      "196 | model.base_model.encoder.layer.10.output.LayerNorm                | LayerNorm                  | 1 K   \n",
      "197 | model.base_model.encoder.layer.10.output.dropout                  | Dropout                    | 0     \n",
      "198 | model.base_model.encoder.layer.11                                 | RobertaLayer               | 7 M   \n",
      "199 | model.base_model.encoder.layer.11.attention                       | RobertaAttention           | 2 M   \n",
      "200 | model.base_model.encoder.layer.11.attention.self                  | RobertaSelfAttention       | 1 M   \n",
      "201 | model.base_model.encoder.layer.11.attention.self.query            | Linear                     | 590 K \n",
      "202 | model.base_model.encoder.layer.11.attention.self.key              | Linear                     | 590 K \n",
      "203 | model.base_model.encoder.layer.11.attention.self.value            | Linear                     | 590 K \n",
      "204 | model.base_model.encoder.layer.11.attention.self.dropout          | Dropout                    | 0     \n",
      "205 | model.base_model.encoder.layer.11.attention.output                | RobertaSelfOutput          | 592 K \n",
      "206 | model.base_model.encoder.layer.11.attention.output.dense          | Linear                     | 590 K \n",
      "207 | model.base_model.encoder.layer.11.attention.output.LayerNorm      | LayerNorm                  | 1 K   \n",
      "208 | model.base_model.encoder.layer.11.attention.output.dropout        | Dropout                    | 0     \n",
      "209 | model.base_model.encoder.layer.11.intermediate                    | RobertaIntermediate        | 2 M   \n",
      "210 | model.base_model.encoder.layer.11.intermediate.dense              | Linear                     | 2 M   \n",
      "211 | model.base_model.encoder.layer.11.output                          | RobertaOutput              | 2 M   \n",
      "212 | model.base_model.encoder.layer.11.output.dense                    | Linear                     | 2 M   \n",
      "213 | model.base_model.encoder.layer.11.output.LayerNorm                | LayerNorm                  | 1 K   \n",
      "214 | model.base_model.encoder.layer.11.output.dropout                  | Dropout                    | 0     \n",
      "215 | model.classifier                                                  | Sequential                 | 592 K \n",
      "216 | model.classifier.0                                                | Dropout                    | 0     \n",
      "217 | model.classifier.1                                                | Linear                     | 590 K \n",
      "218 | model.classifier.2                                                | Mish                       | 0     \n",
      "219 | model.classifier.3                                                | Dropout                    | 0     \n",
      "220 | model.classifier.4                                                | Linear                     | 1 K   \n",
      "221 | loss                                                              | CrossEntropyLoss           | 0     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20:  81%|████████  | 30/37 [00:03<00:00,  7.99it/s, loss=0.353, train_loss=0.364, v_num=124]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train (using cuda)\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=hparams.epochs, progress_bar_refresh_rate=10,\n",
    "                     accumulate_grad_batches=hparams.accumulate_grad_batches,\n",
    "                     early_stop_callback=early_stop_callback)\n",
    "\n",
    "trainer.fit(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model (uncomment to save)\n",
    "\n",
    "# module.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    progress = [\"/\", \"-\", \"\\\\\", \"|\", \"/\", \"-\", \"\\\\\", \"|\"]\n",
    "    module.eval().cuda()\n",
    "    true_y, pred_y = [], []\n",
    "    for i, batch_ in enumerate(module.test_dataloader()):\n",
    "        (X, attn), y = batch_\n",
    "        batch = (X.cuda(), attn.cuda())\n",
    "        print(progress[i % len(progress)], end=\"\\r\")\n",
    "        y_pred = torch.argmax(module(batch), dim=1)\n",
    "        true_y.extend(y.cpu())\n",
    "        pred_y.extend(y_pred.cpu())\n",
    "print(\"\\n\" + \"_\" * 80)\n",
    "print(classification_report(true_y, pred_y, target_names=label2int.keys(), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot confusion matrix\n",
    "\n",
    "cm = confusion_matrix(true_y, pred_y, labels=range(len(labels)))\n",
    "df_cm = pd.DataFrame(cm, index = labels, columns = labels)\n",
    "\n",
    "plt.rcParams.update({'font.size': 12}) \n",
    "plt.figure(figsize = (10,8));\n",
    "sn.heatmap(df_cm, annot=True, cmap='Greens', fmt='g');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tune on EmpatheticPersonas data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we define the paths for train, val, test\n",
    "train_path = \"empathy_dataset/my_train.txt\"\n",
    "test_path = \"empathy_dataset/my_test.txt\"\n",
    "val_path = \"empathy_dataset/my_val.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use PyTorch Lighning for training. Lightning methods are defined here\n",
    "\n",
    "class TrainingModule(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.model = EmpathyClassificationModel(AutoModelWithLMHead.from_pretrained(\"roberta-base\").base_model, len(labels))\n",
    "        self.loss = nn.CrossEntropyLoss() \n",
    "        self.hparams = hparams\n",
    "        #  self.save_hyperparameters(hparams)\n",
    "\n",
    "    def step(self, batch, step_name=\"train\"):\n",
    "        X, y = batch\n",
    "        loss = self.loss(self.forward(X), y)\n",
    "        loss_key = f\"{step_name}_loss\"\n",
    "        tensorboard_logs = {loss_key: loss}\n",
    "\n",
    "        return { (\"loss\" if step_name == \"train\" else loss_key): loss, 'log': tensorboard_logs,\n",
    "               \"progress_bar\": {loss_key: loss}}\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        return self.model(X, *args)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"train\")\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"val\")\n",
    "\n",
    "    def validation_end(self, outputs: List[dict]):\n",
    "        loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        return {\"val_loss\": loss}\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"test\")\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.train_path, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.val_path)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.test_path)\n",
    "                \n",
    "    def create_data_loader(self, ds_path: str, shuffle=False):\n",
    "        return DataLoader(\n",
    "                    EmpathyDataset(ds_path),\n",
    "                    batch_size=self.hparams.batch_size,\n",
    "                    shuffle=shuffle,\n",
    "                    collate_fn=TokenizersCollateFn()\n",
    "        )\n",
    "        \n",
    "    @lru_cache()\n",
    "    def total_steps(self):\n",
    "        return len(self.train_dataloader()) // self.hparams.accumulate_grad_batches * self.hparams.epochs\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.model.parameters(), lr=self.hparams.lr) #we use AdamW as this usually performs well\n",
    "        lr_scheduler = get_linear_schedule_with_warmup(\n",
    "                    optimizer,\n",
    "                    num_warmup_steps=self.hparams.warmup_steps,\n",
    "                    num_training_steps=self.total_steps(),\n",
    "        )\n",
    "        return [optimizer], [{\"scheduler\": lr_scheduler, \"interval\": \"step\"}]\n",
    "    \n",
    "    def save_model(self, version):\n",
    "        torch.save(self.model.state_dict(), f'empathy_model/RoBERTa_empathy_2ft_2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = Namespace(\n",
    "    train_path=train_path,\n",
    "    val_path=val_path,\n",
    "    test_path=test_path,\n",
    "    batch_size=20,\n",
    "    warmup_steps=100,\n",
    "    epochs=30,\n",
    "    lr=2E-06,\n",
    "    accumulate_grad_batches=1\n",
    ")\n",
    "module = TrainingModule(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingModule(\n",
       "  (model): EmpathyClassificationModel(\n",
       "    (base_model): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): Sequential(\n",
       "      (0): Dropout(p=0.05, inplace=False)\n",
       "      (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (2): Mish()\n",
       "      (3): Dropout(p=0.05, inplace=False)\n",
       "      (4): Linear(in_features=768, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (loss): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "module.model.load_state_dict(torch.load('empathy_model/RoBERTa_empathy_2ft_2.pt'))\n",
    "module.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rubbish collection\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",  # monitor validation loss\n",
    "    min_delta=0.001, #to very small change in the monitored quantity to qualify as an improvement\n",
    "    patience=20, # used to check number of time with no improvement after which training will be stopped\n",
    "    verbose=False, \n",
    "    mode=\"min\" #sed while training will stopped when the quantity monitor has stopped decreasing\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:GPU available: True, used: True\n",
      "INFO:lightning:CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\yisiang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:23: RuntimeWarning: You have defined a `val_dataloader()` and have defined a `validation_step()`, you may also want to define `validation_epoch_end()` for accumulating stats.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\yisiang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:23: RuntimeWarning: You have defined a `test_dataloader()` and have defined a `test_step()`, you may also want to define `test_epoch_end()` for accumulating stats.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\yisiang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "INFO:lightning:\n",
      "    | Name                                                              | Type                       | Params\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "0   | model                                                             | EmpathyClassificationModel | 124 M \n",
      "1   | model.base_model                                                  | RobertaModel               | 124 M \n",
      "2   | model.base_model.embeddings                                       | RobertaEmbeddings          | 39 M  \n",
      "3   | model.base_model.embeddings.word_embeddings                       | Embedding                  | 38 M  \n",
      "4   | model.base_model.embeddings.position_embeddings                   | Embedding                  | 394 K \n",
      "5   | model.base_model.embeddings.token_type_embeddings                 | Embedding                  | 768   \n",
      "6   | model.base_model.embeddings.LayerNorm                             | LayerNorm                  | 1 K   \n",
      "7   | model.base_model.embeddings.dropout                               | Dropout                    | 0     \n",
      "8   | model.base_model.encoder                                          | RobertaEncoder             | 85 M  \n",
      "9   | model.base_model.encoder.layer                                    | ModuleList                 | 85 M  \n",
      "10  | model.base_model.encoder.layer.0                                  | RobertaLayer               | 7 M   \n",
      "11  | model.base_model.encoder.layer.0.attention                        | RobertaAttention           | 2 M   \n",
      "12  | model.base_model.encoder.layer.0.attention.self                   | RobertaSelfAttention       | 1 M   \n",
      "13  | model.base_model.encoder.layer.0.attention.self.query             | Linear                     | 590 K \n",
      "14  | model.base_model.encoder.layer.0.attention.self.key               | Linear                     | 590 K \n",
      "15  | model.base_model.encoder.layer.0.attention.self.value             | Linear                     | 590 K \n",
      "16  | model.base_model.encoder.layer.0.attention.self.dropout           | Dropout                    | 0     \n",
      "17  | model.base_model.encoder.layer.0.attention.output                 | RobertaSelfOutput          | 592 K \n",
      "18  | model.base_model.encoder.layer.0.attention.output.dense           | Linear                     | 590 K \n",
      "19  | model.base_model.encoder.layer.0.attention.output.LayerNorm       | LayerNorm                  | 1 K   \n",
      "20  | model.base_model.encoder.layer.0.attention.output.dropout         | Dropout                    | 0     \n",
      "21  | model.base_model.encoder.layer.0.intermediate                     | RobertaIntermediate        | 2 M   \n",
      "22  | model.base_model.encoder.layer.0.intermediate.dense               | Linear                     | 2 M   \n",
      "23  | model.base_model.encoder.layer.0.intermediate.intermediate_act_fn | GELUActivation             | 0     \n",
      "24  | model.base_model.encoder.layer.0.output                           | RobertaOutput              | 2 M   \n",
      "25  | model.base_model.encoder.layer.0.output.dense                     | Linear                     | 2 M   \n",
      "26  | model.base_model.encoder.layer.0.output.LayerNorm                 | LayerNorm                  | 1 K   \n",
      "27  | model.base_model.encoder.layer.0.output.dropout                   | Dropout                    | 0     \n",
      "28  | model.base_model.encoder.layer.1                                  | RobertaLayer               | 7 M   \n",
      "29  | model.base_model.encoder.layer.1.attention                        | RobertaAttention           | 2 M   \n",
      "30  | model.base_model.encoder.layer.1.attention.self                   | RobertaSelfAttention       | 1 M   \n",
      "31  | model.base_model.encoder.layer.1.attention.self.query             | Linear                     | 590 K \n",
      "32  | model.base_model.encoder.layer.1.attention.self.key               | Linear                     | 590 K \n",
      "33  | model.base_model.encoder.layer.1.attention.self.value             | Linear                     | 590 K \n",
      "34  | model.base_model.encoder.layer.1.attention.self.dropout           | Dropout                    | 0     \n",
      "35  | model.base_model.encoder.layer.1.attention.output                 | RobertaSelfOutput          | 592 K \n",
      "36  | model.base_model.encoder.layer.1.attention.output.dense           | Linear                     | 590 K \n",
      "37  | model.base_model.encoder.layer.1.attention.output.LayerNorm       | LayerNorm                  | 1 K   \n",
      "38  | model.base_model.encoder.layer.1.attention.output.dropout         | Dropout                    | 0     \n",
      "39  | model.base_model.encoder.layer.1.intermediate                     | RobertaIntermediate        | 2 M   \n",
      "40  | model.base_model.encoder.layer.1.intermediate.dense               | Linear                     | 2 M   \n",
      "41  | model.base_model.encoder.layer.1.output                           | RobertaOutput              | 2 M   \n",
      "42  | model.base_model.encoder.layer.1.output.dense                     | Linear                     | 2 M   \n",
      "43  | model.base_model.encoder.layer.1.output.LayerNorm                 | LayerNorm                  | 1 K   \n",
      "44  | model.base_model.encoder.layer.1.output.dropout                   | Dropout                    | 0     \n",
      "45  | model.base_model.encoder.layer.2                                  | RobertaLayer               | 7 M   \n",
      "46  | model.base_model.encoder.layer.2.attention                        | RobertaAttention           | 2 M   \n",
      "47  | model.base_model.encoder.layer.2.attention.self                   | RobertaSelfAttention       | 1 M   \n",
      "48  | model.base_model.encoder.layer.2.attention.self.query             | Linear                     | 590 K \n",
      "49  | model.base_model.encoder.layer.2.attention.self.key               | Linear                     | 590 K \n",
      "50  | model.base_model.encoder.layer.2.attention.self.value             | Linear                     | 590 K \n",
      "51  | model.base_model.encoder.layer.2.attention.self.dropout           | Dropout                    | 0     \n",
      "52  | model.base_model.encoder.layer.2.attention.output                 | RobertaSelfOutput          | 592 K \n",
      "53  | model.base_model.encoder.layer.2.attention.output.dense           | Linear                     | 590 K \n",
      "54  | model.base_model.encoder.layer.2.attention.output.LayerNorm       | LayerNorm                  | 1 K   \n",
      "55  | model.base_model.encoder.layer.2.attention.output.dropout         | Dropout                    | 0     \n",
      "56  | model.base_model.encoder.layer.2.intermediate                     | RobertaIntermediate        | 2 M   \n",
      "57  | model.base_model.encoder.layer.2.intermediate.dense               | Linear                     | 2 M   \n",
      "58  | model.base_model.encoder.layer.2.output                           | RobertaOutput              | 2 M   \n",
      "59  | model.base_model.encoder.layer.2.output.dense                     | Linear                     | 2 M   \n",
      "60  | model.base_model.encoder.layer.2.output.LayerNorm                 | LayerNorm                  | 1 K   \n",
      "61  | model.base_model.encoder.layer.2.output.dropout                   | Dropout                    | 0     \n",
      "62  | model.base_model.encoder.layer.3                                  | RobertaLayer               | 7 M   \n",
      "63  | model.base_model.encoder.layer.3.attention                        | RobertaAttention           | 2 M   \n",
      "64  | model.base_model.encoder.layer.3.attention.self                   | RobertaSelfAttention       | 1 M   \n",
      "65  | model.base_model.encoder.layer.3.attention.self.query             | Linear                     | 590 K \n",
      "66  | model.base_model.encoder.layer.3.attention.self.key               | Linear                     | 590 K \n",
      "67  | model.base_model.encoder.layer.3.attention.self.value             | Linear                     | 590 K \n",
      "68  | model.base_model.encoder.layer.3.attention.self.dropout           | Dropout                    | 0     \n",
      "69  | model.base_model.encoder.layer.3.attention.output                 | RobertaSelfOutput          | 592 K \n",
      "70  | model.base_model.encoder.layer.3.attention.output.dense           | Linear                     | 590 K \n",
      "71  | model.base_model.encoder.layer.3.attention.output.LayerNorm       | LayerNorm                  | 1 K   \n",
      "72  | model.base_model.encoder.layer.3.attention.output.dropout         | Dropout                    | 0     \n",
      "73  | model.base_model.encoder.layer.3.intermediate                     | RobertaIntermediate        | 2 M   \n",
      "74  | model.base_model.encoder.layer.3.intermediate.dense               | Linear                     | 2 M   \n",
      "75  | model.base_model.encoder.layer.3.output                           | RobertaOutput              | 2 M   \n",
      "76  | model.base_model.encoder.layer.3.output.dense                     | Linear                     | 2 M   \n",
      "77  | model.base_model.encoder.layer.3.output.LayerNorm                 | LayerNorm                  | 1 K   \n",
      "78  | model.base_model.encoder.layer.3.output.dropout                   | Dropout                    | 0     \n",
      "79  | model.base_model.encoder.layer.4                                  | RobertaLayer               | 7 M   \n",
      "80  | model.base_model.encoder.layer.4.attention                        | RobertaAttention           | 2 M   \n",
      "81  | model.base_model.encoder.layer.4.attention.self                   | RobertaSelfAttention       | 1 M   \n",
      "82  | model.base_model.encoder.layer.4.attention.self.query             | Linear                     | 590 K \n",
      "83  | model.base_model.encoder.layer.4.attention.self.key               | Linear                     | 590 K \n",
      "84  | model.base_model.encoder.layer.4.attention.self.value             | Linear                     | 590 K \n",
      "85  | model.base_model.encoder.layer.4.attention.self.dropout           | Dropout                    | 0     \n",
      "86  | model.base_model.encoder.layer.4.attention.output                 | RobertaSelfOutput          | 592 K \n",
      "87  | model.base_model.encoder.layer.4.attention.output.dense           | Linear                     | 590 K \n",
      "88  | model.base_model.encoder.layer.4.attention.output.LayerNorm       | LayerNorm                  | 1 K   \n",
      "89  | model.base_model.encoder.layer.4.attention.output.dropout         | Dropout                    | 0     \n",
      "90  | model.base_model.encoder.layer.4.intermediate                     | RobertaIntermediate        | 2 M   \n",
      "91  | model.base_model.encoder.layer.4.intermediate.dense               | Linear                     | 2 M   \n",
      "92  | model.base_model.encoder.layer.4.output                           | RobertaOutput              | 2 M   \n",
      "93  | model.base_model.encoder.layer.4.output.dense                     | Linear                     | 2 M   \n",
      "94  | model.base_model.encoder.layer.4.output.LayerNorm                 | LayerNorm                  | 1 K   \n",
      "95  | model.base_model.encoder.layer.4.output.dropout                   | Dropout                    | 0     \n",
      "96  | model.base_model.encoder.layer.5                                  | RobertaLayer               | 7 M   \n",
      "97  | model.base_model.encoder.layer.5.attention                        | RobertaAttention           | 2 M   \n",
      "98  | model.base_model.encoder.layer.5.attention.self                   | RobertaSelfAttention       | 1 M   \n",
      "99  | model.base_model.encoder.layer.5.attention.self.query             | Linear                     | 590 K \n",
      "100 | model.base_model.encoder.layer.5.attention.self.key               | Linear                     | 590 K \n",
      "101 | model.base_model.encoder.layer.5.attention.self.value             | Linear                     | 590 K \n",
      "102 | model.base_model.encoder.layer.5.attention.self.dropout           | Dropout                    | 0     \n",
      "103 | model.base_model.encoder.layer.5.attention.output                 | RobertaSelfOutput          | 592 K \n",
      "104 | model.base_model.encoder.layer.5.attention.output.dense           | Linear                     | 590 K \n",
      "105 | model.base_model.encoder.layer.5.attention.output.LayerNorm       | LayerNorm                  | 1 K   \n",
      "106 | model.base_model.encoder.layer.5.attention.output.dropout         | Dropout                    | 0     \n",
      "107 | model.base_model.encoder.layer.5.intermediate                     | RobertaIntermediate        | 2 M   \n",
      "108 | model.base_model.encoder.layer.5.intermediate.dense               | Linear                     | 2 M   \n",
      "109 | model.base_model.encoder.layer.5.output                           | RobertaOutput              | 2 M   \n",
      "110 | model.base_model.encoder.layer.5.output.dense                     | Linear                     | 2 M   \n",
      "111 | model.base_model.encoder.layer.5.output.LayerNorm                 | LayerNorm                  | 1 K   \n",
      "112 | model.base_model.encoder.layer.5.output.dropout                   | Dropout                    | 0     \n",
      "113 | model.base_model.encoder.layer.6                                  | RobertaLayer               | 7 M   \n",
      "114 | model.base_model.encoder.layer.6.attention                        | RobertaAttention           | 2 M   \n",
      "115 | model.base_model.encoder.layer.6.attention.self                   | RobertaSelfAttention       | 1 M   \n",
      "116 | model.base_model.encoder.layer.6.attention.self.query             | Linear                     | 590 K \n",
      "117 | model.base_model.encoder.layer.6.attention.self.key               | Linear                     | 590 K \n",
      "118 | model.base_model.encoder.layer.6.attention.self.value             | Linear                     | 590 K \n",
      "119 | model.base_model.encoder.layer.6.attention.self.dropout           | Dropout                    | 0     \n",
      "120 | model.base_model.encoder.layer.6.attention.output                 | RobertaSelfOutput          | 592 K \n",
      "121 | model.base_model.encoder.layer.6.attention.output.dense           | Linear                     | 590 K \n",
      "122 | model.base_model.encoder.layer.6.attention.output.LayerNorm       | LayerNorm                  | 1 K   \n",
      "123 | model.base_model.encoder.layer.6.attention.output.dropout         | Dropout                    | 0     \n",
      "124 | model.base_model.encoder.layer.6.intermediate                     | RobertaIntermediate        | 2 M   \n",
      "125 | model.base_model.encoder.layer.6.intermediate.dense               | Linear                     | 2 M   \n",
      "126 | model.base_model.encoder.layer.6.output                           | RobertaOutput              | 2 M   \n",
      "127 | model.base_model.encoder.layer.6.output.dense                     | Linear                     | 2 M   \n",
      "128 | model.base_model.encoder.layer.6.output.LayerNorm                 | LayerNorm                  | 1 K   \n",
      "129 | model.base_model.encoder.layer.6.output.dropout                   | Dropout                    | 0     \n",
      "130 | model.base_model.encoder.layer.7                                  | RobertaLayer               | 7 M   \n",
      "131 | model.base_model.encoder.layer.7.attention                        | RobertaAttention           | 2 M   \n",
      "132 | model.base_model.encoder.layer.7.attention.self                   | RobertaSelfAttention       | 1 M   \n",
      "133 | model.base_model.encoder.layer.7.attention.self.query             | Linear                     | 590 K \n",
      "134 | model.base_model.encoder.layer.7.attention.self.key               | Linear                     | 590 K \n",
      "135 | model.base_model.encoder.layer.7.attention.self.value             | Linear                     | 590 K \n",
      "136 | model.base_model.encoder.layer.7.attention.self.dropout           | Dropout                    | 0     \n",
      "137 | model.base_model.encoder.layer.7.attention.output                 | RobertaSelfOutput          | 592 K \n",
      "138 | model.base_model.encoder.layer.7.attention.output.dense           | Linear                     | 590 K \n",
      "139 | model.base_model.encoder.layer.7.attention.output.LayerNorm       | LayerNorm                  | 1 K   \n",
      "140 | model.base_model.encoder.layer.7.attention.output.dropout         | Dropout                    | 0     \n",
      "141 | model.base_model.encoder.layer.7.intermediate                     | RobertaIntermediate        | 2 M   \n",
      "142 | model.base_model.encoder.layer.7.intermediate.dense               | Linear                     | 2 M   \n",
      "143 | model.base_model.encoder.layer.7.output                           | RobertaOutput              | 2 M   \n",
      "144 | model.base_model.encoder.layer.7.output.dense                     | Linear                     | 2 M   \n",
      "145 | model.base_model.encoder.layer.7.output.LayerNorm                 | LayerNorm                  | 1 K   \n",
      "146 | model.base_model.encoder.layer.7.output.dropout                   | Dropout                    | 0     \n",
      "147 | model.base_model.encoder.layer.8                                  | RobertaLayer               | 7 M   \n",
      "148 | model.base_model.encoder.layer.8.attention                        | RobertaAttention           | 2 M   \n",
      "149 | model.base_model.encoder.layer.8.attention.self                   | RobertaSelfAttention       | 1 M   \n",
      "150 | model.base_model.encoder.layer.8.attention.self.query             | Linear                     | 590 K \n",
      "151 | model.base_model.encoder.layer.8.attention.self.key               | Linear                     | 590 K \n",
      "152 | model.base_model.encoder.layer.8.attention.self.value             | Linear                     | 590 K \n",
      "153 | model.base_model.encoder.layer.8.attention.self.dropout           | Dropout                    | 0     \n",
      "154 | model.base_model.encoder.layer.8.attention.output                 | RobertaSelfOutput          | 592 K \n",
      "155 | model.base_model.encoder.layer.8.attention.output.dense           | Linear                     | 590 K \n",
      "156 | model.base_model.encoder.layer.8.attention.output.LayerNorm       | LayerNorm                  | 1 K   \n",
      "157 | model.base_model.encoder.layer.8.attention.output.dropout         | Dropout                    | 0     \n",
      "158 | model.base_model.encoder.layer.8.intermediate                     | RobertaIntermediate        | 2 M   \n",
      "159 | model.base_model.encoder.layer.8.intermediate.dense               | Linear                     | 2 M   \n",
      "160 | model.base_model.encoder.layer.8.output                           | RobertaOutput              | 2 M   \n",
      "161 | model.base_model.encoder.layer.8.output.dense                     | Linear                     | 2 M   \n",
      "162 | model.base_model.encoder.layer.8.output.LayerNorm                 | LayerNorm                  | 1 K   \n",
      "163 | model.base_model.encoder.layer.8.output.dropout                   | Dropout                    | 0     \n",
      "164 | model.base_model.encoder.layer.9                                  | RobertaLayer               | 7 M   \n",
      "165 | model.base_model.encoder.layer.9.attention                        | RobertaAttention           | 2 M   \n",
      "166 | model.base_model.encoder.layer.9.attention.self                   | RobertaSelfAttention       | 1 M   \n",
      "167 | model.base_model.encoder.layer.9.attention.self.query             | Linear                     | 590 K \n",
      "168 | model.base_model.encoder.layer.9.attention.self.key               | Linear                     | 590 K \n",
      "169 | model.base_model.encoder.layer.9.attention.self.value             | Linear                     | 590 K \n",
      "170 | model.base_model.encoder.layer.9.attention.self.dropout           | Dropout                    | 0     \n",
      "171 | model.base_model.encoder.layer.9.attention.output                 | RobertaSelfOutput          | 592 K \n",
      "172 | model.base_model.encoder.layer.9.attention.output.dense           | Linear                     | 590 K \n",
      "173 | model.base_model.encoder.layer.9.attention.output.LayerNorm       | LayerNorm                  | 1 K   \n",
      "174 | model.base_model.encoder.layer.9.attention.output.dropout         | Dropout                    | 0     \n",
      "175 | model.base_model.encoder.layer.9.intermediate                     | RobertaIntermediate        | 2 M   \n",
      "176 | model.base_model.encoder.layer.9.intermediate.dense               | Linear                     | 2 M   \n",
      "177 | model.base_model.encoder.layer.9.output                           | RobertaOutput              | 2 M   \n",
      "178 | model.base_model.encoder.layer.9.output.dense                     | Linear                     | 2 M   \n",
      "179 | model.base_model.encoder.layer.9.output.LayerNorm                 | LayerNorm                  | 1 K   \n",
      "180 | model.base_model.encoder.layer.9.output.dropout                   | Dropout                    | 0     \n",
      "181 | model.base_model.encoder.layer.10                                 | RobertaLayer               | 7 M   \n",
      "182 | model.base_model.encoder.layer.10.attention                       | RobertaAttention           | 2 M   \n",
      "183 | model.base_model.encoder.layer.10.attention.self                  | RobertaSelfAttention       | 1 M   \n",
      "184 | model.base_model.encoder.layer.10.attention.self.query            | Linear                     | 590 K \n",
      "185 | model.base_model.encoder.layer.10.attention.self.key              | Linear                     | 590 K \n",
      "186 | model.base_model.encoder.layer.10.attention.self.value            | Linear                     | 590 K \n",
      "187 | model.base_model.encoder.layer.10.attention.self.dropout          | Dropout                    | 0     \n",
      "188 | model.base_model.encoder.layer.10.attention.output                | RobertaSelfOutput          | 592 K \n",
      "189 | model.base_model.encoder.layer.10.attention.output.dense          | Linear                     | 590 K \n",
      "190 | model.base_model.encoder.layer.10.attention.output.LayerNorm      | LayerNorm                  | 1 K   \n",
      "191 | model.base_model.encoder.layer.10.attention.output.dropout        | Dropout                    | 0     \n",
      "192 | model.base_model.encoder.layer.10.intermediate                    | RobertaIntermediate        | 2 M   \n",
      "193 | model.base_model.encoder.layer.10.intermediate.dense              | Linear                     | 2 M   \n",
      "194 | model.base_model.encoder.layer.10.output                          | RobertaOutput              | 2 M   \n",
      "195 | model.base_model.encoder.layer.10.output.dense                    | Linear                     | 2 M   \n",
      "196 | model.base_model.encoder.layer.10.output.LayerNorm                | LayerNorm                  | 1 K   \n",
      "197 | model.base_model.encoder.layer.10.output.dropout                  | Dropout                    | 0     \n",
      "198 | model.base_model.encoder.layer.11                                 | RobertaLayer               | 7 M   \n",
      "199 | model.base_model.encoder.layer.11.attention                       | RobertaAttention           | 2 M   \n",
      "200 | model.base_model.encoder.layer.11.attention.self                  | RobertaSelfAttention       | 1 M   \n",
      "201 | model.base_model.encoder.layer.11.attention.self.query            | Linear                     | 590 K \n",
      "202 | model.base_model.encoder.layer.11.attention.self.key              | Linear                     | 590 K \n",
      "203 | model.base_model.encoder.layer.11.attention.self.value            | Linear                     | 590 K \n",
      "204 | model.base_model.encoder.layer.11.attention.self.dropout          | Dropout                    | 0     \n",
      "205 | model.base_model.encoder.layer.11.attention.output                | RobertaSelfOutput          | 592 K \n",
      "206 | model.base_model.encoder.layer.11.attention.output.dense          | Linear                     | 590 K \n",
      "207 | model.base_model.encoder.layer.11.attention.output.LayerNorm      | LayerNorm                  | 1 K   \n",
      "208 | model.base_model.encoder.layer.11.attention.output.dropout        | Dropout                    | 0     \n",
      "209 | model.base_model.encoder.layer.11.intermediate                    | RobertaIntermediate        | 2 M   \n",
      "210 | model.base_model.encoder.layer.11.intermediate.dense              | Linear                     | 2 M   \n",
      "211 | model.base_model.encoder.layer.11.output                          | RobertaOutput              | 2 M   \n",
      "212 | model.base_model.encoder.layer.11.output.dense                    | Linear                     | 2 M   \n",
      "213 | model.base_model.encoder.layer.11.output.LayerNorm                | LayerNorm                  | 1 K   \n",
      "214 | model.base_model.encoder.layer.11.output.dropout                  | Dropout                    | 0     \n",
      "215 | model.classifier                                                  | Sequential                 | 592 K \n",
      "216 | model.classifier.0                                                | Dropout                    | 0     \n",
      "217 | model.classifier.1                                                | Linear                     | 590 K \n",
      "218 | model.classifier.2                                                | Mish                       | 0     \n",
      "219 | model.classifier.3                                                | Dropout                    | 0     \n",
      "220 | model.classifier.4                                                | Linear                     | 1 K   \n",
      "221 | loss                                                              | CrossEntropyLoss           | 0     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  87%|████████▋ | 60/69 [00:07<00:01,  7.89it/s, loss=0.399, train_loss=0.191, v_num=130] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=hparams.epochs, progress_bar_refresh_rate=10,\n",
    "                     accumulate_grad_batches=hparams.accumulate_grad_batches,\n",
    "                     early_stop_callback=early_stop_callback)\n",
    "\n",
    "trainer.fit(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model (uncomment to save)\n",
    "\n",
    "# module.save_model(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on the EmpatheticPersonas test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\n",
      "________________________________________________________________________________\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        weak     0.8438    0.7500    0.7941        36\n",
      "      strong     0.7692    0.8571    0.8108        35\n",
      "\n",
      "    accuracy                         0.8028        71\n",
      "   macro avg     0.8065    0.8036    0.8025        71\n",
      "weighted avg     0.8070    0.8028    0.8023        71\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    progress = [\"/\", \"-\", \"\\\\\", \"|\", \"/\", \"-\", \"\\\\\", \"|\"]\n",
    "    module.eval().cuda()\n",
    "    true_y, pred_y = [], []\n",
    "    for i, batch_ in enumerate(module.test_dataloader()):\n",
    "        (X, attn), y = batch_\n",
    "        batch = (X.cuda(), attn.cuda())\n",
    "        print(progress[i % len(progress)], end=\"\\r\")\n",
    "        y_pred = torch.argmax(module(batch), dim=1)\n",
    "        true_y.extend(y.cpu())\n",
    "        pred_y.extend(y_pred.cpu())\n",
    "print(\"\\n\" + \"_\" * 80)\n",
    "print(classification_report(true_y, pred_y, target_names=label2int.keys(), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,   713,    34,  ...,     1,     1,     1],\n",
      "        [    0,  8275,    47,  ...,     1,     1,     1],\n",
      "        [    0,  8275,    47,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0,   170,   460,  ...,     4,  1437,     2],\n",
      "        [    0,   243,    18,  ...,     1,     1,     1],\n",
      "        [    0, 30086, 25522,  ...,     1,     1,     1]])\n",
      "tensor([[ 0.3811, -0.8123],\n",
      "        [ 1.7814, -2.3231],\n",
      "        [-0.6400,  0.5160],\n",
      "        [-0.2285,  0.1505],\n",
      "        [-0.2049, -0.0305],\n",
      "        [ 1.7215, -2.2450],\n",
      "        [ 0.6563, -0.8706],\n",
      "        [ 0.7261, -0.9672],\n",
      "        [ 0.5438, -0.6772],\n",
      "        [-1.1121,  1.0881],\n",
      "        [-0.1250, -0.1710],\n",
      "        [-0.7629,  0.6112],\n",
      "        [ 1.8023, -2.3718],\n",
      "        [ 1.8589, -2.3789],\n",
      "        [-0.4662,  0.2900],\n",
      "        [-1.3427,  1.2781],\n",
      "        [-0.3330,  0.2279],\n",
      "        [-1.3490,  1.3040],\n",
      "        [ 1.8564, -2.2931],\n",
      "        [ 0.5708, -0.8322]], device='cuda:0')\n",
      "tensor([0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0],\n",
      "       device='cuda:0')\n",
      "tensor([[    0, 29042,    47,  ...,     1,     1,     1],\n",
      "        [    0, 29042,    47,  ...,     1,     1,     1],\n",
      "        [    0,   100,   437,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0, 11773,    32,  ...,     1,     1,     1],\n",
      "        [    0,  1185,    32,  ...,     1,     1,     1],\n",
      "        [    0, 17781,    47,  ...,     1,     1,     1]])\n",
      "tensor([[-1.0102,  0.8974],\n",
      "        [ 0.9036, -1.3166],\n",
      "        [-1.5878,  1.6191],\n",
      "        [-0.3641,  0.3125],\n",
      "        [-1.4546,  1.4404],\n",
      "        [ 1.8902, -2.1689],\n",
      "        [ 1.6609, -2.1271],\n",
      "        [-0.2231,  0.1408],\n",
      "        [-0.6632,  0.3515],\n",
      "        [-1.1935,  1.1463],\n",
      "        [ 1.2609, -1.4721],\n",
      "        [-0.7658,  0.7351],\n",
      "        [-0.6776,  0.5943],\n",
      "        [ 1.2488, -1.5610],\n",
      "        [-1.2203,  1.2206],\n",
      "        [-0.3003,  0.0447],\n",
      "        [ 0.7806, -1.2219],\n",
      "        [-0.1587,  0.0836],\n",
      "        [-0.0661, -0.0539],\n",
      "        [-1.5423,  1.5929]], device='cuda:0')\n",
      "tensor([1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1],\n",
      "       device='cuda:0')\n",
      "tensor([[    0, 25419, 24353,  ...,     1,     1,     1],\n",
      "        [    0,  7939,    18,  ...,     1,     1,     1],\n",
      "        [    0,  8275,    47,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0, 18114,    10,  ...,     1,     1,     1],\n",
      "        [    0, 16040,  6991,  ...,     1,     1,     1],\n",
      "        [    0, 19065,     6,  ...,     4,  1437,     2]])\n",
      "tensor([[-0.5467,  0.4893],\n",
      "        [ 0.1291, -0.6975],\n",
      "        [ 0.3951, -0.8373],\n",
      "        [-0.4103,  0.4573],\n",
      "        [ 1.1158, -1.3643],\n",
      "        [ 1.5617, -1.9614],\n",
      "        [ 1.4036, -1.8914],\n",
      "        [ 0.1451, -0.2639],\n",
      "        [-0.7116,  0.4921],\n",
      "        [ 0.1083, -0.3601],\n",
      "        [-1.3147,  1.2198],\n",
      "        [ 0.8963, -1.1441],\n",
      "        [ 1.7213, -2.1513],\n",
      "        [-0.7844,  0.7942],\n",
      "        [-1.4478,  1.2659],\n",
      "        [-1.0452,  1.0040],\n",
      "        [-1.4186,  1.3130],\n",
      "        [ 1.8649, -2.2243],\n",
      "        [-0.4798,  0.2951],\n",
      "        [-1.5185,  1.4392]], device='cuda:0')\n",
      "tensor([1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1],\n",
      "       device='cuda:0')\n",
      "tensor([[    0,  4528,  3686,    32,  1537,  2721,  3686,     6,   189,    47,\n",
      "          2807,    65,     4,  3401,  1228,   128, 32757,   108,     7,   517,\n",
      "            15,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    0, 17781,    10, 29826,    10,   860,    19,    42, 25522, 36299,\n",
      "         23558, 24303,   122,     8,    47,   115,  8286,    10,  3143,     9,\n",
      "          8597,     4,  3128,    47,   348,  2121,     5,  1940,     6,  2540,\n",
      "          1228,   535,     4,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    0,   100,    33,   130,  1735,    52,    64,  2807,     7,  2501,\n",
      "           110,  3904,   801,   150,    47,  3014,   110,   310, 21843,     4,\n",
      "          6834,   109,    47,   619,   101,  6475,   452,   116,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    0,   243,  1326,   101,    99,  1102,   938,    75,    99,    47,\n",
      "            56,   421,     6,    24,    18, 19717,    47,   619,    14,   169,\n",
      "             4,  2780,    18,   185,    10,  1151,     7, 12327,     6,   109,\n",
      "            47,   206,    47,    64,  8559,    10,  7923,    31,    24,   116,\n",
      "             2],\n",
      "        [    0, 31414, 25522, 25158, 48268,    38,   524,    10,  3904, 14084,\n",
      "           131,   259,     7,   244,    19,    70,   110,  3904,   782,     4,\n",
      "          1336,    18,    24,   164,   452,   116,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    0,  2709,   201,     7,   860,    42, 25522, 36299, 23558, 48268,\n",
      "           114,    52,   109,    42,    24,   189,   244,    47,  8286,    92,\n",
      "           383,    59,  2512,     4,  3128,   626,     6,  5797,     7,   535,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    0, 10836,    38,  2540,  6581,    47,     7, 25522,   104,  2571,\n",
      "         11883,   291, 48634,   152,  3325,    40,   244,    47, 33136,  5516,\n",
      "         13536,   110,   937,  6563,    15,    10, 14569,   864,     4,   520,\n",
      "          1550,     6,  2540,  1228,   128, 32757,  2652,     2,     1,     1,\n",
      "             1],\n",
      "        [    0,  7939,    18,   122,   213,   149, 25522,   104,  2571, 11883,\n",
      "           545, 24303,     7,   860,     7,   464,   110,  4263,     7,     5,\n",
      "            97,   526,     4,   520,    47,   214,   626,     6,    95,  3753,\n",
      "           128, 32757,  2652,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    0,  5975,    24,    16,    86,     7,   386,     5, 25522, 36299,\n",
      "         23558, 48634,   370,    32,   164,     7,    28,   372,     8,  8286,\n",
      "          2770,   383,    59,  2512,     6,    53,  1228,   535,    77,    47,\n",
      "            32,  1227,     4,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    0, 42337, 28814,   328,   978,    24,    18,    86,    13,   103,\n",
      "          1531,   328,   977,   535,     7,   517,    15,     8,   465,    66,\n",
      "           141,    47,    64,   712,   110,  3904,   801,   328,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    0,  5975,    24,    18,    86,     7,  6581, 25522,   104,  2571,\n",
      "         11883,   291, 48634,   152,    40,   244,    47,     7, 33136,  2992,\n",
      "           110,  5619,    15,   937,  1142,     4,   977,   535,    77,  1550,\n",
      "             4,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1]])\n",
      "tensor([[ 0.8808, -1.3608],\n",
      "        [-1.0075,  0.8761],\n",
      "        [ 0.3303, -0.6972],\n",
      "        [-1.5449,  1.6170],\n",
      "        [-0.6244,  0.4960],\n",
      "        [ 0.0055, -0.4115],\n",
      "        [-1.5015,  1.4826],\n",
      "        [-0.9293,  0.9640],\n",
      "        [ 0.7427, -1.2599],\n",
      "        [ 0.7988, -1.0769],\n",
      "        [-0.8997,  0.9048]], device='cuda:0')\n",
      "tensor([0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1], device='cuda:0')\n",
      "\n",
      "________________________________________________________________________________\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        weak     0.8438    0.7500    0.7941        36\n",
      "      strong     0.7692    0.8571    0.8108        35\n",
      "\n",
      "    accuracy                         0.8028        71\n",
      "   macro avg     0.8065    0.8036    0.8025        71\n",
      "weighted avg     0.8070    0.8028    0.8023        71\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    progress = [\"/\", \"-\", \"\\\\\", \"|\", \"/\", \"-\", \"\\\\\", \"|\"]\n",
    "    module.eval().cuda()\n",
    "    true_y, pred_y = [], []\n",
    "    for i, batch_ in enumerate(module.test_dataloader()):\n",
    "        (X, attn), y = batch_\n",
    "        batch = (X.cuda(), attn.cuda())\n",
    "        print(X)\n",
    "        print(progress[i % len(progress)], end=\"\\r\")\n",
    "        print(module(batch))\n",
    "        y_pred = torch.argmax(module(batch), dim=1)\n",
    "        print(y_pred)\n",
    "        true_y.extend(y.cpu())\n",
    "        pred_y.extend(y_pred.cpu())\n",
    "print(\"\\n\" + \"_\" * 80)\n",
    "print(classification_report(true_y, pred_y, target_names=label2int.keys(), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot confusion matrix\n",
    "\n",
    "cm = confusion_matrix(true_y, pred_y, labels=range(len(labels)))\n",
    "df_cm = pd.DataFrame(cm, index = labels, columns = labels)\n",
    "\n",
    "plt.rcParams.update({'font.size': 12}) \n",
    "plt.figure(figsize = (10,8));\n",
    "sn.heatmap(df_cm, annot=True, cmap='Greens', fmt='g');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54bb103c3e8827112ac287ff09b16e5ca2d85540a3af0b288083619c88e41aa7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
