{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#package imports \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from transformers import DistilBertTokenizer, AutoTokenizer, AutoModelWithLMHead, DistilBertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "\n",
    "from typing import List\n",
    "import logging\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "from functools import lru_cache\n",
    "from argparse import Namespace\n",
    "from packaging import version\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we define the paths for train, val, test (change if desired to match location of splits created in baseline notebook)\n",
    "train_path = \"empathy_dataset/my_train.txt\"\n",
    "test_path = \"empathy_dataset/my_test.txt\"\n",
    "val_path = \"empathy_dataset/my_val.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weak': 0, 'strong': 1}\n"
     ]
    }
   ],
   "source": [
    "#create a dictionary which associates each string label to an integer value\n",
    "labels = [\"weak\", \"strong\"]\n",
    "label2int = dict(zip(labels, list(range(len(labels)))))\n",
    "print(label2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use RoBERTa base model\n",
    "\n",
    "#load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yisiang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:998: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#load actual model\n",
    "model = AutoModelWithLMHead.from_pretrained('roberta-base')\n",
    "base_model = model.base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we need a custom classification head on top of the LM\n",
    "#note: the following code is partly adapted from Marcin Zablocki's tutorial 'custom classifier on top of bert-like language model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Mish activiation function as it's the one proposed in the original tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Mish\n",
    "@torch.jit.script\n",
    "def mish(input):\n",
    "    return input * torch.tanh(F.softplus(input))\n",
    "  \n",
    "class Mish(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return mish(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define an EmpathyClassificationModel class to do the actual fine-tuning\n",
    "\n",
    "class EmpathyClassificationModel(nn.Module):\n",
    "    def __init__(self, base_model, n_classes, base_model_output_size=768, dropout=0.05):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(base_model_output_size, base_model_output_size),\n",
    "            Mish(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(base_model_output_size, n_classes)\n",
    "        )\n",
    "        \n",
    "        for layer in self.classifier:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                layer.weight.data.normal_(mean=0.0, std=0.02)\n",
    "                if layer.bias is not None:\n",
    "                    layer.bias.data.zero_()\n",
    "\n",
    "    def forward(self, input_, *args):\n",
    "        X, attention_mask = input_\n",
    "        hidden_states = self.base_model(X, attention_mask=attention_mask)\n",
    "        \n",
    "        return self.classifier(hidden_states[0][:, 0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now some dataset preparation for the fine-tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tokenizer\\\\tokenizer_config.json',\n",
       " 'tokenizer\\\\special_tokens_map.json',\n",
       " 'tokenizer\\\\vocab.json',\n",
       " 'tokenizer\\\\merges.txt',\n",
       " 'tokenizer\\\\added_tokens.json',\n",
       " 'tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load pretrained tokenizer information\n",
    "tokenizer.save_pretrained(\"tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementation of CollateFN to do tokenization and batches of sequences\n",
    "\n",
    "class TokenizersCollateFn:\n",
    "    def __init__(self, max_tokens=512): \n",
    "\n",
    "        #RoBERTa uses the BPE tokenizer, similarly to GPT-2\n",
    "        t = ByteLevelBPETokenizer(\n",
    "            \"tokenizer/vocab.json\",\n",
    "            \"tokenizer/merges.txt\"\n",
    "        )\n",
    "        t._tokenizer.post_processor = BertProcessing(\n",
    "            (\"</s>\", t.token_to_id(\"</s>\")),\n",
    "            (\"<s>\", t.token_to_id(\"<s>\")),\n",
    "        )\n",
    "        t.enable_truncation(max_tokens)\n",
    "        t.enable_padding(pad_id=t.token_to_id(\"<pad>\"))\n",
    "        self.tokenizer = t\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        encoded = self.tokenizer.encode_batch([x[0] for x in batch])\n",
    "        sequences_padded = torch.tensor([enc.ids for enc in encoded])\n",
    "        attention_masks_padded = torch.tensor([enc.attention_mask for enc in encoded])\n",
    "        labels = torch.tensor([x[1] for x in batch])\n",
    "        \n",
    "        return (sequences_padded, attention_masks_padded), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class to create dataset objects from the data\n",
    "\n",
    "class EmpathyDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        super().__init__()\n",
    "        self.data_column = \"text\"\n",
    "        self.class_column = \"class\"\n",
    "        self.data = pd.read_csv(path, sep=\";\", header=None, names=[self.data_column, self.class_column],\n",
    "                               engine=\"python\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data.loc[idx, self.data_column], label2int[self.data.loc[idx, self.class_column]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Acquiring both charactersitics from {a dichotomy} contributes to nurturing creativity. It could allow you to have more fruitful opportunities from a doubled collection of responses - killing two birds with a stone.',\n",
       " 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check, visualise one sample and label (converted to numerical)\n",
    "ds = EmpathyDataset(train_path)\n",
    "ds[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use PyTorch Lighning for training. Lightning methods are defined here\n",
    "\n",
    "class TrainingModule(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.model = EmpathyClassificationModel(AutoModelWithLMHead.from_pretrained(\"roberta-base\").base_model, len(labels))\n",
    "        self.loss = nn.CrossEntropyLoss() \n",
    "        self.hparams = hparams\n",
    "        #  self.save_hyperparameters(hparams)\n",
    "\n",
    "    def step(self, batch, step_name=\"train\"):\n",
    "        X, y = batch\n",
    "        loss = self.loss(self.forward(X), y)\n",
    "        loss_key = f\"{step_name}_loss\"\n",
    "        tensorboard_logs = {loss_key: loss}\n",
    "\n",
    "        return { (\"loss\" if step_name == \"train\" else loss_key): loss, 'log': tensorboard_logs,\n",
    "               \"progress_bar\": {loss_key: loss}}\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        return self.model(X, *args)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"train\")\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"val\")\n",
    "\n",
    "    def validation_end(self, outputs: List[dict]):\n",
    "        loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        return {\"val_loss\": loss}\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"test\")\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.train_path, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.val_path)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.test_path)\n",
    "                \n",
    "    def create_data_loader(self, ds_path: str, shuffle=False):\n",
    "        return DataLoader(\n",
    "                    EmpathyDataset(ds_path),\n",
    "                    batch_size=self.hparams.batch_size,\n",
    "                    shuffle=shuffle,\n",
    "                    collate_fn=TokenizersCollateFn()\n",
    "        )\n",
    "        \n",
    "    @lru_cache()\n",
    "    def total_steps(self):\n",
    "        return len(self.train_dataloader()) // self.hparams.accumulate_grad_batches * self.hparams.epochs\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.model.parameters(), lr=self.hparams.lr) #we use AdamW as this usually performs well\n",
    "        lr_scheduler = get_linear_schedule_with_warmup(\n",
    "                    optimizer,\n",
    "                    num_warmup_steps=self.hparams.warmup_steps,\n",
    "                    num_training_steps=self.total_steps(),\n",
    "        )\n",
    "        return [optimizer], [{\"scheduler\": lr_scheduler, \"interval\": \"step\"}]\n",
    "    \n",
    "    def save_model(self, version):\n",
    "        torch.save(self.model.state_dict(), f'empathy_model/RoBERTa_empathy_1ft_{version}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chosen hyperparams:\n",
    "hparams = Namespace(\n",
    "    train_path=train_path,\n",
    "    val_path=val_path,\n",
    "    test_path=test_path,\n",
    "    batch_size=20,\n",
    "    warmup_steps=100,\n",
    "    epochs=50,\n",
    "    lr=1E-06,\n",
    "    accumulate_grad_batches=1\n",
    ")\n",
    "module = TrainingModule(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",  # monitor validation loss\n",
    "    min_delta=0.001, #to very small change in the monitored quantity to qualify as an improvement\n",
    "    patience=20, # used to check number of time with no improvement after which training will be stopped\n",
    "    verbose=False, \n",
    "    mode=\"min\" #sed while training will stopped when the quantity monitor has stopped decreasing\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rubbish collection\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:GPU available: True, used: True\n",
      "INFO:lightning:CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\yisiang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:23: RuntimeWarning: You have defined a `val_dataloader()` and have defined a `validation_step()`, you may also want to define `validation_epoch_end()` for accumulating stats.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\yisiang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:23: RuntimeWarning: You have defined a `test_dataloader()` and have defined a `test_step()`, you may also want to define `test_epoch_end()` for accumulating stats.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\yisiang\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "INFO:lightning:\n",
      "    | Name                                                              | Type                       | Params\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "0   | model                                                             | EmpathyClassificationModel | 124 M \n",
      "1   | model.base_model                                                  | RobertaModel               | 124 M \n",
      "2   | model.base_model.embeddings                                       | RobertaEmbeddings          | 39 M  \n",
      "3   | model.base_model.embeddings.word_embeddings                       | Embedding                  | 38 M  \n",
      "4   | model.base_model.embeddings.position_embeddings                   | Embedding                  | 394 K \n",
      "5   | model.base_model.embeddings.token_type_embeddings                 | Embedding                  | 768   \n",
      "6   | model.base_model.embeddings.LayerNorm                             | LayerNorm                  | 1 K   \n",
      "7   | model.base_model.embeddings.dropout                               | Dropout                    | 0     \n",
      "8   | model.base_model.encoder                                          | RobertaEncoder             | 85 M  \n",
      "9   | model.base_model.encoder.layer                                    | ModuleList                 | 85 M  \n",
      "10  | model.base_model.encoder.layer.0                                  | RobertaLayer               | 7 M   \n",
      "11  | model.base_model.encoder.layer.0.attention                        | RobertaAttention           | 2 M   \n",
      "12  | model.base_model.encoder.layer.0.attention.self                   | RobertaSelfAttention       | 1 M   \n",
      "13  | model.base_model.encoder.layer.0.attention.self.query             | Linear                     | 590 K \n",
      "14  | model.base_model.encoder.layer.0.attention.self.key               | Linear                     | 590 K \n",
      "15  | model.base_model.encoder.layer.0.attention.self.value             | Linear                     | 590 K \n",
      "16  | model.base_model.encoder.layer.0.attention.self.dropout           | Dropout                    | 0     \n",
      "17  | model.base_model.encoder.layer.0.attention.output                 | RobertaSelfOutput          | 592 K \n",
      "18  | model.base_model.encoder.layer.0.attention.output.dense           | Linear                     | 590 K \n",
      "19  | model.base_model.encoder.layer.0.attention.output.LayerNorm       | LayerNorm                  | 1 K   \n",
      "20  | model.base_model.encoder.layer.0.attention.output.dropout         | Dropout                    | 0     \n",
      "21  | model.base_model.encoder.layer.0.intermediate                     | RobertaIntermediate        | 2 M   \n",
      "22  | model.base_model.encoder.layer.0.intermediate.dense               | Linear                     | 2 M   \n",
      "23  | model.base_model.encoder.layer.0.intermediate.intermediate_act_fn | GELUActivation             | 0     \n",
      "24  | model.base_model.encoder.layer.0.output                           | RobertaOutput              | 2 M   \n",
      "25  | model.base_model.encoder.layer.0.output.dense                     | Linear                     | 2 M   \n",
      "26  | model.base_model.encoder.layer.0.output.LayerNorm                 | LayerNorm                  | 1 K   \n",
      "27  | model.base_model.encoder.layer.0.output.dropout                   | Dropout                    | 0     \n",
      "28  | model.base_model.encoder.layer.1                                  | RobertaLayer               | 7 M   \n",
      "29  | model.base_model.encoder.layer.1.attention                        | RobertaAttention           | 2 M   \n",
      "30  | model.base_model.encoder.layer.1.attention.self                   | RobertaSelfAttention       | 1 M   \n",
      "31  | model.base_model.encoder.layer.1.attention.self.query             | Linear                     | 590 K \n",
      "32  | model.base_model.encoder.layer.1.attention.self.key               | Linear                     | 590 K \n",
      "33  | model.base_model.encoder.layer.1.attention.self.value             | Linear                     | 590 K \n",
      "34  | model.base_model.encoder.layer.1.attention.self.dropout           | Dropout                    | 0     \n",
      "35  | model.base_model.encoder.layer.1.attention.output                 | RobertaSelfOutput          | 592 K \n",
      "36  | model.base_model.encoder.layer.1.attention.output.dense           | Linear                     | 590 K \n",
      "37  | model.base_model.encoder.layer.1.attention.output.LayerNorm       | LayerNorm                  | 1 K   \n",
      "38  | model.base_model.encoder.layer.1.attention.output.dropout         | Dropout                    | 0     \n",
      "39  | model.base_model.encoder.layer.1.intermediate                     | RobertaIntermediate        | 2 M   \n",
      "40  | model.base_model.encoder.layer.1.intermediate.dense               | Linear                     | 2 M   \n",
      "41  | model.base_model.encoder.layer.1.output                           | RobertaOutput              | 2 M   \n",
      "42  | model.base_model.encoder.layer.1.output.dense                     | Linear                     | 2 M   \n",
      "43  | model.base_model.encoder.layer.1.output.LayerNorm                 | LayerNorm                  | 1 K   \n",
      "44  | model.base_model.encoder.layer.1.output.dropout                   | Dropout                    | 0     \n",
      "45  | model.base_model.encoder.layer.2                                  | RobertaLayer               | 7 M   \n",
      "46  | model.base_model.encoder.layer.2.attention                        | RobertaAttention           | 2 M   \n",
      "47  | model.base_model.encoder.layer.2.attention.self                   | RobertaSelfAttention       | 1 M   \n",
      "48  | model.base_model.encoder.layer.2.attention.self.query             | Linear                     | 590 K \n",
      "49  | model.base_model.encoder.layer.2.attention.self.key               | Linear                     | 590 K \n",
      "50  | model.base_model.encoder.layer.2.attention.self.value             | Linear                     | 590 K \n",
      "51  | model.base_model.encoder.layer.2.attention.self.dropout           | Dropout                    | 0     \n",
      "52  | model.base_model.encoder.layer.2.attention.output                 | RobertaSelfOutput          | 592 K \n",
      "53  | model.base_model.encoder.layer.2.attention.output.dense           | Linear                     | 590 K \n",
      "54  | model.base_model.encoder.layer.2.attention.output.LayerNorm       | LayerNorm                  | 1 K   \n",
      "55  | model.base_model.encoder.layer.2.attention.output.dropout         | Dropout                    | 0     \n",
      "56  | model.base_model.encoder.layer.2.intermediate                     | RobertaIntermediate        | 2 M   \n",
      "57  | model.base_model.encoder.layer.2.intermediate.dense               | Linear                     | 2 M   \n",
      "58  | model.base_model.encoder.layer.2.output                           | RobertaOutput              | 2 M   \n",
      "59  | model.base_model.encoder.layer.2.output.dense                     | Linear                     | 2 M   \n",
      "60  | model.base_model.encoder.layer.2.output.LayerNorm                 | LayerNorm                  | 1 K   \n",
      "61  | model.base_model.encoder.layer.2.output.dropout                   | Dropout                    | 0     \n",
      "62  | model.base_model.encoder.layer.3                                  | RobertaLayer               | 7 M   \n",
      "63  | model.base_model.encoder.layer.3.attention                        | RobertaAttention           | 2 M   \n",
      "64  | model.base_model.encoder.layer.3.attention.self                   | RobertaSelfAttention       | 1 M   \n",
      "65  | model.base_model.encoder.layer.3.attention.self.query             | Linear                     | 590 K \n",
      "66  | model.base_model.encoder.layer.3.attention.self.key               | Linear                     | 590 K \n",
      "67  | model.base_model.encoder.layer.3.attention.self.value             | Linear                     | 590 K \n",
      "68  | model.base_model.encoder.layer.3.attention.self.dropout           | Dropout                    | 0     \n",
      "69  | model.base_model.encoder.layer.3.attention.output                 | RobertaSelfOutput          | 592 K \n",
      "70  | model.base_model.encoder.layer.3.attention.output.dense           | Linear                     | 590 K \n",
      "71  | model.base_model.encoder.layer.3.attention.output.LayerNorm       | LayerNorm                  | 1 K   \n",
      "72  | model.base_model.encoder.layer.3.attention.output.dropout         | Dropout                    | 0     \n",
      "73  | model.base_model.encoder.layer.3.intermediate                     | RobertaIntermediate        | 2 M   \n",
      "74  | model.base_model.encoder.layer.3.intermediate.dense               | Linear                     | 2 M   \n",
      "75  | model.base_model.encoder.layer.3.output                           | RobertaOutput              | 2 M   \n",
      "76  | model.base_model.encoder.layer.3.output.dense                     | Linear                     | 2 M   \n",
      "77  | model.base_model.encoder.layer.3.output.LayerNorm                 | LayerNorm                  | 1 K   \n",
      "78  | model.base_model.encoder.layer.3.output.dropout                   | Dropout                    | 0     \n",
      "79  | model.base_model.encoder.layer.4                                  | RobertaLayer               | 7 M   \n",
      "80  | model.base_model.encoder.layer.4.attention                        | RobertaAttention           | 2 M   \n",
      "81  | model.base_model.encoder.layer.4.attention.self                   | RobertaSelfAttention       | 1 M   \n",
      "82  | model.base_model.encoder.layer.4.attention.self.query             | Linear                     | 590 K \n",
      "83  | model.base_model.encoder.layer.4.attention.self.key               | Linear                     | 590 K \n",
      "84  | model.base_model.encoder.layer.4.attention.self.value             | Linear                     | 590 K \n",
      "85  | model.base_model.encoder.layer.4.attention.self.dropout           | Dropout                    | 0     \n",
      "86  | model.base_model.encoder.layer.4.attention.output                 | RobertaSelfOutput          | 592 K \n",
      "87  | model.base_model.encoder.layer.4.attention.output.dense           | Linear                     | 590 K \n",
      "88  | model.base_model.encoder.layer.4.attention.output.LayerNorm       | LayerNorm                  | 1 K   \n",
      "89  | model.base_model.encoder.layer.4.attention.output.dropout         | Dropout                    | 0     \n",
      "90  | model.base_model.encoder.layer.4.intermediate                     | RobertaIntermediate        | 2 M   \n",
      "91  | model.base_model.encoder.layer.4.intermediate.dense               | Linear                     | 2 M   \n",
      "92  | model.base_model.encoder.layer.4.output                           | RobertaOutput              | 2 M   \n",
      "93  | model.base_model.encoder.layer.4.output.dense                     | Linear                     | 2 M   \n",
      "94  | model.base_model.encoder.layer.4.output.LayerNorm                 | LayerNorm                  | 1 K   \n",
      "95  | model.base_model.encoder.layer.4.output.dropout                   | Dropout                    | 0     \n",
      "96  | model.base_model.encoder.layer.5                                  | RobertaLayer               | 7 M   \n",
      "97  | model.base_model.encoder.layer.5.attention                        | RobertaAttention           | 2 M   \n",
      "98  | model.base_model.encoder.layer.5.attention.self                   | RobertaSelfAttention       | 1 M   \n",
      "99  | model.base_model.encoder.layer.5.attention.self.query             | Linear                     | 590 K \n",
      "100 | model.base_model.encoder.layer.5.attention.self.key               | Linear                     | 590 K \n",
      "101 | model.base_model.encoder.layer.5.attention.self.value             | Linear                     | 590 K \n",
      "102 | model.base_model.encoder.layer.5.attention.self.dropout           | Dropout                    | 0     \n",
      "103 | model.base_model.encoder.layer.5.attention.output                 | RobertaSelfOutput          | 592 K \n",
      "104 | model.base_model.encoder.layer.5.attention.output.dense           | Linear                     | 590 K \n",
      "105 | model.base_model.encoder.layer.5.attention.output.LayerNorm       | LayerNorm                  | 1 K   \n",
      "106 | model.base_model.encoder.layer.5.attention.output.dropout         | Dropout                    | 0     \n",
      "107 | model.base_model.encoder.layer.5.intermediate                     | RobertaIntermediate        | 2 M   \n",
      "108 | model.base_model.encoder.layer.5.intermediate.dense               | Linear                     | 2 M   \n",
      "109 | model.base_model.encoder.layer.5.output                           | RobertaOutput              | 2 M   \n",
      "110 | model.base_model.encoder.layer.5.output.dense                     | Linear                     | 2 M   \n",
      "111 | model.base_model.encoder.layer.5.output.LayerNorm                 | LayerNorm                  | 1 K   \n",
      "112 | model.base_model.encoder.layer.5.output.dropout                   | Dropout                    | 0     \n",
      "113 | model.base_model.encoder.layer.6                                  | RobertaLayer               | 7 M   \n",
      "114 | model.base_model.encoder.layer.6.attention                        | RobertaAttention           | 2 M   \n",
      "115 | model.base_model.encoder.layer.6.attention.self                   | RobertaSelfAttention       | 1 M   \n",
      "116 | model.base_model.encoder.layer.6.attention.self.query             | Linear                     | 590 K \n",
      "117 | model.base_model.encoder.layer.6.attention.self.key               | Linear                     | 590 K \n",
      "118 | model.base_model.encoder.layer.6.attention.self.value             | Linear                     | 590 K \n",
      "119 | model.base_model.encoder.layer.6.attention.self.dropout           | Dropout                    | 0     \n",
      "120 | model.base_model.encoder.layer.6.attention.output                 | RobertaSelfOutput          | 592 K \n",
      "121 | model.base_model.encoder.layer.6.attention.output.dense           | Linear                     | 590 K \n",
      "122 | model.base_model.encoder.layer.6.attention.output.LayerNorm       | LayerNorm                  | 1 K   \n",
      "123 | model.base_model.encoder.layer.6.attention.output.dropout         | Dropout                    | 0     \n",
      "124 | model.base_model.encoder.layer.6.intermediate                     | RobertaIntermediate        | 2 M   \n",
      "125 | model.base_model.encoder.layer.6.intermediate.dense               | Linear                     | 2 M   \n",
      "126 | model.base_model.encoder.layer.6.output                           | RobertaOutput              | 2 M   \n",
      "127 | model.base_model.encoder.layer.6.output.dense                     | Linear                     | 2 M   \n",
      "128 | model.base_model.encoder.layer.6.output.LayerNorm                 | LayerNorm                  | 1 K   \n",
      "129 | model.base_model.encoder.layer.6.output.dropout                   | Dropout                    | 0     \n",
      "130 | model.base_model.encoder.layer.7                                  | RobertaLayer               | 7 M   \n",
      "131 | model.base_model.encoder.layer.7.attention                        | RobertaAttention           | 2 M   \n",
      "132 | model.base_model.encoder.layer.7.attention.self                   | RobertaSelfAttention       | 1 M   \n",
      "133 | model.base_model.encoder.layer.7.attention.self.query             | Linear                     | 590 K \n",
      "134 | model.base_model.encoder.layer.7.attention.self.key               | Linear                     | 590 K \n",
      "135 | model.base_model.encoder.layer.7.attention.self.value             | Linear                     | 590 K \n",
      "136 | model.base_model.encoder.layer.7.attention.self.dropout           | Dropout                    | 0     \n",
      "137 | model.base_model.encoder.layer.7.attention.output                 | RobertaSelfOutput          | 592 K \n",
      "138 | model.base_model.encoder.layer.7.attention.output.dense           | Linear                     | 590 K \n",
      "139 | model.base_model.encoder.layer.7.attention.output.LayerNorm       | LayerNorm                  | 1 K   \n",
      "140 | model.base_model.encoder.layer.7.attention.output.dropout         | Dropout                    | 0     \n",
      "141 | model.base_model.encoder.layer.7.intermediate                     | RobertaIntermediate        | 2 M   \n",
      "142 | model.base_model.encoder.layer.7.intermediate.dense               | Linear                     | 2 M   \n",
      "143 | model.base_model.encoder.layer.7.output                           | RobertaOutput              | 2 M   \n",
      "144 | model.base_model.encoder.layer.7.output.dense                     | Linear                     | 2 M   \n",
      "145 | model.base_model.encoder.layer.7.output.LayerNorm                 | LayerNorm                  | 1 K   \n",
      "146 | model.base_model.encoder.layer.7.output.dropout                   | Dropout                    | 0     \n",
      "147 | model.base_model.encoder.layer.8                                  | RobertaLayer               | 7 M   \n",
      "148 | model.base_model.encoder.layer.8.attention                        | RobertaAttention           | 2 M   \n",
      "149 | model.base_model.encoder.layer.8.attention.self                   | RobertaSelfAttention       | 1 M   \n",
      "150 | model.base_model.encoder.layer.8.attention.self.query             | Linear                     | 590 K \n",
      "151 | model.base_model.encoder.layer.8.attention.self.key               | Linear                     | 590 K \n",
      "152 | model.base_model.encoder.layer.8.attention.self.value             | Linear                     | 590 K \n",
      "153 | model.base_model.encoder.layer.8.attention.self.dropout           | Dropout                    | 0     \n",
      "154 | model.base_model.encoder.layer.8.attention.output                 | RobertaSelfOutput          | 592 K \n",
      "155 | model.base_model.encoder.layer.8.attention.output.dense           | Linear                     | 590 K \n",
      "156 | model.base_model.encoder.layer.8.attention.output.LayerNorm       | LayerNorm                  | 1 K   \n",
      "157 | model.base_model.encoder.layer.8.attention.output.dropout         | Dropout                    | 0     \n",
      "158 | model.base_model.encoder.layer.8.intermediate                     | RobertaIntermediate        | 2 M   \n",
      "159 | model.base_model.encoder.layer.8.intermediate.dense               | Linear                     | 2 M   \n",
      "160 | model.base_model.encoder.layer.8.output                           | RobertaOutput              | 2 M   \n",
      "161 | model.base_model.encoder.layer.8.output.dense                     | Linear                     | 2 M   \n",
      "162 | model.base_model.encoder.layer.8.output.LayerNorm                 | LayerNorm                  | 1 K   \n",
      "163 | model.base_model.encoder.layer.8.output.dropout                   | Dropout                    | 0     \n",
      "164 | model.base_model.encoder.layer.9                                  | RobertaLayer               | 7 M   \n",
      "165 | model.base_model.encoder.layer.9.attention                        | RobertaAttention           | 2 M   \n",
      "166 | model.base_model.encoder.layer.9.attention.self                   | RobertaSelfAttention       | 1 M   \n",
      "167 | model.base_model.encoder.layer.9.attention.self.query             | Linear                     | 590 K \n",
      "168 | model.base_model.encoder.layer.9.attention.self.key               | Linear                     | 590 K \n",
      "169 | model.base_model.encoder.layer.9.attention.self.value             | Linear                     | 590 K \n",
      "170 | model.base_model.encoder.layer.9.attention.self.dropout           | Dropout                    | 0     \n",
      "171 | model.base_model.encoder.layer.9.attention.output                 | RobertaSelfOutput          | 592 K \n",
      "172 | model.base_model.encoder.layer.9.attention.output.dense           | Linear                     | 590 K \n",
      "173 | model.base_model.encoder.layer.9.attention.output.LayerNorm       | LayerNorm                  | 1 K   \n",
      "174 | model.base_model.encoder.layer.9.attention.output.dropout         | Dropout                    | 0     \n",
      "175 | model.base_model.encoder.layer.9.intermediate                     | RobertaIntermediate        | 2 M   \n",
      "176 | model.base_model.encoder.layer.9.intermediate.dense               | Linear                     | 2 M   \n",
      "177 | model.base_model.encoder.layer.9.output                           | RobertaOutput              | 2 M   \n",
      "178 | model.base_model.encoder.layer.9.output.dense                     | Linear                     | 2 M   \n",
      "179 | model.base_model.encoder.layer.9.output.LayerNorm                 | LayerNorm                  | 1 K   \n",
      "180 | model.base_model.encoder.layer.9.output.dropout                   | Dropout                    | 0     \n",
      "181 | model.base_model.encoder.layer.10                                 | RobertaLayer               | 7 M   \n",
      "182 | model.base_model.encoder.layer.10.attention                       | RobertaAttention           | 2 M   \n",
      "183 | model.base_model.encoder.layer.10.attention.self                  | RobertaSelfAttention       | 1 M   \n",
      "184 | model.base_model.encoder.layer.10.attention.self.query            | Linear                     | 590 K \n",
      "185 | model.base_model.encoder.layer.10.attention.self.key              | Linear                     | 590 K \n",
      "186 | model.base_model.encoder.layer.10.attention.self.value            | Linear                     | 590 K \n",
      "187 | model.base_model.encoder.layer.10.attention.self.dropout          | Dropout                    | 0     \n",
      "188 | model.base_model.encoder.layer.10.attention.output                | RobertaSelfOutput          | 592 K \n",
      "189 | model.base_model.encoder.layer.10.attention.output.dense          | Linear                     | 590 K \n",
      "190 | model.base_model.encoder.layer.10.attention.output.LayerNorm      | LayerNorm                  | 1 K   \n",
      "191 | model.base_model.encoder.layer.10.attention.output.dropout        | Dropout                    | 0     \n",
      "192 | model.base_model.encoder.layer.10.intermediate                    | RobertaIntermediate        | 2 M   \n",
      "193 | model.base_model.encoder.layer.10.intermediate.dense              | Linear                     | 2 M   \n",
      "194 | model.base_model.encoder.layer.10.output                          | RobertaOutput              | 2 M   \n",
      "195 | model.base_model.encoder.layer.10.output.dense                    | Linear                     | 2 M   \n",
      "196 | model.base_model.encoder.layer.10.output.LayerNorm                | LayerNorm                  | 1 K   \n",
      "197 | model.base_model.encoder.layer.10.output.dropout                  | Dropout                    | 0     \n",
      "198 | model.base_model.encoder.layer.11                                 | RobertaLayer               | 7 M   \n",
      "199 | model.base_model.encoder.layer.11.attention                       | RobertaAttention           | 2 M   \n",
      "200 | model.base_model.encoder.layer.11.attention.self                  | RobertaSelfAttention       | 1 M   \n",
      "201 | model.base_model.encoder.layer.11.attention.self.query            | Linear                     | 590 K \n",
      "202 | model.base_model.encoder.layer.11.attention.self.key              | Linear                     | 590 K \n",
      "203 | model.base_model.encoder.layer.11.attention.self.value            | Linear                     | 590 K \n",
      "204 | model.base_model.encoder.layer.11.attention.self.dropout          | Dropout                    | 0     \n",
      "205 | model.base_model.encoder.layer.11.attention.output                | RobertaSelfOutput          | 592 K \n",
      "206 | model.base_model.encoder.layer.11.attention.output.dense          | Linear                     | 590 K \n",
      "207 | model.base_model.encoder.layer.11.attention.output.LayerNorm      | LayerNorm                  | 1 K   \n",
      "208 | model.base_model.encoder.layer.11.attention.output.dropout        | Dropout                    | 0     \n",
      "209 | model.base_model.encoder.layer.11.intermediate                    | RobertaIntermediate        | 2 M   \n",
      "210 | model.base_model.encoder.layer.11.intermediate.dense              | Linear                     | 2 M   \n",
      "211 | model.base_model.encoder.layer.11.output                          | RobertaOutput              | 2 M   \n",
      "212 | model.base_model.encoder.layer.11.output.dense                    | Linear                     | 2 M   \n",
      "213 | model.base_model.encoder.layer.11.output.LayerNorm                | LayerNorm                  | 1 K   \n",
      "214 | model.base_model.encoder.layer.11.output.dropout                  | Dropout                    | 0     \n",
      "215 | model.classifier                                                  | Sequential                 | 592 K \n",
      "216 | model.classifier.0                                                | Dropout                    | 0     \n",
      "217 | model.classifier.1                                                | Linear                     | 590 K \n",
      "218 | model.classifier.2                                                | Mish                       | 0     \n",
      "219 | model.classifier.3                                                | Dropout                    | 0     \n",
      "220 | model.classifier.4                                                | Linear                     | 1 K   \n",
      "221 | loss                                                              | CrossEntropyLoss           | 0     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34:  87%|████████▋ | 60/69 [00:07<00:01,  7.59it/s, loss=0.505, train_loss=0.19, v_num=110] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=hparams.epochs, progress_bar_refresh_rate=10,\n",
    "                     accumulate_grad_batches=hparams.accumulate_grad_batches,\n",
    "                     early_stop_callback=early_stop_callback)\n",
    "\n",
    "trainer.fit(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\n",
      "________________________________________________________________________________\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        weak     0.7419    0.6389    0.6866        36\n",
      "      strong     0.6750    0.7714    0.7200        35\n",
      "\n",
      "    accuracy                         0.7042        71\n",
      "   macro avg     0.7085    0.7052    0.7033        71\n",
      "weighted avg     0.7089    0.7042    0.7030        71\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    progress = [\"/\", \"-\", \"\\\\\", \"|\", \"/\", \"-\", \"\\\\\", \"|\"]\n",
    "    module.eval().cuda()\n",
    "    true_y, pred_y = [], []\n",
    "    for i, batch_ in enumerate(module.test_dataloader()):\n",
    "        (X, attn), y = batch_\n",
    "        batch = (X.cuda(), attn.cuda())\n",
    "        print(progress[i % len(progress)], end=\"\\r\")\n",
    "        y_pred = torch.argmax(module(batch), dim=1)\n",
    "        true_y.extend(y.cpu())\n",
    "        pred_y.extend(y_pred.cpu())\n",
    "print(\"\\n\" + \"_\" * 80)\n",
    "print(classification_report(true_y, pred_y, target_names=label2int.keys(), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot confusion matrix\n",
    "\n",
    "cm = confusion_matrix(true_y, pred_y, labels=range(len(labels)))\n",
    "df_cm = pd.DataFrame(cm, index = labels, columns = labels)\n",
    "\n",
    "plt.rcParams.update({'font.size': 12}) \n",
    "plt.figure(figsize = (10,8));\n",
    "sn.heatmap(df_cm, annot=True, cmap='Greens', fmt='g');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "# module.save_model(version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model test\n",
    "# hparams = Namespace(\n",
    "#     train_path=train_path,\n",
    "#     val_path=val_path,\n",
    "#     test_path=test_path,\n",
    "#     batch_size=10,\n",
    "#     warmup_steps=100,\n",
    "#     epochs=20,\n",
    "#     lr=2E-05,\n",
    "#     accumulate_grad_batches=1\n",
    "# )\n",
    "# device = torch.device('cuda:0')\n",
    "# model = TrainingModule(hparams)\n",
    "# model.model.load_state_dict(torch.load('empathy_model\\RoBERTa_empathy_1ft_1.pt'), strict=False)\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # testing for retrieving model\n",
    "# with torch.no_grad():\n",
    "#     progress = [\"/\", \"-\", \"\\\\\", \"|\", \"/\", \"-\", \"\\\\\", \"|\"]\n",
    "#     model.eval().cuda()\n",
    "#     true_y, pred_y = [], []\n",
    "#     for i, batch_ in enumerate(model.test_dataloader()):\n",
    "#         (X, attn), y = batch_\n",
    "#         batch = (X.cuda(), attn.cuda())\n",
    "#         print(progress[i % len(progress)], end=\"\\r\")\n",
    "#         y_pred = torch.argmax(model(batch), dim=1)\n",
    "#         true_y.extend(y.cpu())\n",
    "#         pred_y.extend(y_pred.cpu())\n",
    "# print(\"\\n\" + \"_\" * 80)\n",
    "# print(classification_report(true_y, pred_y, target_names=label2int.keys(), digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54bb103c3e8827112ac287ff09b16e5ca2d85540a3af0b288083619c88e41aa7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
