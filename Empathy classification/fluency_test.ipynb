{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yisiang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tokenizers.processors import BertProcessing\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from transformers import (\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    GPT2Tokenizer,\n",
    "    GPT2LMHeadModel,\n",
    "    BertTokenizer,\n",
    "    BertModel,\n",
    "    AutoModelWithLMHead,\n",
    "    AutoTokenizer\n",
    ")\n",
    "from nltk.corpus import stopwords\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained GPT2 language model weights\n",
    "with torch.no_grad():\n",
    "    gptmodel = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "    gptmodel.eval()\n",
    "\n",
    "# Load pre-trained GPT2 tokenizer\n",
    "gpttokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# simple tokenizer + stemmer\n",
    "regextokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "stemmer = nltk.stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repetition_penalty(sentence):\n",
    "    '''\n",
    "    Adds a penalty for each repeated (stemmed) token in\n",
    "    an utterance. Returns the total penalty of the sentence\n",
    "    '''\n",
    "    word_list = regextokenizer.tokenize(sentence.lower())\n",
    "    filtered_words = [\n",
    "        word for word in word_list if word not in stopwords.words('english')]\n",
    "    stem_list = [stemmer.stem(word) for word in filtered_words]\n",
    "    penalty = 0\n",
    "    visited = []\n",
    "    for w in stem_list:\n",
    "        if w not in visited:\n",
    "            visited.append(w)\n",
    "        else:\n",
    "            penalty += 0.001\n",
    "    print(visited)\n",
    "    print(penalty)\n",
    "    return penalty\n",
    "\n",
    "def perplexity(sentence):\n",
    "    '''\n",
    "    Computes the PPL of an utterance using GPT2 LM\n",
    "    '''\n",
    "    tokenize_input = gpttokenizer.encode(sentence)\n",
    "    tensor_input = torch.tensor([tokenize_input])\n",
    "    with torch.no_grad():\n",
    "        loss = gptmodel(tensor_input, labels=tensor_input)[0]\n",
    "    return np.exp(loss.detach().numpy())\n",
    "\n",
    "\n",
    "def fluency_score(sentence):\n",
    "    '''\n",
    "    Computes the fluency score of an utterance, given by the\n",
    "    inverse of the perplexity minus a penalty for repeated tokens\n",
    "    '''\n",
    "    ppl = perplexity(sentence)\n",
    "    penalty = repetition_penalty(sentence)\n",
    "    score = (1 / ppl) - penalty\n",
    "    # normalise by the highest possible fluency computed on the corpus:\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('empathy_annotate.csv')#put data in Drive root folder or change path\n",
    "data = data.drop([\"Annotator2\",\"Annotator3\",\"Annotator1\"], axis=1)\n",
    "data = data.dropna()\n",
    "data = data.drop([\"Score\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi {Bob}. I am a robot specialising in creativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi {Bob}! How are you feeling today? I'm Creat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello {Bob}, are you having a good day, how do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi {Bob}, this is CreativeBot. How are you today?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hello {Bob}, my name is CreativeBot and I'm he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Response\n",
       "1  Hi {Bob}. I am a robot specialising in creativ...\n",
       "2  Hi {Bob}! How are you feeling today? I'm Creat...\n",
       "3  Hello {Bob}, are you having a good day, how do...\n",
       "4  Hi {Bob}, this is CreativeBot. How are you today?\n",
       "5  Hello {Bob}, my name is CreativeBot and I'm he..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1414\n"
     ]
    }
   ],
   "source": [
    "d1 = data.Response.values.tolist()\n",
    "print(len(d1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acquir', 'characterist', 'dichotomi', 'contribut', 'nurtur', 'creativ', 'could', 'doubl', 'collect', 'respons', 'allow', 'interact', 'wider', 'rang', 'opportun', 'like', 'two', 'yolk', 'one', 'egg', 'twice', 'fun']\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00993104443186193"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = \"Acquiring both characteristics of {a dichotomy} contributes to nurturing creativity, it could double your collection of responses and allow you to interact with a wider range of opportunities. It is like two yolks in one egg, twice the fun.\"\n",
    "fluency_score(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = []\n",
    "for sentence in d1:\n",
    "    score = fluency_score(sentence)\n",
    "    ls.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.018432738929968554\n",
      "std:  0.012613155336390784\n",
      "max:  0.09022261645209122\n"
     ]
    }
   ],
   "source": [
    "print(\"mean: \", np.mean(ls))\n",
    "print(\"std: \" , np.std(ls))\n",
    "print(\"max: \", max(ls))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54bb103c3e8827112ac287ff09b16e5ca2d85540a3af0b288083619c88e41aa7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
